{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "YoaV-F722tlR"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# fix seed: results of training depend on seed value; typically, one runs several simulations \n",
    "# and post-selects the best performance\n",
    "seed=0 \n",
    "np.random.seed(seed)\n",
    "\n",
    "# fix output array\n",
    "np.set_printoptions(suppress=True,precision=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AP5VvuX72tlO"
   },
   "source": [
    "# Deep Policy Gradient (PG)\n",
    "\n",
    "\n",
    "In this notebook, our goal is to implement the REINFORCE algorithm for policy gradient using [JAX](https://jax.readthedocs.io/en/latest/). \n",
    "\n",
    "We will apply this RL algorithm to control a single quantum bit of information (qubit) in the presence of different kinds of noise and spontaneous emission.  \n",
    "\n",
    "## The REINFORCE Algorithm\n",
    "\n",
    "The reinforcement learning objective $\\mathbf J$ is the expected total return $\\mathbf G$, following the policy $\\pi$. If the transition probability is denoted by $p(s'|s,a)$, and the initial state distribution is $p(s_0)$, the probability for a trajectory $\\tau = (s_0,a_0,r_1,s_1,a_1,\\dots,s_{T-1},a_{T-1},r_T,s_T)$ to occur can be written as\n",
    "\n",
    "$$ \n",
    "P_\\pi(\\tau) = p(s_0)\\prod_{t=1}^T \\pi(a_t|s_t)p(s_{t+1}|s_t,a_t). \n",
    "$$\n",
    "\n",
    "The RL objective then takes the form\n",
    "\n",
    "$$\n",
    "\\mathbf J = \\mathbb{E}_{\\tau\\sim P_\\pi} \\left[ \\mathbf G(\\tau) | s_{t=0}=s_0 \\right],\\qquad \\mathbf G(\\tau)=\\sum_{t=1}^T r(s_t,a_t).\n",
    "$$\n",
    "\n",
    "Policy gradient methods in RL approximate directly the policy $\\pi\\approx\\pi_\\theta$ using a variational ansatz, parametrized by some unknown parameters $\\theta$ (e.g., the weights and biases of a neural network). The goal is then to find those optimal parameters $\\theta$, which maximize the RL objective $\\mathbf J(\\theta)$. To define an update rule for $\\theta$, we can use gradient ascent. This requires us to evaluate the gradient of the RL objective,\n",
    "$$\n",
    "\\mathbf J(\\theta) = \\mathbb{E}_{\\tau\\sim P_{\\pi_\\theta}} \\left[ \\mathbf G(\\tau) | s_{t=0}=s_0 \\right]\n",
    "    = \\int\\mathcal{D}\\tau\\; P_{\\pi_{\\theta}}(\\tau)\\; G(\\tau),\n",
    "$$\n",
    "w.r.t. the parameters $\\theta$.\n",
    "\n",
    "In a model-free setting, we don't have access to the transition probabilities $p(s'|s,a)$ and this requires us to be able to estimate the gradients from samples. This can be accomplished by noticing that $\\nabla_\\theta P_{\\pi_\\theta} = P_{\\pi_\\theta} \\nabla_\\theta \\log P_{\\pi_\\theta}$ (almost everywhere, i.e. up to a set of measure zero):\n",
    "\n",
    "$$\n",
    "\\nabla_\\theta \\mathbf J(\\theta) \n",
    "= \\nabla_\\theta \\mathbb{E}_{\\tau\\sim P_\\pi} \\left[ \\sum_{t=1}^T r(s_t,a_t) | s_{t=0}=s_0 \\right] \n",
    "= \\nabla_\\theta \\int\\mathcal{D}\\tau\\; P_{\\pi_\\theta}(\\tau)\\; \\mathbf G(\\tau)\n",
    "= \\int\\mathcal{D}\\tau\\; \\nabla_\\theta P_{\\pi_\\theta}(\\tau)\\; \\mathbf G(\\tau)\n",
    "= \\int\\mathcal{D}\\tau\\; P_{\\pi_\\theta} \\nabla_\\theta \\log P_{\\pi_\\theta}\\; \\mathbf G(\\tau)\n",
    "= \\nabla_\\theta \\mathbb{E}_{\\tau\\sim P_\\pi} \\left[ \\nabla_\\theta \\log P_{\\pi_\\theta}\\; \\mathbf G \\right] .\n",
    "$$\n",
    "Since the initial state distribution $p(s_0)$ and the transition probabilities $p(s_{t+1}|s_t,a_t)$ are independent of $\\theta$, using the definition of $P_{\\pi_\\theta}$, we see that $\\nabla_\\theta \\log P_{\\pi_\\theta}(\\tau) = \\nabla_\\theta \\log \\pi_\\theta(\\tau)$ where $\\pi_\\theta(\\tau) = \\prod_{t=1}^T \\pi_\\theta(a_t|s_t)$. \n",
    "\n",
    "We can therefore use Monte Carlo sampling to estimate the gradients directly from a sample of trajectories $\\{\\tau_j\\}_{j=1}^N$ using the policy $\\pi_\\theta(\\tau)$:\n",
    "$$\n",
    "    \\nabla_\\theta \\mathbf J(\\theta) = \\mathbb{E}_{\\tau\\sim P_\\pi} \\left[\\nabla_\\theta \\log \\pi_\\theta(\\tau)\\; \\mathbf G(\\tau)\\right]\n",
    "    \\approx \\frac{1}{N}\\sum_{j=1}^N \\nabla_\\theta \\log \\pi_\\theta(\\tau_j)\\; \\mathbf G(\\tau_j)\n",
    "    = \\frac{1}{N}\\sum_{j=1}^N \\left( \\sum_{t=1}^T \\nabla_\\theta\\; \\pi_\\theta(a^j_t|s^j_t) \\sum_{t'=1}^T r(a^j_{t'},s^j_{t'}) \\right),    \n",
    "$$\n",
    "where in the last equality we used $\\log \\pi_\\theta(\\tau) = \\log \\prod_{t=1}^T \\pi_\\theta(a_t|s_t) = \\sum_{t=1}^T \\pi_\\theta(a^j_t|s^j_t)$, together with the definition of the total return $\\mathbf G(\\tau)$ above.\n",
    "\n",
    "To alleviate the problem with the large variance of the gradient estimate, one can introduce a baseline $b=N^{-1}\\sum_j \\sum_{t'=t}^T r(a^j_{t'}|s^j_{t'})$, defined as the average return over the sample. The policy gradient (PG) update then takes the form\n",
    "\n",
    "$$\n",
    "\\nabla_\\theta \\mathbf J(\\theta)\n",
    "\\approx \\frac{1}{N}\\sum_{j=1}^N \\sum_{t=1}^T \\nabla_\\theta \\log \\pi_\\theta(a^j_t|s^j_t) \\left[\\sum_{t'=t}^T r(a^j_{t'}|s^j_{t'})) - b\\right].\n",
    "$$\n",
    "\n",
    "One can show that adding this baseline term does not change the expectation value $\\nabla_\\theta \\mathbf J(\\theta) = \\mathbb{E}_{\\tau\\sim P_\\pi} \\left[\\nabla_\\theta \\log \\pi_\\theta(\\tau)\\; \\mathbf G(\\tau)\\right]$.\n",
    "\n",
    "The corresponding gradient *ascent* update rule reads as\n",
    "\n",
    "$$\n",
    "\\theta \\leftarrow \\theta + \\alpha \\nabla_\\theta \\mathbf J(\\theta),\n",
    "$$\n",
    "for some step size (or learning rate) $\\alpha$. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "phj-0zwt2tlQ"
   },
   "source": [
    "## Qubit Environment: Shortcuts to Adiabaticity\n",
    "\n",
    "Let us define the qubit environment that models the action of gates on the state of the two-level system (2LS). Our goal is to use RL to improve counter-diabatic (CD) driving. To this end, we first use CD theory to determine the operator to which the CD terms couple. However, instead of using the CD protocol, we let the RL agent find the optimal counter drive. \n",
    "\n",
    "### Basic Definitions\n",
    "\n",
    "The state of a qubit $|\\psi\\rangle\\in\\mathbb{C}^2$ is modeled by a two-dimensional complex-valued vector with unit norm: $\\langle\\psi|\\psi\\rangle:=\\sqrt{|\\psi_1|^2+|\\psi_2|^2}=1$. Every qubit state is uniquely described by two angles $\\theta\\in[0,\\pi]$ and $\\varphi\\in[0,2\\pi)$:\n",
    "\n",
    "\\begin{equation}\n",
    "|\\psi\\rangle=\n",
    "\\begin{pmatrix}\n",
    "\\psi_1 \\\\ \\psi_2\n",
    "\\end{pmatrix}=\n",
    "\\mathrm{e}^{i\\alpha}\n",
    "\\begin{pmatrix}\n",
    "\\cos\\frac{\\theta}{2} \\\\\n",
    "\\mathrm{e}^{i\\varphi}\\sin\\frac{\\theta}{2}\n",
    "\\end{pmatrix}\n",
    "\\end{equation}\n",
    "\n",
    "The overall phase $\\alpha$ of a single quantum state has no physical meaning.\n",
    "Thus, any qubit state can be pictured as an arrow on the unit sphere (called the Bloch sphere) with spherical coordinates $(\\theta,\\varphi)$. \n",
    "\n",
    "To operate on qubits, we use quantum gates. Quantum gates are represented as unitary transformations $U\\in \\mathrm{U(2)}$, where $\\mathrm{U(2)}$ is the unitary group. Gates act on qubit states by matrix multiplication to transform an input state $|\\psi\\rangle$ to the output state $|\\psi'\\rangle$: $|\\psi'\\rangle=U|\\psi\\rangle.$ \n",
    "\n",
    "In quantum platforms, unitary gates are generated by Hamiltonian time evolution. Given an arbitrary time-dependent Hamiltonian $H(t)$, the associated time-evolution operator is given by\n",
    "\\begin{equation}\n",
    "    U(t,0) = \\mathcal{T}_t\\exp\\left(-i \\int_0^t\\mathrm d t' H(t')\\right),\n",
    "\\end{equation}\n",
    "where $\\mathcal{t}_t\\exp$ denotes the time-ordered exponential, and $t$ is the total time the Hamiltonian is applied for. \n",
    "\n",
    "For this problem, we consider a two-level system given by the Hamiltonian\n",
    "\\begin{equation}\n",
    "H(t) = \\Delta\\sigma^x + \\nu(t)\\sigma^z,\n",
    "\\end{equation}\n",
    "where $\\Delta$ sets the energy splitting, and the control field $\\nu(t)$ couples the two levels. The identity and the Pauli matrices are defined as\n",
    "\n",
    "\\begin{equation}\n",
    "\\boldsymbol{1}=\\begin{pmatrix}\n",
    "1 & 0 \\\\ 0 & 1\n",
    "\\end{pmatrix}\n",
    ",\\qquad\n",
    "\\sigma^x=\\begin{pmatrix}\n",
    "0 & 1 \\\\ 1 & 0\n",
    "\\end{pmatrix}\n",
    ",\\qquad\n",
    "\\sigma^y=\\begin{pmatrix}\n",
    "0 & -i \\\\ i & 0\n",
    "\\end{pmatrix}\n",
    ",\\ \\qquad\n",
    "\\sigma^z=\\begin{pmatrix}\n",
    "1 & 0 \\\\ 0 & -1\n",
    "\\end{pmatrix}.\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "### Control Problem\n",
    "\n",
    "Counter-diabatic driving introduces additional control terms to suppress excitations during the protocol:\n",
    "\\begin{equation}\n",
    "H_\\text{CD}(t) = \\Delta\\sigma^x + \\nu(t)\\sigma^z - \\frac{1}{2}\\frac{\\Delta\\; \\dot\\nu(t)}{\\Delta^2 + \\nu^2(t)}\\sigma^y.\n",
    "\\end{equation}\n",
    "When evolved using $H_\\text{CD}(t)$, the system follows the instantaneous eigenstates of the Hamiltonian $H(t)$ at all times. \n",
    "\n",
    "\n",
    "We now initialize the system in the ground state of the Hamiltonian $H(0)$ at $\\nu_i=+2\\Delta$, and want to transfer the population in the ground state at $H(t)$ at $\\nu_\\ast=-2\\Delta$ in a finite amount of time $T$ (referred to as the duration of the protocol). The system is subject to the Hamitlnoan\n",
    "\\begin{equation}\n",
    "    H_g(t) = \\Delta\\sigma^x + \\nu(t)\\sigma^z - g(t)\\sigma^y,\n",
    "\\end{equation}\n",
    "where $\\nu(t) = (\\nu_\\ast-\\nu_i)t/T + \\nu_i$ is the linear drift term that is always on (and the RL agent has no control over), while $g(t)$ is the unknown counter protocol that we want our RL agent to find.  \n",
    "\n",
    "To determine if a qubit, described by the state $|\\psi\\rangle$, is in a desired target state $|\\psi_\\mathrm{target}\\rangle$, we compute the fidelity\n",
    "\n",
    "\\begin{equation}\n",
    "\\mathcal F=|\\langle\\psi_\\mathrm{target}|\\psi\\rangle|^2 = |(\\psi_\\mathrm{target})^\\ast_1 \\psi_1 + (\\psi_\\mathrm{target})^\\ast_2 \\psi_2|^2,\\qquad \\mathcal F\\in[0,1]\n",
    "\\end{equation}\n",
    "\n",
    "where $\\ast$ stands for complex conjugation. Physically, the fidelity corresponds to the angle between the arrows representing the qubit state on the Bloch sphere (we want to maximize the fidelity but minimize the angle between the states)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constructing the Qubit Environment\n",
    "\n",
    "Now, let us define an episodic RL environment, which contains the laws of physics that govern the dynamics of the qubit (i.e. the application of the gate operations corresponding to the Hamiltonian evolution to the qubit state). Our RL agent will later interact with this environment to learn how to control the qubit to bring it from an initial state to a prescribed target state (see above). \n",
    "\n",
    "We define the RL states $s=(\\theta,\\varphi)$ as an array containing the Bloch sphere angles of the quantum state. For each timestep of size $\\delta t$ within an episode, the agent has to determine the value of the protocol function $g(t)$; to this end, starting from some initial value $g_i$, we let the agent find the optimal relative change in the protocol (i.e., by now much the protocol value has to jump at the given timestep). In practice, we define a minimum protocol size $\\delta g$, and consider $2n+1$ steps of size $(-n\\delta g, -(n-1)\\delta g, \\dots, -\\delta g, 0,\\delta g,\\dots, (n-1)\\delta g, n\\delta g)$ that the agent has to choose from.   \n",
    "\n",
    "We use the logarithmic fidelity w.r.t. the target state at the end of the protocol \n",
    "\\begin{equation}\n",
    "    r_t=-\\log_{10}\\left(1-\\mathcal F\\right),\\qquad \\mathcal F=|\\langle\\psi_\\ast|\\psi(T)\\rangle|^2,\\qquad |\\psi(T)\\rangle = U(T,0)|\\psi_i\\rangle,\n",
    "\\end{equation} \n",
    "as a reward. The logarithm allows us to learn on a logarithmic scale. Note also that the reward is sparse (i.e., given only at the end of the episode) -- this reflects the character of quantum measurements that collapse the wavefunction. \n",
    "\n",
    "**state space:** $\\mathbf{S} = \\{(\\theta,\\varphi)|\\theta\\in[0,\\pi],\\varphi\\in[0,2\\pi)\\}$. There are no well-defined terminal states in this task. Instead, we consider a fixed number of time steps, after which the episode terminates deterministically. \n",
    "\n",
    "**action space:** $\\mathbf{A} = \\{-n,-(n-1),\\cdots,-1,0,1,\\cdots,n-1,n\\}$. Actions act on RL states as follows: \n",
    "1. if the current state is $s=(\\theta,\\varphi)$, we first create the quantum state $|\\psi(s)\\rangle$; \n",
    "2. we apply the gate $U_a$ corresponding to action $a$ to the quantum state, defined by:\n",
    "\\begin{equation}\n",
    "    U_a = \\exp(-i \\delta t H_{a\\times\\delta g}(n\\delta t)),\\qquad H_{a\\times\\delta g}(n\\delta t) = \\Delta\\sigma^x + \\nu(n\\delta t)\\sigma^z - a\\times\\delta g\\sigma^y,\n",
    "\\end{equation}\n",
    "where $n$ labels the time steps (such the current time is $t=n\\delta t$), $a\\in\\mathbf{A}$, and $\\delta g$ is the minimum protocol size.\n",
    "4. we obtain the new quantum state $|\\psi(s')\\rangle = U_a|\\psi(s)\\rangle$. \n",
    "5. last, we compute the Bloch sphere coordinates which define the next state $s'=(\\theta',\\varphi')$, using the Bloch sphere parametrization for qubits given above.\n",
    "Note that all actions are allowed from every state. \n",
    "\n",
    "\n",
    "**reward space:** $\\mathbf{R}=[0,+\\infty)$. The reward is zero at each step during the protocol: $r_{t<T}=0$, except at the last step, where we use the fidelity between the final state $s_T$ and the target state $s_\\ast$ as a reward at the end of every protocol: \n",
    "\n",
    "$$r(s,s',a)= r_T = -\\log_{10}\\left(1-\\mathcal F\\right),\\qquad \\mathcal F=|\\langle\\psi_\\ast|\\psi(T)\\rangle|^2$$\n",
    "\n",
    "for all states $s,s'\\in\\mathbf{S}$ and actions $a\\in\\mathbf{A}$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "STFbyoqq4frU"
   },
   "outputs": [],
   "source": [
    "class QubitEnv():\n",
    "    \"\"\"\n",
    "    Gym style environment for RL. You may also inherit the class structure from OpenAI Gym. \n",
    "    Parameters:\n",
    "        n_time_steps:   int\n",
    "                        Total number of time steps within each episode\n",
    "        seed:   int\n",
    "                seed of the RNG (for reproducibility)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, n_time_steps, seed):\n",
    "        \"\"\"\n",
    "        Initialize the environment.\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        self.n_time_steps = n_time_steps\n",
    "        \n",
    "        ### define action space variables\n",
    "        max_action = 10\n",
    "        self.n_actions = 2*max_action+1 # action space size\n",
    "        self.action_space=np.linspace(-max_action,+max_action, self.n_actions, dtype=int) \n",
    "        self.actions = np.arange(self.n_actions)\n",
    "\n",
    "\n",
    "        # set model parameters\n",
    "        self.T = 1.2 # total duration of protocol\n",
    "        self.dt = self.T/self.n_time_steps # time step\n",
    "        \n",
    "        self.Delta=1.0 # splitting\n",
    "        self.h_init  =+2.0 # initial field value\n",
    "        self.h_target=-2.0 # target field value\n",
    "        self.delta_h = (self.h_target-self.h_init)/(max_action*self.n_time_steps)\n",
    "\n",
    "        # linear ramp\n",
    "        self.h_t = lambda t: (self.h_target-self.h_init)*t/self.T + self.h_init\n",
    "        self.h_t_prime = lambda t: (self.h_target-self.h_init)/self.T\n",
    "        # self.h_t = lambda t: self.h_target*2.0*(-0.5 + np.sin(0.5*np.pi*t/self.T)**2 )\n",
    "        # self.h_t_prime = lambda t: self.h_target*2.0 * 2.0*(0.5*np.pi/self.T)*np.sin(0.5*np.pi*t/self.T)*np.cos(0.5*np.pi*t/self.T)\n",
    "        \n",
    "        # define Pauli matrices\n",
    "        self.Id     =np.array([[1.0,0.0  ], [0.0 ,+1.0]])\n",
    "        self.sigma_x=np.array([[0.0,1.0  ], [1.0 , 0.0]])\n",
    "        self.sigma_y=np.array([[0.0,-1.0j], [1.0j, 0.0]])\n",
    "        self.sigma_z=np.array([[1.0,0.0  ], [0.0 ,-1.0]])\n",
    "        \n",
    "        \n",
    "        ### define state space variables\n",
    "        H = lambda h: self.Delta*self.sigma_x + h*self.sigma_z\n",
    "        # initial states\n",
    "        E_init,V_init = np.linalg.eigh(H(self.h_init))\n",
    "        self.psi_init = V_init[:,0]\n",
    "        # target state\n",
    "        E_target,V_target = np.linalg.eigh(H(self.h_target))\n",
    "        self.psi_target = V_target[:,0]\n",
    "        \n",
    "        # compute Bloch sphere coordinates\n",
    "        self.S_target = self.qubit_to_RL_state(self.psi_target)\n",
    "        \n",
    "        \n",
    "        # set seed\n",
    "        self.set_seed(seed)\n",
    "        self.reset()\n",
    "    \n",
    "    def compute_gate(self, action,):\n",
    "        \"\"\"\n",
    "        Given the action, computes the gate to be applied on the qubit.\n",
    "        Parameters:\n",
    "            action: int\n",
    "                    the index of the respective action in the action array.\n",
    "        Returns:\n",
    "            output: np.ndarray\n",
    "                    unitary matrix encoding the gate operation. \n",
    "        \"\"\"\n",
    "        \n",
    "        # drift part of Hamiltonian, always on, ~ sigma_x\n",
    "        drive = self.h_t(self.dt*self.ep_step) \n",
    "        # control part of the Hamiltonian, controlled by RL agent, ~ sigma_y\n",
    "        self.CD_drive += self.delta_h*self.action_space[action] \n",
    "        \n",
    "        # total angle of rotation = dt x norm of the total external field\n",
    "        norm = self.dt * np.sqrt(self.Delta**2 + drive**2 + self.CD_drive**2)\n",
    "\n",
    "        # \\exp(-i norm * \\vec{n} \\dot \\vec{\\sigma})\n",
    "        gate = np.cos(norm)*self.Id - 1j*np.sin(norm)*self.dt/norm*(self.Delta * self.sigma_x + \n",
    "                                                                    drive * self.sigma_z - \n",
    "                                                                    self.CD_drive * self.sigma_y\n",
    "                                                               )\n",
    "        return gate\n",
    "    \n",
    "    def step(self, action):\n",
    "        \"\"\"\n",
    "        Interface between environment and agent. Performs one step in the environemnt.\n",
    "        Parameters:\n",
    "            action: int\n",
    "                    the index of the respective action in the action array\n",
    "        Returns:\n",
    "            output: (object, float, bool)\n",
    "                    information provided by the environment about its current state:\n",
    "                    (state, reward, done)\n",
    "        \"\"\"\n",
    "\n",
    "        # apply gate to quantum state\n",
    "        gate = self.compute_gate(action)\n",
    "        \n",
    "        # apply unitary\n",
    "        self.psi = gate.dot(self.psi)\n",
    "        \n",
    "        # compute RL state\n",
    "        self.state = self.qubit_to_RL_state(self.psi)\n",
    "        \n",
    "        self.ep_step+=1 # increment step\n",
    "\n",
    "        # compute reward\n",
    "        if self.ep_step == self.n_time_steps:\n",
    "            #reward = np.abs( self.psi_target.conj().dot(self.psi)  )**2\n",
    "            reward = -np.log10( 1.0 - np.abs( self.psi_target.conj().dot(self.psi)  )**2 )\n",
    "        else:\n",
    "            reward = 0.0\n",
    "\n",
    "        \n",
    "        # check if state is terminal\n",
    "        done=False\n",
    "        \n",
    "        return self.state, reward, done\n",
    "\n",
    "    \n",
    "    \n",
    "    def set_seed(self,seed=0):\n",
    "        \"\"\"\n",
    "        Sets the seed of the RNG.\n",
    "        \n",
    "        \"\"\"\n",
    "        np.random.seed(seed)\n",
    "    \n",
    "    \n",
    "    \n",
    "    def reset(self, ):\n",
    "        \"\"\"\n",
    "        Resets the environment to its initial values.\n",
    "        Returns:\n",
    "            state:  object\n",
    "                    the initial state of the environment\n",
    "            random: bool\n",
    "                    controls whether the initial state is a random state on the sphere or a fixed initial state.\n",
    "        \"\"\"\n",
    "        self.ep_step=0 # reset step coutner\n",
    "        self.CD_drive = 0.5*self.Delta * self.h_t_prime(self.dt*self.ep_step) / (self.Delta**2 + (self.h_t(self.dt*self.ep_step))**2) # -0.33\n",
    "        \n",
    "        self.psi=self.psi_init[:]\n",
    "        self.state=self.qubit_to_RL_state(self.psi)\n",
    "\n",
    "        return self.state\n",
    "\n",
    "    \n",
    "    \n",
    "    def render(self):\n",
    "        \"\"\"\n",
    "        Plots the state of the environment. For visulization purposes only. Feel free to ignore. \n",
    "\n",
    "        \"\"\"\n",
    "        pass\n",
    "    \n",
    "    \n",
    "    def RL_to_qubit_state(self,s):\n",
    "        \"\"\"\n",
    "        Take as input the RL state s, and return the quantum state |psi>\n",
    "        \"\"\"\n",
    "        theta, phi = s\n",
    "        psi = np.array([np.cos(0.5*theta), np.exp(1j*phi)*np.sin(0.5*theta)] )\n",
    "        return psi\n",
    "    \n",
    "    \n",
    "    def qubit_to_RL_state(self,psi):\n",
    "        \"\"\"\n",
    "        Take as input the RL state s, and return the quantum state |psi>\n",
    "        \"\"\"\n",
    "        # take away unphysical global phase\n",
    "        alpha = np.angle(psi[0])\n",
    "        psi_new = np.exp(-1j*alpha) * psi \n",
    "        \n",
    "        # find Bloch sphere angles\n",
    "        theta = 2.0*np.arccos(psi_new[0]).real\n",
    "        phi = np.angle(psi_new[1])\n",
    "        \n",
    "        return np.array([theta, phi])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a1EyMAt-4i7F"
   },
   "source": [
    "Let us test how the qubit environment works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "29-YtNb02tlS",
    "outputId": "940d847a-b3b5-4281-ef53-5592373a3a67"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0. s=[2.68 3.14], a=12, r=0.0, s'=[ 2.66 -3.14]\n",
      "\n",
      "1. s=[ 2.66 -3.14], a=15, r=0.0, s'=[ 2.63 -3.14]\n",
      "\n",
      "2. s=[ 2.63 -3.14], a=0, r=0.0, s'=[ 2.62 -3.13]\n",
      "\n",
      "3. s=[ 2.62 -3.13], a=3, r=0.0, s'=[ 2.6  -3.13]\n",
      "\n",
      "4. s=[ 2.6  -3.13], a=3, r=0.0, s'=[ 2.59 -3.14]\n",
      "\n",
      "5. s=[ 2.59 -3.14], a=7, r=0.0, s'=[2.58 3.14]\n",
      "\n",
      "6. s=[2.58 3.14], a=9, r=0.0, s'=[2.58 3.13]\n",
      "\n",
      "7. s=[2.58 3.13], a=19, r=0.0, s'=[2.56 3.11]\n",
      "\n",
      "8. s=[2.56 3.11], a=18, r=0.0, s'=[2.54 3.1 ]\n",
      "\n",
      "9. s=[2.54 3.1 ], a=4, r=0.0, s'=[2.53 3.08]\n",
      "\n",
      "10. s=[2.53 3.08], a=6, r=0.0, s'=[2.51 3.06]\n",
      "\n",
      "11. s=[2.51 3.06], a=12, r=0.0, s'=[2.49 3.03]\n",
      "\n",
      "12. s=[2.49 3.03], a=1, r=0.0, s'=[2.48 3.  ]\n",
      "\n",
      "13. s=[2.48 3.  ], a=6, r=0.0, s'=[2.46 2.97]\n",
      "\n",
      "14. s=[2.46 2.97], a=7, r=0.0, s'=[2.45 2.94]\n",
      "\n",
      "15. s=[2.45 2.94], a=14, r=0.0, s'=[2.43 2.9 ]\n",
      "\n",
      "16. s=[2.43 2.9 ], a=17, r=0.0, s'=[2.4  2.86]\n",
      "\n",
      "17. s=[2.4  2.86], a=5, r=0.0, s'=[2.38 2.82]\n",
      "\n",
      "18. s=[2.38 2.82], a=13, r=0.0, s'=[2.35 2.78]\n",
      "\n",
      "19. s=[2.35 2.78], a=8, r=0.0, s'=[2.32 2.73]\n",
      "\n",
      "20. s=[2.32 2.73], a=9, r=0.0, s'=[2.29 2.69]\n",
      "\n",
      "21. s=[2.29 2.69], a=20, r=0.0, s'=[2.25 2.64]\n",
      "\n",
      "22. s=[2.25 2.64], a=19, r=0.0, s'=[2.21 2.59]\n",
      "\n",
      "23. s=[2.21 2.59], a=16, r=0.0, s'=[2.15 2.55]\n",
      "\n",
      "24. s=[2.15 2.55], a=19, r=0.0, s'=[2.1 2.5]\n",
      "\n",
      "25. s=[2.1 2.5], a=5, r=0.0, s'=[2.04 2.46]\n",
      "\n",
      "26. s=[2.04 2.46], a=15, r=0.0, s'=[1.98 2.41]\n",
      "\n",
      "27. s=[1.98 2.41], a=15, r=0.0, s'=[1.92 2.36]\n",
      "\n",
      "28. s=[1.92 2.36], a=0, r=0.0, s'=[1.86 2.3 ]\n",
      "\n",
      "29. s=[1.86 2.3 ], a=18, r=0.0, s'=[1.79 2.24]\n",
      "\n",
      "30. s=[1.79 2.24], a=3, r=0.0, s'=[1.73 2.18]\n",
      "\n",
      "31. s=[1.73 2.18], a=17, r=0.0, s'=[1.67 2.11]\n",
      "\n",
      "32. s=[1.67 2.11], a=19, r=0.0, s'=[1.6  2.04]\n",
      "\n",
      "33. s=[1.6  2.04], a=19, r=0.0, s'=[1.53 1.96]\n",
      "\n",
      "34. s=[1.53 1.96], a=19, r=0.0, s'=[1.45 1.88]\n",
      "\n",
      "35. s=[1.45 1.88], a=14, r=0.0, s'=[1.38 1.78]\n",
      "\n",
      "36. s=[1.38 1.78], a=7, r=0.0, s'=[1.32 1.68]\n",
      "\n",
      "37. s=[1.32 1.68], a=0, r=0.0, s'=[1.25 1.56]\n",
      "\n",
      "38. s=[1.25 1.56], a=1, r=0.0, s'=[1.2  1.44]\n",
      "\n",
      "39. s=[1.2  1.44], a=9, r=0.434482, s'=[1.14 1.31]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# set seed of rng (for reproducibility of the results)\n",
    "n_time_steps = 40 # steps of each episode\n",
    "\n",
    "# create environment and reset it to a random initial state\n",
    "env=QubitEnv(n_time_steps,seed)\n",
    "env.reset()\n",
    "\n",
    "done=False\n",
    "j=0\n",
    "while j < n_time_steps:\n",
    "    \n",
    "    # pick a random action\n",
    "    action=np.random.choice(env.actions) # equiprobable policy\n",
    "    \n",
    "    # take an environment step\n",
    "    state=env.state.copy()\n",
    "    state_p, reward, done = env.step(action)\n",
    "    \n",
    "    print(\"{}. s={}, a={}, r={}, s'={}\\n\".format(j, state, action, np.round(reward,6), state_p))\n",
    "    \n",
    "    j+=1\n",
    "    \n",
    "    if done:\n",
    "        print('\\nreached terminal state!')\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us now define the exact CD protocol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "exact_CD_protocol = lambda t: 0.5 * env.h_t_prime(t) / (env.Delta**2 + env.h_t(t)**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we find the best approximation to the exact CD protocol, within the available action space. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# reset environment\n",
    "env.reset()\n",
    "# preallocate arrays for approximate CD actions and the approximate CD protocol\n",
    "CD_actions_t = np.zeros(env.n_time_steps, dtype=int)\n",
    "CD_protocol_t = np.zeros(env.n_time_steps,)\n",
    "\n",
    "for time_step in range(env.n_time_steps):\n",
    "\n",
    "    # construct exact CD drive\n",
    "    drive = env.h_t(env.dt*time_step)\n",
    "    CD_drive = 0.5*env.Delta * env.h_t_prime(env.dt*time_step) / (env.Delta**2 + drive**2)\n",
    "\n",
    "    # find action that gives closes value to theory CD protocol\n",
    "    action = np.argmin( np.abs(env.CD_drive + env.delta_h*env.action_space - CD_drive) )\n",
    "    \n",
    "    # take an environment step with approximate CD action\n",
    "    state[:], reward, _ = env.step(action)\n",
    "    # compute instantaneous fidelity\n",
    "    fidelity = np.abs( env.psi_target.conj().dot(env.psi)  )**2 \n",
    "\n",
    "    # record approximate CD action and protocol\n",
    "    CD_actions_t[time_step] = action\n",
    "    CD_protocol_t[time_step]=env.CD_drive    \n",
    "\n",
    "# store reward\n",
    "reward_CD_approx = reward\n",
    "\n",
    "# plot approximate CD protocol\n",
    "times = np.arange(env.n_time_steps)*env.dt\n",
    "plt.step(times, CD_protocol_t, '.-b', where='pre', label='discretized CD, $r_T={0:0.3f}$'.format(reward_CD_approx) )\n",
    "plt.plot(times, exact_CD_protocol(times),'--r', label='exact CD, $r_T=\\infty$' )\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gNPlNyN_2tlT"
   },
   "source": [
    "## Policy Gradient Implementation\n",
    "\n",
    "The implementation of the PG algorithm proceeds as follows:\n",
    "\n",
    "1. Define the a SoftMax model for the discrete policy $\\pi_\\theta$.\n",
    "2. Define the pseudo loss function to easily compute $\\nabla_\\theta J(\\theta)$.\n",
    "3. Define generalized gradient descent optimizer.\n",
    "4. Define the PG training loop and train the policy.\n",
    "\n",
    "*Note:* if you are familiar with solving the MNIST problem, you will recognize many of the steps used to construct and train the neural network. What is different here is the training algorithm.\n",
    "\n",
    "### Define a SoftMax model for the discrete policy $\\pi_\\theta$\n",
    "\n",
    "Use JAX to construct a feed-forward fully-connected deep neural network with neuron acrchitecture $(M_s, 512, |\\mathcal{A}|)$, where there are $512$ ($256$) neurons in the first (second) hidden layer, respectively, and $M_s$ and $|\\mathcal{A}|$ define the input and output sizes.\n",
    "\n",
    "The input data into the neural network should have the shape `input_shape = (-1, n_time_steps, M_s)`, where `M_s` is the number of features/components in the RL state $s=(\\theta,\\varphi)$. The output data should have the shape `output_shape = (-1, n_time_steps, abs_A)`, where `abs_A`$=|\\mathcal{A}|$. In this way, we can use the neural network to process simultaneously all time steps and MC samples, generated in a single training iteration. \n",
    "\n",
    "Check explicitly the output shape and test that the network runs on some fake data (e.g. a small batch of vectors of ones with the appropriate shape). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X8s8-3P12tlT",
    "outputId": "82d46569-7732-4ebb-b0a1-f55ed6bd1076"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "output shape of the policy network is (-1, 40, 21).\n",
      "\n",
      "(3, 40, 21)\n"
     ]
    }
   ],
   "source": [
    "import jax.numpy as jnp # jax's numpy version with GPU support\n",
    "from jax import random # used to define a RNG key to control the random input in JAX\n",
    "from jax.example_libraries import stax # neural network library\n",
    "from jax.example_libraries.stax import Dense, Relu, LogSoftmax # neural network layers\n",
    "\n",
    "# set key for the RNG (see JAX docs)\n",
    "rng = random.PRNGKey(seed)\n",
    "\n",
    "# define functions which initialize the parameters and evaluate the model\n",
    "initialize_params, predict = stax.serial(\n",
    "                                            ### fully connected DNN\n",
    "                                            Dense(512), # 512 hidden neurons\n",
    "                                            Relu,\n",
    "                                            #Dense(256), # 256 hidden neurons\n",
    "                                            #Relu,\n",
    "                                            #Dense(128), # 128 hidden neurons\n",
    "                                            #Relu,\n",
    "                                            Dense(env.n_actions), # 4 output neurons\n",
    "                                            LogSoftmax # NB: computes the log-probability\n",
    "                                        )\n",
    "\n",
    "# initialize the model parameters\n",
    "input_shape = (-1,env.n_time_steps,2) # -1: number of MC points, number of time steps, size of state vector\n",
    "output_shape, inital_params = initialize_params(rng, input_shape) # fcc layer 28x28 pixes in each image\n",
    "\n",
    "print('\\noutput shape of the policy network is {}.\\n'.format(output_shape))\n",
    "\n",
    "\n",
    "# test network\n",
    "states=np.ones((3,env.n_time_steps,2), dtype=np.float32)\n",
    "\n",
    "predictions = predict(inital_params, states)\n",
    "# check the output shape\n",
    "print(predictions.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "343Vdvxv2tlT"
   },
   "source": [
    "### Define the pseudo loss function to easily compute $\\nabla_\\theta J(\\theta)$\n",
    "\n",
    "REINFORCE allows to define a scalar pseudoloss function, whose gradients give $\\nabla_\\theta J(\\theta)$. Note that this pseudoloss does ***NOT*** correspond to the RL objective $J(\\theta)$: the difference stems from the fact that the two operations of taking the derivative and performing the MC approximation are not interchangeable (do you see why?).  \n",
    "\n",
    "$$\n",
    "J_\\mathrm{pseudo}(\\theta) = \n",
    "\\frac{1}{N}\\sum_{j=1}^N \\sum_{t=1}^T \n",
    "\\log \\pi_\\theta(a^j_t|s^j_t) \n",
    "\\left[\n",
    "\\sum_{t'=t}^T \\left(r(a^j_{t'}|s^j_{t'}) - b_t \\right)\n",
    "-\\frac{\\beta^{-1}}{2}\\sum_{t'=1}^T \\log \\pi_\\theta(a^j_{t'}|s^j_{t'}) \n",
    "\\right],\\qquad \n",
    "b_t = \\frac{1}{N}\\sum_{j=1}^N G_t(\\tau_j).\n",
    "$$\n",
    "The baseline is a sample average of the reward-to-go (return) from time step $t$ onwards: $G_t(\\tau_j) = \\sum_{t'=t}^T r(s^j_{t'},s^j_{t'})$ .\n",
    "\n",
    "Because we will be doing gradient **a**scent, do **NOT** forget to add an extra minus sign to the output ot the pseudoloss (or else your agent will end up minimizing the return). \n",
    "\n",
    "Below, we also add an L2 regularizer to the pseudoloss function to prevent overfitting. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "LmTcCdqQ2tlU"
   },
   "outputs": [],
   "source": [
    "### define loss and accuracy functions\n",
    "\n",
    "from jax import grad\n",
    "from jax.tree_util import tree_flatten # jax params are stored as nested tuples; use this to manipulate tuples\n",
    "\n",
    "\n",
    "def l2_regularizer(params,lmbda=1E-3):\n",
    "    \"\"\"\n",
    "    Define l2 regularizer: $\\lambda \\ sum_j ||theta_j||^2 $ for every parameter in the model $\\theta_j$\n",
    "    \n",
    "    \"\"\"\n",
    "    return lmbda*jnp.sum(jnp.array([jnp.sum(jnp.abs(theta)**2) for theta in tree_flatten(params)[0] ]))\n",
    "\n",
    "def policy_entropy_pseudo_loss(preds_select,beta_inv=1E-1):\n",
    "    ent_max = env.n_time_steps*jnp.log(env.n_actions)\n",
    "    return -beta_inv*0.5*jnp.sum(preds_select,axis=1)**2 / ent_max\n",
    "\n",
    "def policy_pseudo_loss(preds_select,returns,baseline):\n",
    "    #return jnp.sum(preds_select * (returns - baseline), axis=1)\n",
    "    return jnp.sum(preds_select * (returns - baseline), axis=1)\n",
    "\n",
    "def pseudo_loss(params, trajectory_batch):\n",
    "    \"\"\"\n",
    "    Define the pseudo loss function for policy gradient. \n",
    "    \n",
    "    params: object(jax pytree):\n",
    "        parameters of the deep policy network.\n",
    "    trajectory_batch: tuple (states, actions, returns) containing the RL states, actions and returns (not the rewards!): \n",
    "        states: np.array of size (N_MC, env.n_time_steps,2)\n",
    "        actions: np.array of size (N_MC, env.n_time_steps)\n",
    "        returns: np.array of size (N_MC, env.n_time_steps)\n",
    "    \n",
    "    Returns:\n",
    "        -J_{pseudo}(\\theta)\n",
    "\n",
    "    \"\"\"\n",
    "    # extract data from the batch\n",
    "    states, actions, returns = trajectory_batch\n",
    "    # compute policy predictions\n",
    "    preds = predict(params, states)\n",
    "    # combute the baseline\n",
    "    baseline = jnp.mean(returns, axis=0)\n",
    "    # select those values of the policy along the action trajectory\n",
    "    preds_select = jnp.take_along_axis(preds, jnp.expand_dims(actions, axis=2), axis=2).squeeze()\n",
    "    # return negative pseudo loss function (want to maximize reward with gradient DEscent)\n",
    "    return -jnp.mean(policy_pseudo_loss(preds_select,returns,baseline) + policy_entropy_pseudo_loss(preds_select)) + l2_regularizer(params)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "quxCV2lm2tlU"
   },
   "source": [
    "### Define generalized gradient descent optimizer\n",
    "\n",
    "Define the optimizer and the `update` function which computes the gradient o the pseudo-loss function and performs the update. \n",
    "\n",
    "We use the Adam optimizer here with `step_size = 0.001` and the rest of the parameters have default values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "nVKex_mp2tlU"
   },
   "outputs": [],
   "source": [
    "### define generalized gradient descent optimizer and a function to update model parameters\n",
    "\n",
    "from jax.example_libraries import optimizers # gradient descent optimizers\n",
    "from jax import jit\n",
    "\n",
    "step_size = 0.001 # step size or learning rate \n",
    "\n",
    "# compute optimizer functions\n",
    "opt_init, opt_update, get_params = optimizers.adam(step_size)\n",
    "\n",
    "\n",
    "# define function which updates the parameters using the change computed by the optimizer\n",
    "@jit # Just In Time compilation speeds up the code; requires to use jnp everywhere; remove when debugging\n",
    "def update(i, opt_state, batch):\n",
    "    \"\"\"\n",
    "    i: int,\n",
    "        counter to count how many update steps we have performed\n",
    "    opt_state: object,\n",
    "        the state of the optimizer\n",
    "    batch: np.array\n",
    "        batch containing the data used to update the model\n",
    "        \n",
    "    Returns: \n",
    "    opt_state: object,\n",
    "        the new state of the optimizer\n",
    "        \n",
    "    \"\"\"\n",
    "    # get current parameters of the model\n",
    "    current_params = get_params(opt_state)\n",
    "    # compute gradients\n",
    "    grad_params = grad(pseudo_loss)(current_params, batch)\n",
    "    # use the optimizer to perform the update using opt_update\n",
    "    return opt_update(i, grad_params, opt_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lVYUTo0-2tlU"
   },
   "source": [
    "### Define the PG training loop and train the policy\n",
    "\n",
    "Finally, we implement the REINFORCE algorithm for policy gradient. \n",
    "\n",
    "Follow the steps below:\n",
    "\n",
    "1. Preallocate variables\n",
    "    * Define the number of episodes `N_episodes`, and the batch size `N_MC`.\n",
    "    * Preallocate arrays for the current `state`, and the `states`, `actions`, `returns` triple which defines the trajectory batch. \n",
    "    * Preallocate arrays to compute the `mean_final_reward`, `std_final_reward`, `min_final_reward`, and , `max_final_reward`.\n",
    "2. Initialize the optimizer using the `opt_init` function. \n",
    "3. Loop over the episodes; for every episode:\n",
    "\n",
    "    3.1 get the current Network parameters\n",
    "    \n",
    "    3.2 loop to collect MC samples\n",
    "        \n",
    "      3.2.1 reset the `env` and roll out the policy until the episode is over; collect the trajectory data\n",
    "    \n",
    "      3.2.2 compute the returns (rewards to go)\n",
    "    \n",
    "    3.3 compile the PG data into a trajectory batch\n",
    "    \n",
    "    3.4 use the `update` function to update the network parameters\n",
    "    \n",
    "    3.5 print instantaneous performance\n",
    "\n",
    "***Note*** that training can take a considerably long time with the default hyperparameters. \n",
    "\n",
    "***Note*** also that, despite fixing the seed of the random number generator, you may not be able to reproduce *precisely* the same plots from the paper since different architectures use different arithmetic instructions.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GDG845ox2tlV",
    "outputId": "1212c2d9-56db-49ec-a61c-dc7070fa2e94",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting training...\n",
      "\n",
      "loss comparison -0.047066927 5.959206 0.045099996\n",
      "new optimal trajectory encountered:\n",
      "episode 0 in 2.71 sec\n",
      "mean reward: 0.560048\n",
      "return standard deviation: 0.251699\n",
      "min return: 0.192190; max return: 1.721746\n",
      "\n",
      "max ever return: 1.721746\n",
      "loss comparison -0.09422326 5.9626207 0.044904936\n",
      "episode 1 in 1.61 sec\n",
      "mean reward: 0.609364\n",
      "return standard deviation: 0.252082\n",
      "min return: 0.192480; max return: 1.627664\n",
      "\n",
      "max ever return: 1.721746\n",
      "loss comparison -0.14931512 5.9119935 0.04471594\n",
      "episode 2 in 1.48 sec\n",
      "mean reward: 0.708414\n",
      "return standard deviation: 0.276112\n",
      "min return: 0.207435; max return: 1.711585\n",
      "\n",
      "max ever return: 1.721746\n",
      "loss comparison -0.22865114 5.9085917 0.04454291\n",
      "episode 3 in 1.94 sec\n",
      "mean reward: 0.725997\n",
      "return standard deviation: 0.284031\n",
      "min return: 0.240442; max return: 1.622615\n",
      "\n",
      "max ever return: 1.721746\n",
      "loss comparison -0.29791892 5.8503656 0.04439353\n",
      "new optimal trajectory encountered:\n",
      "episode 4 in 2.15 sec\n",
      "mean reward: 0.810715\n",
      "return standard deviation: 0.302209\n",
      "min return: 0.201160; max return: 1.942948\n",
      "\n",
      "max ever return: 1.942948\n",
      "loss comparison -0.3410097 5.8097534 0.044260472\n",
      "episode 5 in 1.79 sec\n",
      "mean reward: 0.862725\n",
      "return standard deviation: 0.278905\n",
      "min return: 0.282096; max return: 1.580868\n",
      "\n",
      "max ever return: 1.942948\n",
      "loss comparison -0.34454846 5.725733 0.04414938\n",
      "new optimal trajectory encountered:\n",
      "episode 6 in 1.88 sec\n",
      "mean reward: 0.960851\n",
      "return standard deviation: 0.274457\n",
      "min return: 0.350058; max return: 2.031909\n",
      "\n",
      "max ever return: 2.031909\n",
      "loss comparison -0.31284606 5.7095613 0.044058446\n",
      "episode 7 in 1.82 sec\n",
      "mean reward: 0.982506\n",
      "return standard deviation: 0.266225\n",
      "min return: 0.406750; max return: 1.791998\n",
      "\n",
      "max ever return: 2.031909\n",
      "loss comparison -0.1751427 5.6043086 0.043978497\n",
      "episode 8 in 1.85 sec\n",
      "mean reward: 1.028175\n",
      "return standard deviation: 0.241947\n",
      "min return: 0.350133; max return: 1.793404\n",
      "\n",
      "max ever return: 2.031909\n",
      "loss comparison -0.16342032 5.5344605 0.043901417\n",
      "new optimal trajectory encountered:\n",
      "episode 9 in 1.82 sec\n",
      "mean reward: 1.059459\n",
      "return standard deviation: 0.240401\n",
      "min return: 0.340974; max return: 2.048475\n",
      "\n",
      "max ever return: 2.048475\n",
      "loss comparison -0.016717792 5.511991 0.04383141\n",
      "episode 10 in 1.86 sec\n",
      "mean reward: 1.083263\n",
      "return standard deviation: 0.224109\n",
      "min return: 0.520294; max return: 1.853624\n",
      "\n",
      "max ever return: 2.048475\n",
      "loss comparison 0.05163455 5.446027 0.043757454\n",
      "episode 11 in 1.77 sec\n",
      "mean reward: 1.039194\n",
      "return standard deviation: 0.215423\n",
      "min return: 0.417940; max return: 1.651589\n",
      "\n",
      "max ever return: 2.048475\n",
      "loss comparison 0.28864858 5.3412733 0.04367516\n",
      "episode 12 in 1.89 sec\n",
      "mean reward: 1.043820\n",
      "return standard deviation: 0.229612\n",
      "min return: 0.409960; max return: 1.978707\n",
      "\n",
      "max ever return: 2.048475\n",
      "loss comparison 0.31076884 5.2896285 0.04357589\n",
      "episode 13 in 2.01 sec\n",
      "mean reward: 1.029563\n",
      "return standard deviation: 0.220950\n",
      "min return: 0.484604; max return: 1.939153\n",
      "\n",
      "max ever return: 2.048475\n",
      "loss comparison 0.32118905 5.334865 0.0434591\n",
      "episode 14 in 1.89 sec\n",
      "mean reward: 1.036178\n",
      "return standard deviation: 0.215867\n",
      "min return: 0.509177; max return: 1.702945\n",
      "\n",
      "max ever return: 2.048475\n",
      "loss comparison 0.29634488 5.301023 0.043326948\n",
      "episode 15 in 1.74 sec\n",
      "mean reward: 1.046766\n",
      "return standard deviation: 0.210397\n",
      "min return: 0.467850; max return: 1.598427\n",
      "\n",
      "max ever return: 2.048475\n",
      "loss comparison 0.35196015 5.2845616 0.043180913\n",
      "episode 16 in 1.70 sec\n",
      "mean reward: 1.026269\n",
      "return standard deviation: 0.223651\n",
      "min return: 0.348912; max return: 1.713726\n",
      "\n",
      "max ever return: 2.048475\n",
      "loss comparison 0.4322231 5.342804 0.04302292\n",
      "episode 17 in 1.85 sec\n",
      "mean reward: 1.057562\n",
      "return standard deviation: 0.227903\n",
      "min return: 0.459102; max return: 1.865307\n",
      "\n",
      "max ever return: 2.048475\n",
      "loss comparison 0.2557363 5.3109 0.042851802\n",
      "episode 18 in 1.77 sec\n",
      "mean reward: 1.036961\n",
      "return standard deviation: 0.204336\n",
      "min return: 0.526653; max return: 1.587833\n",
      "\n",
      "max ever return: 2.048475\n",
      "loss comparison 0.28987807 5.293256 0.042677157\n",
      "episode 19 in 1.73 sec\n",
      "mean reward: 1.021886\n",
      "return standard deviation: 0.215779\n",
      "min return: 0.488348; max return: 1.784956\n",
      "\n",
      "max ever return: 2.048475\n",
      "loss comparison 0.2657045 5.3533854 0.042501412\n",
      "episode 20 in 1.87 sec\n",
      "mean reward: 1.067920\n",
      "return standard deviation: 0.232134\n",
      "min return: 0.492436; max return: 1.874832\n",
      "\n",
      "max ever return: 2.048475\n",
      "loss comparison 0.23562962 5.393904 0.04232755\n",
      "episode 21 in 1.91 sec\n",
      "mean reward: 1.070311\n",
      "return standard deviation: 0.225136\n",
      "min return: 0.551007; max return: 1.820454\n",
      "\n",
      "max ever return: 2.048475\n",
      "loss comparison 0.10965815 5.366707 0.04215277\n",
      "episode 22 in 1.70 sec\n",
      "mean reward: 1.078216\n",
      "return standard deviation: 0.215313\n",
      "min return: 0.408730; max return: 1.847711\n",
      "\n",
      "max ever return: 2.048475\n",
      "loss comparison 0.055928558 5.408507 0.04198736\n",
      "episode 23 in 1.95 sec\n",
      "mean reward: 1.089025\n",
      "return standard deviation: 0.221960\n",
      "min return: 0.544365; max return: 1.971312\n",
      "\n",
      "max ever return: 2.048475\n",
      "loss comparison 0.04863012 5.416541 0.041829094\n",
      "episode 24 in 1.88 sec\n",
      "mean reward: 1.085235\n",
      "return standard deviation: 0.235826\n",
      "min return: 0.442160; max return: 1.948397\n",
      "\n",
      "max ever return: 2.048475\n",
      "loss comparison -0.094394416 5.4902825 0.041678835\n",
      "episode 25 in 1.74 sec\n",
      "mean reward: 1.092280\n",
      "return standard deviation: 0.219259\n",
      "min return: 0.557892; max return: 1.722064\n",
      "\n",
      "max ever return: 2.048475\n",
      "loss comparison 0.044538155 5.4647007 0.041538578\n",
      "episode 26 in 1.75 sec\n",
      "mean reward: 1.090760\n",
      "return standard deviation: 0.219997\n",
      "min return: 0.390493; max return: 1.760383\n",
      "\n",
      "max ever return: 2.048475\n",
      "loss comparison -0.11636531 5.493966 0.041400522\n",
      "episode 27 in 1.89 sec\n",
      "mean reward: 1.073143\n",
      "return standard deviation: 0.200152\n",
      "min return: 0.471630; max return: 1.615683\n",
      "\n",
      "max ever return: 2.048475\n",
      "loss comparison -0.117872 5.4708357 0.041271254\n",
      "episode 28 in 1.94 sec\n",
      "mean reward: 1.091755\n",
      "return standard deviation: 0.221496\n",
      "min return: 0.474255; max return: 1.750824\n",
      "\n",
      "max ever return: 2.048475\n",
      "loss comparison -0.016065001 5.4669495 0.0411534\n",
      "episode 29 in 1.75 sec\n",
      "mean reward: 1.097164\n",
      "return standard deviation: 0.241287\n",
      "min return: 0.446575; max return: 2.040245\n",
      "\n",
      "max ever return: 2.048475\n",
      "loss comparison -0.102238595 5.487601 0.04103956\n",
      "episode 30 in 1.73 sec\n",
      "mean reward: 1.079293\n",
      "return standard deviation: 0.230852\n",
      "min return: 0.519388; max return: 1.804425\n",
      "\n",
      "max ever return: 2.048475\n",
      "loss comparison -0.14279974 5.5279326 0.040933445\n",
      "episode 31 in 1.88 sec\n",
      "mean reward: 1.095948\n",
      "return standard deviation: 0.221157\n",
      "min return: 0.568648; max return: 1.806142\n",
      "\n",
      "max ever return: 2.048475\n",
      "loss comparison -0.109169334 5.500738 0.040835243\n",
      "new optimal trajectory encountered:\n",
      "episode 32 in 1.94 sec\n",
      "mean reward: 1.102274\n",
      "return standard deviation: 0.255017\n",
      "min return: 0.490804; max return: 2.361594\n",
      "\n",
      "max ever return: 2.361594\n",
      "loss comparison -0.1582624 5.472325 0.040746484\n",
      "episode 33 in 1.67 sec\n",
      "mean reward: 1.120001\n",
      "return standard deviation: 0.259972\n",
      "min return: 0.400019; max return: 1.978318\n",
      "\n",
      "max ever return: 2.361594\n",
      "loss comparison -0.11816287 5.495049 0.040667396\n",
      "episode 34 in 1.67 sec\n",
      "mean reward: 1.125425\n",
      "return standard deviation: 0.239065\n",
      "min return: 0.401827; max return: 1.646809\n",
      "\n",
      "max ever return: 2.361594\n",
      "loss comparison -0.14675033 5.4854884 0.04059366\n",
      "episode 35 in 1.73 sec\n",
      "mean reward: 1.102610\n",
      "return standard deviation: 0.224573\n",
      "min return: 0.422887; max return: 1.738054\n",
      "\n",
      "max ever return: 2.361594\n",
      "loss comparison -0.026526898 5.4557095 0.040526293\n",
      "episode 36 in 1.69 sec\n",
      "mean reward: 1.130785\n",
      "return standard deviation: 0.249674\n",
      "min return: 0.414610; max return: 1.936936\n",
      "\n",
      "max ever return: 2.361594\n",
      "loss comparison -0.067249626 5.432763 0.040462203\n",
      "episode 37 in 1.64 sec\n",
      "mean reward: 1.114302\n",
      "return standard deviation: 0.233205\n",
      "min return: 0.519419; max return: 1.879654\n",
      "\n",
      "max ever return: 2.361594\n",
      "loss comparison -0.15262753 5.5094643 0.040400892\n",
      "new optimal trajectory encountered:\n",
      "episode 38 in 1.69 sec\n",
      "mean reward: 1.100186\n",
      "return standard deviation: 0.272731\n",
      "min return: 0.487800; max return: 2.772496\n",
      "\n",
      "max ever return: 2.772496\n",
      "loss comparison -0.074567035 5.462742 0.040343747\n",
      "episode 39 in 1.69 sec\n",
      "mean reward: 1.130105\n",
      "return standard deviation: 0.260629\n",
      "min return: 0.519709; max return: 2.074994\n",
      "\n",
      "max ever return: 2.772496\n",
      "loss comparison -0.08914149 5.4506917 0.04029145\n",
      "episode 40 in 1.84 sec\n",
      "mean reward: 1.153718\n",
      "return standard deviation: 0.260715\n",
      "min return: 0.362149; max return: 1.837097\n",
      "\n",
      "max ever return: 2.772496\n",
      "loss comparison -0.018417597 5.3995957 0.040243067\n",
      "episode 41 in 1.71 sec\n",
      "mean reward: 1.142602\n",
      "return standard deviation: 0.241318\n",
      "min return: 0.490267; max return: 1.949414\n",
      "\n",
      "max ever return: 2.772496\n",
      "loss comparison -0.014775753 5.402637 0.040196244\n",
      "episode 42 in 1.75 sec\n",
      "mean reward: 1.149104\n",
      "return standard deviation: 0.248068\n",
      "min return: 0.467424; max return: 1.899113\n",
      "\n",
      "max ever return: 2.772496\n",
      "loss comparison 0.09825647 5.426089 0.040150523\n",
      "episode 43 in 1.94 sec\n",
      "mean reward: 1.154330\n",
      "return standard deviation: 0.256911\n",
      "min return: 0.399051; max return: 1.783521\n",
      "\n",
      "max ever return: 2.772496\n",
      "loss comparison -0.07222712 5.437533 0.04010264\n",
      "episode 44 in 1.82 sec\n",
      "mean reward: 1.134758\n",
      "return standard deviation: 0.253998\n",
      "min return: 0.524884; max return: 1.779321\n",
      "\n",
      "max ever return: 2.772496\n",
      "loss comparison -0.027505279 5.433677 0.04005965\n",
      "episode 45 in 1.90 sec\n",
      "mean reward: 1.136216\n",
      "return standard deviation: 0.256333\n",
      "min return: 0.475081; max return: 1.890691\n",
      "\n",
      "max ever return: 2.772496\n",
      "loss comparison 0.011336446 5.422106 0.04001734\n",
      "episode 46 in 1.82 sec\n",
      "mean reward: 1.149860\n",
      "return standard deviation: 0.272042\n",
      "min return: 0.536426; max return: 2.204825\n",
      "\n",
      "max ever return: 2.772496\n",
      "loss comparison -0.07174778 5.452834 0.039976746\n",
      "episode 47 in 1.74 sec\n",
      "mean reward: 1.180622\n",
      "return standard deviation: 0.256167\n",
      "min return: 0.439634; max return: 1.911816\n",
      "\n",
      "max ever return: 2.772496\n",
      "loss comparison -0.22999223 5.4681654 0.039938632\n",
      "episode 48 in 1.77 sec\n",
      "mean reward: 1.133694\n",
      "return standard deviation: 0.264817\n",
      "min return: 0.408485; max return: 2.158453\n",
      "\n",
      "max ever return: 2.772496\n",
      "loss comparison -0.1685059 5.463855 0.039909925\n",
      "episode 49 in 1.77 sec\n",
      "mean reward: 1.156027\n",
      "return standard deviation: 0.287757\n",
      "min return: 0.510238; max return: 2.204057\n",
      "\n",
      "max ever return: 2.772496\n",
      "loss comparison -0.061009556 5.462856 0.0398894\n",
      "episode 50 in 1.75 sec\n",
      "mean reward: 1.171499\n",
      "return standard deviation: 0.264766\n",
      "min return: 0.453306; max return: 2.073220\n",
      "\n",
      "max ever return: 2.772496\n",
      "loss comparison -0.07882881 5.456576 0.03987199\n",
      "episode 51 in 1.66 sec\n",
      "mean reward: 1.160294\n",
      "return standard deviation: 0.278553\n",
      "min return: 0.452454; max return: 2.182664\n",
      "\n",
      "max ever return: 2.772496\n",
      "loss comparison -0.19781548 5.5042467 0.039858177\n",
      "episode 52 in 1.74 sec\n",
      "mean reward: 1.188790\n",
      "return standard deviation: 0.296234\n",
      "min return: 0.584051; max return: 2.235021\n",
      "\n",
      "max ever return: 2.772496\n",
      "loss comparison -0.09114638 5.4597597 0.0398553\n",
      "episode 53 in 1.69 sec\n",
      "mean reward: 1.161067\n",
      "return standard deviation: 0.249442\n",
      "min return: 0.501350; max return: 1.782443\n",
      "\n",
      "max ever return: 2.772496\n",
      "loss comparison -0.22124648 5.506309 0.039856076\n",
      "episode 54 in 1.67 sec\n",
      "mean reward: 1.196438\n",
      "return standard deviation: 0.279915\n",
      "min return: 0.531640; max return: 2.141707\n",
      "\n",
      "max ever return: 2.772496\n",
      "loss comparison -0.16548747 5.5014725 0.039862517\n",
      "episode 55 in 1.65 sec\n",
      "mean reward: 1.185672\n",
      "return standard deviation: 0.271078\n",
      "min return: 0.451111; max return: 2.106349\n",
      "\n",
      "max ever return: 2.772496\n",
      "loss comparison -0.10326901 5.497137 0.039873164\n",
      "new optimal trajectory encountered:\n",
      "episode 56 in 1.68 sec\n",
      "mean reward: 1.180148\n",
      "return standard deviation: 0.301525\n",
      "min return: 0.500512; max return: 2.853757\n",
      "\n",
      "max ever return: 2.853757\n",
      "loss comparison -0.017749459 5.441081 0.03988912\n",
      "episode 57 in 1.83 sec\n",
      "mean reward: 1.185440\n",
      "return standard deviation: 0.264475\n",
      "min return: 0.613175; max return: 2.052202\n",
      "\n",
      "max ever return: 2.853757\n",
      "loss comparison -0.19248259 5.484613 0.039908245\n",
      "episode 58 in 1.83 sec\n",
      "mean reward: 1.192858\n",
      "return standard deviation: 0.266125\n",
      "min return: 0.491165; max return: 1.862154\n",
      "\n",
      "max ever return: 2.853757\n",
      "loss comparison -0.19240773 5.513828 0.03992975\n",
      "episode 59 in 1.75 sec\n",
      "mean reward: 1.204550\n",
      "return standard deviation: 0.312878\n",
      "min return: 0.494850; max return: 2.296499\n",
      "\n",
      "max ever return: 2.853757\n",
      "loss comparison -0.21151885 5.504918 0.03995527\n",
      "episode 60 in 1.79 sec\n",
      "mean reward: 1.212339\n",
      "return standard deviation: 0.308408\n",
      "min return: 0.476862; max return: 2.472442\n",
      "\n",
      "max ever return: 2.853757\n",
      "loss comparison -0.1826044 5.515864 0.039990813\n",
      "episode 61 in 1.68 sec\n",
      "mean reward: 1.221415\n",
      "return standard deviation: 0.284462\n",
      "min return: 0.507731; max return: 1.966067\n",
      "\n",
      "max ever return: 2.853757\n",
      "loss comparison -0.05349779 5.4705973 0.040031955\n",
      "episode 62 in 1.77 sec\n",
      "mean reward: 1.205391\n",
      "return standard deviation: 0.243604\n",
      "min return: 0.343506; max return: 1.927262\n",
      "\n",
      "max ever return: 2.853757\n",
      "loss comparison -0.25417754 5.5370426 0.04007485\n",
      "episode 63 in 1.72 sec\n",
      "mean reward: 1.221183\n",
      "return standard deviation: 0.289450\n",
      "min return: 0.524364; max return: 2.281958\n",
      "\n",
      "max ever return: 2.853757\n",
      "loss comparison -0.14026254 5.487939 0.0401225\n",
      "episode 64 in 1.78 sec\n",
      "mean reward: 1.251259\n",
      "return standard deviation: 0.257044\n",
      "min return: 0.684273; max return: 1.931819\n",
      "\n",
      "max ever return: 2.853757\n",
      "loss comparison -0.13675356 5.466658 0.040177837\n",
      "episode 65 in 1.79 sec\n",
      "mean reward: 1.222208\n",
      "return standard deviation: 0.265476\n",
      "min return: 0.571526; max return: 2.039902\n",
      "\n",
      "max ever return: 2.853757\n",
      "loss comparison -0.23315358 5.4789567 0.040237483\n",
      "episode 66 in 1.69 sec\n",
      "mean reward: 1.248598\n",
      "return standard deviation: 0.283445\n",
      "min return: 0.520755; max return: 2.102237\n",
      "\n",
      "max ever return: 2.853757\n",
      "loss comparison -0.08890164 5.4951105 0.040307503\n",
      "episode 67 in 1.80 sec\n",
      "mean reward: 1.220758\n",
      "return standard deviation: 0.290546\n",
      "min return: 0.461791; max return: 2.323287\n",
      "\n",
      "max ever return: 2.853757\n",
      "loss comparison -0.22639188 5.4799213 0.04037685\n",
      "episode 68 in 1.80 sec\n",
      "mean reward: 1.255568\n",
      "return standard deviation: 0.283341\n",
      "min return: 0.475251; max return: 2.145527\n",
      "\n",
      "max ever return: 2.853757\n",
      "loss comparison -0.3380198 5.5016017 0.040450655\n",
      "episode 69 in 1.73 sec\n",
      "mean reward: 1.228432\n",
      "return standard deviation: 0.271401\n",
      "min return: 0.487416; max return: 2.024088\n",
      "\n",
      "max ever return: 2.853757\n",
      "loss comparison -0.25121397 5.4944625 0.040532067\n",
      "episode 70 in 1.75 sec\n",
      "mean reward: 1.241224\n",
      "return standard deviation: 0.290342\n",
      "min return: 0.476032; max return: 2.296977\n",
      "\n",
      "max ever return: 2.853757\n",
      "loss comparison -0.2779832 5.463386 0.04062369\n",
      "episode 71 in 1.74 sec\n",
      "mean reward: 1.295757\n",
      "return standard deviation: 0.296293\n",
      "min return: 0.544218; max return: 2.475522\n",
      "\n",
      "max ever return: 2.853757\n",
      "loss comparison -0.1647011 5.4706197 0.040725138\n",
      "episode 72 in 1.76 sec\n",
      "mean reward: 1.295621\n",
      "return standard deviation: 0.273514\n",
      "min return: 0.675813; max return: 2.309398\n",
      "\n",
      "max ever return: 2.853757\n",
      "loss comparison -0.2788433 5.4551077 0.040825818\n",
      "episode 73 in 1.73 sec\n",
      "mean reward: 1.256724\n",
      "return standard deviation: 0.284773\n",
      "min return: 0.534435; max return: 2.176364\n",
      "\n",
      "max ever return: 2.853757\n",
      "loss comparison -0.22870064 5.4609203 0.040931992\n",
      "episode 74 in 1.67 sec\n",
      "mean reward: 1.267956\n",
      "return standard deviation: 0.310814\n",
      "min return: 0.601235; max return: 2.177624\n",
      "\n",
      "max ever return: 2.853757\n",
      "loss comparison -0.28339344 5.4218783 0.04104407\n",
      "episode 75 in 1.83 sec\n",
      "mean reward: 1.300854\n",
      "return standard deviation: 0.296643\n",
      "min return: 0.670687; max return: 2.194545\n",
      "\n",
      "max ever return: 2.853757\n",
      "loss comparison -0.20268142 5.4238048 0.04116614\n",
      "episode 76 in 1.64 sec\n",
      "mean reward: 1.282176\n",
      "return standard deviation: 0.281253\n",
      "min return: 0.588393; max return: 2.153731\n",
      "\n",
      "max ever return: 2.853757\n",
      "loss comparison -0.14072597 5.3888645 0.04129206\n",
      "episode 77 in 1.68 sec\n",
      "mean reward: 1.278395\n",
      "return standard deviation: 0.269455\n",
      "min return: 0.565324; max return: 2.219563\n",
      "\n",
      "max ever return: 2.853757\n",
      "loss comparison -0.27853996 5.374504 0.041418187\n",
      "episode 78 in 1.79 sec\n",
      "mean reward: 1.305973\n",
      "return standard deviation: 0.295937\n",
      "min return: 0.669868; max return: 2.335293\n",
      "\n",
      "max ever return: 2.853757\n",
      "loss comparison -0.22072765 5.3706765 0.041552\n",
      "episode 79 in 1.76 sec\n",
      "mean reward: 1.317766\n",
      "return standard deviation: 0.325862\n",
      "min return: 0.566927; max return: 2.509425\n",
      "\n",
      "max ever return: 2.853757\n",
      "loss comparison -0.30729476 5.3587027 0.04169412\n",
      "episode 80 in 1.68 sec\n",
      "mean reward: 1.297740\n",
      "return standard deviation: 0.290584\n",
      "min return: 0.642202; max return: 2.161927\n",
      "\n",
      "max ever return: 2.853757\n",
      "loss comparison -0.32968295 5.329454 0.041841928\n",
      "episode 81 in 1.67 sec\n",
      "mean reward: 1.325873\n",
      "return standard deviation: 0.297078\n",
      "min return: 0.546159; max return: 2.383957\n",
      "\n",
      "max ever return: 2.853757\n",
      "loss comparison -0.28389353 5.314781 0.04199086\n",
      "episode 82 in 1.64 sec\n",
      "mean reward: 1.324692\n",
      "return standard deviation: 0.301335\n",
      "min return: 0.440317; max return: 2.178033\n",
      "\n",
      "max ever return: 2.853757\n",
      "loss comparison -0.23335564 5.3046627 0.04214696\n",
      "episode 83 in 1.67 sec\n",
      "mean reward: 1.356547\n",
      "return standard deviation: 0.311539\n",
      "min return: 0.639784; max return: 2.476902\n",
      "\n",
      "max ever return: 2.853757\n",
      "loss comparison -0.39196485 5.300437 0.04230584\n",
      "episode 84 in 1.71 sec\n",
      "mean reward: 1.378041\n",
      "return standard deviation: 0.322651\n",
      "min return: 0.536611; max return: 2.509984\n",
      "\n",
      "max ever return: 2.853757\n",
      "loss comparison -0.4330544 5.2696953 0.042473562\n",
      "episode 85 in 1.68 sec\n",
      "mean reward: 1.384602\n",
      "return standard deviation: 0.333013\n",
      "min return: 0.772549; max return: 2.546079\n",
      "\n",
      "max ever return: 2.853757\n",
      "loss comparison -0.45329538 5.262916 0.042654242\n",
      "new optimal trajectory encountered:\n",
      "episode 86 in 1.71 sec\n",
      "mean reward: 1.399275\n",
      "return standard deviation: 0.344019\n",
      "min return: 0.550307; max return: 3.139839\n",
      "\n",
      "max ever return: 3.139839\n",
      "loss comparison -0.47506487 5.2211213 0.04284411\n",
      "episode 87 in 1.70 sec\n",
      "mean reward: 1.374828\n",
      "return standard deviation: 0.342683\n",
      "min return: 0.566525; max return: 2.359027\n",
      "\n",
      "max ever return: 3.139839\n",
      "loss comparison -0.27603465 5.1822233 0.0430419\n",
      "episode 88 in 1.73 sec\n",
      "mean reward: 1.392249\n",
      "return standard deviation: 0.360415\n",
      "min return: 0.641942; max return: 2.732052\n",
      "\n",
      "max ever return: 3.139839\n",
      "loss comparison -0.56740516 5.1956615 0.043242265\n",
      "episode 89 in 1.67 sec\n",
      "mean reward: 1.393777\n",
      "return standard deviation: 0.371032\n",
      "min return: 0.628077; max return: 2.661443\n",
      "\n",
      "max ever return: 3.139839\n",
      "loss comparison -0.6511399 5.190139 0.043452404\n",
      "episode 90 in 1.70 sec\n",
      "mean reward: 1.404056\n",
      "return standard deviation: 0.362316\n",
      "min return: 0.522417; max return: 2.865246\n",
      "\n",
      "max ever return: 3.139839\n",
      "loss comparison -0.56247336 5.128533 0.04366189\n",
      "episode 91 in 1.66 sec\n",
      "mean reward: 1.460994\n",
      "return standard deviation: 0.387042\n",
      "min return: 0.602401; max return: 2.930527\n",
      "\n",
      "max ever return: 3.139839\n",
      "loss comparison -0.57469535 5.112755 0.0438778\n",
      "episode 92 in 1.70 sec\n",
      "mean reward: 1.436487\n",
      "return standard deviation: 0.316151\n",
      "min return: 0.543592; max return: 2.223495\n",
      "\n",
      "max ever return: 3.139839\n",
      "loss comparison -0.5912986 5.0178795 0.044098504\n",
      "episode 93 in 1.66 sec\n",
      "mean reward: 1.498873\n",
      "return standard deviation: 0.393160\n",
      "min return: 0.570071; max return: 2.566583\n",
      "\n",
      "max ever return: 3.139839\n",
      "loss comparison -0.61683774 5.008224 0.044331975\n",
      "episode 94 in 1.67 sec\n",
      "mean reward: 1.448327\n",
      "return standard deviation: 0.360966\n",
      "min return: 0.549028; max return: 2.587407\n",
      "\n",
      "max ever return: 3.139839\n",
      "loss comparison -0.6816454 4.9990125 0.04457294\n",
      "episode 95 in 1.67 sec\n",
      "mean reward: 1.480770\n",
      "return standard deviation: 0.401042\n",
      "min return: 0.661248; max return: 2.766220\n",
      "\n",
      "max ever return: 3.139839\n",
      "loss comparison -0.5169281 4.974564 0.044823643\n",
      "episode 96 in 1.62 sec\n",
      "mean reward: 1.408897\n",
      "return standard deviation: 0.387141\n",
      "min return: 0.678649; max return: 2.606177\n",
      "\n",
      "max ever return: 3.139839\n",
      "loss comparison -0.7979586 4.94255 0.045075223\n",
      "episode 97 in 1.68 sec\n",
      "mean reward: 1.480547\n",
      "return standard deviation: 0.367275\n",
      "min return: 0.729489; max return: 2.605273\n",
      "\n",
      "max ever return: 3.139839\n",
      "loss comparison -0.65124154 4.8625374 0.045337465\n",
      "episode 98 in 1.62 sec\n",
      "mean reward: 1.534771\n",
      "return standard deviation: 0.377519\n",
      "min return: 0.646921; max return: 2.558528\n",
      "\n",
      "max ever return: 3.139839\n",
      "loss comparison -0.7938792 4.880412 0.04560535\n",
      "episode 99 in 1.63 sec\n",
      "mean reward: 1.515180\n",
      "return standard deviation: 0.390405\n",
      "min return: 0.752113; max return: 2.917250\n",
      "\n",
      "max ever return: 3.139839\n",
      "loss comparison -0.5141177 4.8300967 0.04587551\n",
      "new optimal trajectory encountered:\n",
      "episode 100 in 1.66 sec\n",
      "mean reward: 1.553091\n",
      "return standard deviation: 0.403041\n",
      "min return: 0.796392; max return: 3.234535\n",
      "\n",
      "max ever return: 3.234535\n",
      "loss comparison -0.86485064 4.813022 0.046132497\n",
      "episode 101 in 1.67 sec\n",
      "mean reward: 1.535056\n",
      "return standard deviation: 0.404328\n",
      "min return: 0.766229; max return: 2.863955\n",
      "\n",
      "max ever return: 3.234535\n",
      "loss comparison -0.72972697 4.746399 0.04639445\n",
      "new optimal trajectory encountered:\n",
      "episode 102 in 1.65 sec\n",
      "mean reward: 1.597934\n",
      "return standard deviation: 0.400879\n",
      "min return: 0.804109; max return: 3.335934\n",
      "\n",
      "max ever return: 3.335934\n",
      "loss comparison -0.72645235 4.6978045 0.04666236\n",
      "episode 103 in 1.67 sec\n",
      "mean reward: 1.561794\n",
      "return standard deviation: 0.407805\n",
      "min return: 0.788238; max return: 3.109121\n",
      "\n",
      "max ever return: 3.335934\n",
      "loss comparison -0.75442296 4.686467 0.046939895\n",
      "new optimal trajectory encountered:\n",
      "episode 104 in 1.72 sec\n",
      "mean reward: 1.594514\n",
      "return standard deviation: 0.424993\n",
      "min return: 0.760295; max return: 3.355475\n",
      "\n",
      "max ever return: 3.355475\n",
      "loss comparison -0.80179596 4.643471 0.047212742\n",
      "episode 105 in 1.79 sec\n",
      "mean reward: 1.604829\n",
      "return standard deviation: 0.411090\n",
      "min return: 0.840794; max return: 2.960617\n",
      "\n",
      "max ever return: 3.355475\n",
      "loss comparison -0.75692856 4.609431 0.047490817\n",
      "episode 106 in 1.69 sec\n",
      "mean reward: 1.608103\n",
      "return standard deviation: 0.382506\n",
      "min return: 0.754807; max return: 2.678774\n",
      "\n",
      "max ever return: 3.355475\n",
      "loss comparison -1.0055726 4.5263 0.047766805\n",
      "episode 107 in 1.74 sec\n",
      "mean reward: 1.641951\n",
      "return standard deviation: 0.417460\n",
      "min return: 0.688921; max return: 2.987333\n",
      "\n",
      "max ever return: 3.355475\n",
      "loss comparison -0.95422685 4.5483346 0.04806104\n",
      "episode 108 in 1.71 sec\n",
      "mean reward: 1.659275\n",
      "return standard deviation: 0.424683\n",
      "min return: 0.797879; max return: 2.978258\n",
      "\n",
      "max ever return: 3.355475\n",
      "loss comparison -0.82759786 4.4762125 0.048366487\n",
      "episode 109 in 1.74 sec\n",
      "mean reward: 1.633368\n",
      "return standard deviation: 0.401154\n",
      "min return: 0.705124; max return: 3.214326\n",
      "\n",
      "max ever return: 3.355475\n",
      "loss comparison -0.8000966 4.4126277 0.04867516\n",
      "episode 110 in 1.73 sec\n",
      "mean reward: 1.727032\n",
      "return standard deviation: 0.422614\n",
      "min return: 0.801332; max return: 2.975228\n",
      "\n",
      "max ever return: 3.355475\n",
      "loss comparison -0.88433367 4.303435 0.04899243\n",
      "new optimal trajectory encountered:\n",
      "episode 111 in 1.76 sec\n",
      "mean reward: 1.777666\n",
      "return standard deviation: 0.456501\n",
      "min return: 0.879830; max return: 3.630275\n",
      "\n",
      "max ever return: 3.630275\n",
      "loss comparison -0.6955544 4.304841 0.049319673\n",
      "episode 112 in 1.69 sec\n",
      "mean reward: 1.715357\n",
      "return standard deviation: 0.419254\n",
      "min return: 0.881162; max return: 3.150327\n",
      "\n",
      "max ever return: 3.630275\n",
      "loss comparison -0.77751327 4.267549 0.04964232\n",
      "new optimal trajectory encountered:\n",
      "episode 113 in 1.65 sec\n",
      "mean reward: 1.732902\n",
      "return standard deviation: 0.503918\n",
      "min return: 0.823315; max return: 4.235255\n",
      "\n",
      "max ever return: 4.235255\n",
      "loss comparison -1.077672 4.2222605 0.049969926\n",
      "episode 114 in 1.70 sec\n",
      "mean reward: 1.776491\n",
      "return standard deviation: 0.512579\n",
      "min return: 0.840992; max return: 3.630054\n",
      "\n",
      "max ever return: 4.235255\n",
      "loss comparison -1.0527159 4.1441474 0.0503072\n",
      "episode 115 in 1.69 sec\n",
      "mean reward: 1.785170\n",
      "return standard deviation: 0.465965\n",
      "min return: 0.779547; max return: 3.489420\n",
      "\n",
      "max ever return: 4.235255\n",
      "loss comparison -0.85987216 4.07801 0.05065358\n",
      "episode 116 in 1.70 sec\n",
      "mean reward: 1.810501\n",
      "return standard deviation: 0.436734\n",
      "min return: 0.813978; max return: 2.954517\n",
      "\n",
      "max ever return: 4.235255\n",
      "loss comparison -0.7398198 4.087916 0.05100869\n",
      "episode 117 in 1.81 sec\n",
      "mean reward: 1.790126\n",
      "return standard deviation: 0.457908\n",
      "min return: 0.931426; max return: 3.854146\n",
      "\n",
      "max ever return: 4.235255\n",
      "loss comparison -0.91070914 4.000835 0.051351175\n",
      "episode 118 in 1.73 sec\n",
      "mean reward: 1.822755\n",
      "return standard deviation: 0.500412\n",
      "min return: 0.937135; max return: 3.822281\n",
      "\n",
      "max ever return: 4.235255\n",
      "loss comparison -0.47466648 3.8990774 0.051699065\n",
      "new optimal trajectory encountered:\n",
      "episode 119 in 1.73 sec\n",
      "mean reward: 1.887792\n",
      "return standard deviation: 0.543043\n",
      "min return: 0.697672; max return: 4.682127\n",
      "\n",
      "max ever return: 4.682127\n",
      "loss comparison -0.94558185 3.8998168 0.052047618\n",
      "episode 120 in 1.68 sec\n",
      "mean reward: 1.903415\n",
      "return standard deviation: 0.564372\n",
      "min return: 0.784318; max return: 4.277292\n",
      "\n",
      "max ever return: 4.682127\n",
      "loss comparison -0.84118724 3.8512645 0.05239933\n",
      "episode 121 in 1.83 sec\n",
      "mean reward: 1.914286\n",
      "return standard deviation: 0.545756\n",
      "min return: 0.737044; max return: 3.633578\n",
      "\n",
      "max ever return: 4.682127\n",
      "loss comparison -0.6350824 3.7766285 0.052742153\n",
      "episode 122 in 1.67 sec\n",
      "mean reward: 1.944375\n",
      "return standard deviation: 0.515511\n",
      "min return: 0.763267; max return: 4.081275\n",
      "\n",
      "max ever return: 4.682127\n",
      "loss comparison -0.31077152 3.7947776 0.053080328\n",
      "episode 123 in 1.63 sec\n",
      "mean reward: 2.033122\n",
      "return standard deviation: 0.584771\n",
      "min return: 0.991577; max return: 4.353155\n",
      "\n",
      "max ever return: 4.682127\n",
      "loss comparison -0.5387647 3.7898784 0.05340782\n",
      "episode 124 in 1.64 sec\n",
      "mean reward: 1.978900\n",
      "return standard deviation: 0.558454\n",
      "min return: 1.010224; max return: 4.457182\n",
      "\n",
      "max ever return: 4.682127\n",
      "loss comparison -0.7967937 3.7567067 0.053729273\n",
      "episode 125 in 1.72 sec\n",
      "mean reward: 1.992786\n",
      "return standard deviation: 0.573292\n",
      "min return: 0.781727; max return: 3.930291\n",
      "\n",
      "max ever return: 4.682127\n",
      "loss comparison -0.5909889 3.772126 0.054050528\n",
      "episode 126 in 1.69 sec\n",
      "mean reward: 2.027514\n",
      "return standard deviation: 0.562622\n",
      "min return: 0.900296; max return: 3.895224\n",
      "\n",
      "max ever return: 4.682127\n",
      "loss comparison -1.1118904 3.6440833 0.054372173\n",
      "new optimal trajectory encountered:\n",
      "episode 127 in 1.87 sec\n",
      "mean reward: 2.116081\n",
      "return standard deviation: 0.685893\n",
      "min return: 0.890655; max return: 4.761786\n",
      "\n",
      "max ever return: 4.761786\n",
      "loss comparison -0.3208499 3.6139069 0.054710828\n",
      "episode 128 in 1.67 sec\n",
      "mean reward: 2.021339\n",
      "return standard deviation: 0.576696\n",
      "min return: 0.864147; max return: 3.671746\n",
      "\n",
      "max ever return: 4.761786\n",
      "loss comparison -0.86057746 3.6182156 0.05504024\n",
      "episode 129 in 1.67 sec\n",
      "mean reward: 2.032955\n",
      "return standard deviation: 0.616608\n",
      "min return: 0.759255; max return: 3.845331\n",
      "\n",
      "max ever return: 4.761786\n",
      "loss comparison -0.40387064 3.5056307 0.055375002\n",
      "new optimal trajectory encountered:\n",
      "episode 130 in 1.75 sec\n",
      "mean reward: 2.176214\n",
      "return standard deviation: 0.622037\n",
      "min return: 0.824401; max return: 5.438706\n",
      "\n",
      "max ever return: 5.438706\n",
      "loss comparison -0.36383748 3.4136865 0.055689853\n",
      "episode 131 in 1.67 sec\n",
      "mean reward: 2.060472\n",
      "return standard deviation: 0.557541\n",
      "min return: 0.954653; max return: 4.559464\n",
      "\n",
      "max ever return: 5.438706\n",
      "loss comparison -0.57074714 3.3746963 0.055978287\n",
      "episode 132 in 1.85 sec\n",
      "mean reward: 2.116328\n",
      "return standard deviation: 0.539525\n",
      "min return: 0.852344; max return: 4.431679\n",
      "\n",
      "max ever return: 5.438706\n",
      "loss comparison -0.31839812 3.2619634 0.05625999\n",
      "episode 133 in 1.68 sec\n",
      "mean reward: 2.140389\n",
      "return standard deviation: 0.563552\n",
      "min return: 0.798402; max return: 4.594788\n",
      "\n",
      "max ever return: 5.438706\n",
      "loss comparison -0.460356 3.1932817 0.056531157\n",
      "new optimal trajectory encountered:\n",
      "episode 134 in 1.74 sec\n",
      "mean reward: 2.151201\n",
      "return standard deviation: 0.653802\n",
      "min return: 0.988892; max return: 5.960164\n",
      "\n",
      "max ever return: 5.960164\n",
      "loss comparison -0.2329526 3.051585 0.056794662\n",
      "episode 135 in 1.66 sec\n",
      "mean reward: 2.111739\n",
      "return standard deviation: 0.581634\n",
      "min return: 1.073907; max return: 4.152001\n",
      "\n",
      "max ever return: 5.960164\n",
      "loss comparison -0.28280205 2.987161 0.057041172\n",
      "episode 136 in 1.65 sec\n",
      "mean reward: 2.131955\n",
      "return standard deviation: 0.567589\n",
      "min return: 1.007705; max return: 4.556406\n",
      "\n",
      "max ever return: 5.960164\n",
      "loss comparison 0.04277706 2.9209206 0.057271864\n",
      "episode 137 in 1.76 sec\n",
      "mean reward: 2.215950\n",
      "return standard deviation: 0.643650\n",
      "min return: 1.053364; max return: 5.433266\n",
      "\n",
      "max ever return: 5.960164\n",
      "loss comparison -0.6162698 2.8506227 0.05745785\n",
      "episode 138 in 1.71 sec\n",
      "mean reward: 2.152619\n",
      "return standard deviation: 0.578049\n",
      "min return: 0.963914; max return: 4.241389\n",
      "\n",
      "max ever return: 5.960164\n",
      "loss comparison -0.29426354 2.7347546 0.057644434\n",
      "episode 139 in 2.10 sec\n",
      "mean reward: 2.206455\n",
      "return standard deviation: 0.629230\n",
      "min return: 0.834807; max return: 4.943784\n",
      "\n",
      "max ever return: 5.960164\n",
      "loss comparison 0.11683965 2.608546 0.057823177\n",
      "episode 140 in 1.83 sec\n",
      "mean reward: 2.185555\n",
      "return standard deviation: 0.599102\n",
      "min return: 0.974799; max return: 4.733422\n",
      "\n",
      "max ever return: 5.960164\n",
      "loss comparison -0.36785147 2.5783083 0.057983395\n",
      "episode 141 in 1.72 sec\n",
      "mean reward: 2.188975\n",
      "return standard deviation: 0.587851\n",
      "min return: 0.898705; max return: 4.835081\n",
      "\n",
      "max ever return: 5.960164\n",
      "loss comparison -0.7518854 2.4549382 0.058132872\n",
      "episode 142 in 1.68 sec\n",
      "mean reward: 2.231555\n",
      "return standard deviation: 0.653696\n",
      "min return: 0.896865; max return: 4.730712\n",
      "\n",
      "max ever return: 5.960164\n",
      "loss comparison -1.5151646 2.3480878 0.058286756\n",
      "episode 143 in 1.66 sec\n",
      "mean reward: 2.202121\n",
      "return standard deviation: 0.636186\n",
      "min return: 0.718834; max return: 4.981576\n",
      "\n",
      "max ever return: 5.960164\n",
      "loss comparison -0.028217912 2.2146902 0.058473513\n",
      "episode 144 in 1.66 sec\n",
      "mean reward: 2.242062\n",
      "return standard deviation: 0.628144\n",
      "min return: 0.970115; max return: 5.270836\n",
      "\n",
      "max ever return: 5.960164\n",
      "loss comparison -0.4305838 2.194872 0.05864481\n",
      "episode 145 in 1.66 sec\n",
      "mean reward: 2.239637\n",
      "return standard deviation: 0.612046\n",
      "min return: 1.015936; max return: 5.367816\n",
      "\n",
      "max ever return: 5.960164\n",
      "loss comparison -0.9852653 2.0863028 0.058803722\n",
      "episode 146 in 1.76 sec\n",
      "mean reward: 2.247710\n",
      "return standard deviation: 0.560281\n",
      "min return: 1.240884; max return: 4.305781\n",
      "\n",
      "max ever return: 5.960164\n",
      "loss comparison -0.82867956 1.9601178 0.05897256\n",
      "episode 147 in 1.65 sec\n",
      "mean reward: 2.273078\n",
      "return standard deviation: 0.611884\n",
      "min return: 1.150003; max return: 4.354572\n",
      "\n",
      "max ever return: 5.960164\n",
      "loss comparison -1.0471442 1.9299362 0.059148643\n",
      "episode 148 in 1.63 sec\n",
      "mean reward: 2.325748\n",
      "return standard deviation: 0.604822\n",
      "min return: 0.977425; max return: 4.533090\n",
      "\n",
      "max ever return: 5.960164\n",
      "loss comparison -0.6095127 1.8640858 0.059340775\n",
      "episode 149 in 1.67 sec\n",
      "mean reward: 2.364937\n",
      "return standard deviation: 0.671002\n",
      "min return: 0.913311; max return: 5.521472\n",
      "\n",
      "max ever return: 5.960164\n",
      "loss comparison -1.2259634 1.7836955 0.059543792\n",
      "episode 150 in 1.65 sec\n",
      "mean reward: 2.292069\n",
      "return standard deviation: 0.621031\n",
      "min return: 1.132055; max return: 5.115787\n",
      "\n",
      "max ever return: 5.960164\n",
      "loss comparison -0.56254363 1.7318913 0.05976241\n",
      "episode 151 in 1.66 sec\n",
      "mean reward: 2.344731\n",
      "return standard deviation: 0.617143\n",
      "min return: 1.227150; max return: 4.916300\n",
      "\n",
      "max ever return: 5.960164\n",
      "loss comparison -0.78764904 1.7129773 0.059968438\n",
      "episode 152 in 1.69 sec\n",
      "mean reward: 2.303906\n",
      "return standard deviation: 0.586995\n",
      "min return: 1.259591; max return: 5.298879\n",
      "\n",
      "max ever return: 5.960164\n",
      "loss comparison -1.1150959 1.6659213 0.06016846\n",
      "episode 153 in 1.72 sec\n",
      "mean reward: 2.402354\n",
      "return standard deviation: 0.677508\n",
      "min return: 1.313349; max return: 5.819343\n",
      "\n",
      "max ever return: 5.960164\n",
      "loss comparison -1.450294 1.5872897 0.060370784\n",
      "episode 154 in 1.68 sec\n",
      "mean reward: 2.384893\n",
      "return standard deviation: 0.624056\n",
      "min return: 1.294586; max return: 4.393653\n",
      "\n",
      "max ever return: 5.960164\n",
      "loss comparison -0.7520933 1.4741709 0.06058043\n",
      "episode 155 in 1.71 sec\n",
      "mean reward: 2.491349\n",
      "return standard deviation: 0.688865\n",
      "min return: 1.355774; max return: 5.553631\n",
      "\n",
      "max ever return: 5.960164\n",
      "loss comparison -0.329948 1.4236497 0.06078992\n",
      "episode 156 in 1.71 sec\n",
      "mean reward: 2.428545\n",
      "return standard deviation: 0.680172\n",
      "min return: 1.306996; max return: 5.168584\n",
      "\n",
      "max ever return: 5.960164\n",
      "loss comparison -0.5635098 1.3583683 0.06098532\n",
      "episode 157 in 1.75 sec\n",
      "mean reward: 2.395062\n",
      "return standard deviation: 0.574532\n",
      "min return: 1.345817; max return: 4.372785\n",
      "\n",
      "max ever return: 5.960164\n",
      "loss comparison -0.8108854 1.3630393 0.061171606\n",
      "new optimal trajectory encountered:\n",
      "episode 158 in 1.66 sec\n",
      "mean reward: 2.422933\n",
      "return standard deviation: 0.689134\n",
      "min return: 1.081751; max return: 6.788247\n",
      "\n",
      "max ever return: 6.788247\n",
      "loss comparison -1.2726337 1.3619071 0.061359257\n",
      "episode 159 in 1.66 sec\n",
      "mean reward: 2.428345\n",
      "return standard deviation: 0.659699\n",
      "min return: 1.112548; max return: 5.225559\n",
      "\n",
      "max ever return: 6.788247\n",
      "loss comparison -1.3550147 1.3121214 0.061550993\n",
      "episode 160 in 1.65 sec\n",
      "mean reward: 2.329815\n",
      "return standard deviation: 0.630574\n",
      "min return: 1.096942; max return: 4.432401\n",
      "\n",
      "max ever return: 6.788247\n",
      "loss comparison -1.6188759 1.3185962 0.061742585\n",
      "episode 161 in 1.63 sec\n",
      "mean reward: 2.472510\n",
      "return standard deviation: 0.630059\n",
      "min return: 1.248984; max return: 4.392481\n",
      "\n",
      "max ever return: 6.788247\n",
      "loss comparison -1.3649197 1.2489321 0.061931677\n",
      "episode 162 in 1.78 sec\n",
      "mean reward: 2.460958\n",
      "return standard deviation: 0.644415\n",
      "min return: 1.110509; max return: 5.211775\n",
      "\n",
      "max ever return: 6.788247\n",
      "loss comparison -1.6469097 1.1524019 0.062116183\n",
      "episode 163 in 1.70 sec\n",
      "mean reward: 2.467258\n",
      "return standard deviation: 0.662415\n",
      "min return: 1.131050; max return: 5.830103\n",
      "\n",
      "max ever return: 6.788247\n",
      "loss comparison -1.016448 1.1703472 0.06230364\n",
      "episode 164 in 1.72 sec\n",
      "mean reward: 2.442427\n",
      "return standard deviation: 0.608986\n",
      "min return: 1.200305; max return: 4.863727\n",
      "\n",
      "max ever return: 6.788247\n",
      "loss comparison -0.8507996 1.071825 0.06249177\n",
      "episode 165 in 1.73 sec\n",
      "mean reward: 2.501291\n",
      "return standard deviation: 0.621868\n",
      "min return: 1.221986; max return: 5.648750\n",
      "\n",
      "max ever return: 6.788247\n",
      "loss comparison -0.56483835 1.0127387 0.062674806\n",
      "episode 166 in 1.67 sec\n",
      "mean reward: 2.508637\n",
      "return standard deviation: 0.660476\n",
      "min return: 1.349346; max return: 4.657799\n",
      "\n",
      "max ever return: 6.788247\n",
      "loss comparison -0.9502603 0.9696125 0.062846206\n",
      "episode 167 in 1.73 sec\n",
      "mean reward: 2.498924\n",
      "return standard deviation: 0.616250\n",
      "min return: 1.214048; max return: 4.803143\n",
      "\n",
      "max ever return: 6.788247\n",
      "loss comparison -1.5121038 0.99290127 0.063007504\n",
      "episode 168 in 1.65 sec\n",
      "mean reward: 2.575480\n",
      "return standard deviation: 0.646426\n",
      "min return: 1.231097; max return: 5.174623\n",
      "\n",
      "max ever return: 6.788247\n",
      "loss comparison -1.8965585 0.91176367 0.06317298\n",
      "episode 169 in 1.66 sec\n",
      "mean reward: 2.565271\n",
      "return standard deviation: 0.615890\n",
      "min return: 1.335094; max return: 5.005895\n",
      "\n",
      "max ever return: 6.788247\n",
      "loss comparison -1.1630028 0.89199734 0.06334777\n",
      "episode 170 in 1.73 sec\n",
      "mean reward: 2.543517\n",
      "return standard deviation: 0.656202\n",
      "min return: 1.330115; max return: 5.349979\n",
      "\n",
      "max ever return: 6.788247\n",
      "loss comparison -1.489745 0.7823833 0.06352284\n",
      "episode 171 in 1.74 sec\n",
      "mean reward: 2.513527\n",
      "return standard deviation: 0.649742\n",
      "min return: 1.126959; max return: 4.668262\n",
      "\n",
      "max ever return: 6.788247\n",
      "loss comparison -1.3526073 0.6988994 0.063708276\n",
      "episode 172 in 1.70 sec\n",
      "mean reward: 2.642479\n",
      "return standard deviation: 0.667464\n",
      "min return: 1.190122; max return: 4.796634\n",
      "\n",
      "max ever return: 6.788247\n",
      "loss comparison -1.4490896 0.6848394 0.063896604\n",
      "episode 173 in 1.66 sec\n",
      "mean reward: 2.606554\n",
      "return standard deviation: 0.675977\n",
      "min return: 1.390258; max return: 4.457432\n",
      "\n",
      "max ever return: 6.788247\n",
      "loss comparison -1.2821481 0.66460884 0.064084485\n",
      "episode 174 in 1.65 sec\n",
      "mean reward: 2.646592\n",
      "return standard deviation: 0.661245\n",
      "min return: 1.107284; max return: 5.448770\n",
      "\n",
      "max ever return: 6.788247\n",
      "loss comparison -1.6134596 0.6387763 0.06428114\n",
      "episode 175 in 1.68 sec\n",
      "mean reward: 2.633870\n",
      "return standard deviation: 0.649471\n",
      "min return: 1.298896; max return: 5.329075\n",
      "\n",
      "max ever return: 6.788247\n",
      "loss comparison -1.3943232 0.6247267 0.06447161\n",
      "episode 176 in 1.67 sec\n",
      "mean reward: 2.574887\n",
      "return standard deviation: 0.661567\n",
      "min return: 1.100420; max return: 5.384980\n",
      "\n",
      "max ever return: 6.788247\n",
      "loss comparison -1.542167 0.5746959 0.06465933\n",
      "episode 177 in 1.71 sec\n",
      "mean reward: 2.674384\n",
      "return standard deviation: 0.609618\n",
      "min return: 1.352442; max return: 4.610745\n",
      "\n",
      "max ever return: 6.788247\n",
      "loss comparison -1.4935489 0.5261103 0.064845726\n",
      "episode 178 in 1.65 sec\n",
      "mean reward: 2.724219\n",
      "return standard deviation: 0.706888\n",
      "min return: 1.154437; max return: 5.472208\n",
      "\n",
      "max ever return: 6.788247\n",
      "loss comparison -1.4189402 0.4728431 0.06503219\n",
      "episode 179 in 1.66 sec\n",
      "mean reward: 2.702711\n",
      "return standard deviation: 0.709293\n",
      "min return: 1.376149; max return: 6.603173\n",
      "\n",
      "max ever return: 6.788247\n",
      "loss comparison -0.93594354 0.44195414 0.06521755\n",
      "episode 180 in 1.70 sec\n",
      "mean reward: 2.623085\n",
      "return standard deviation: 0.680133\n",
      "min return: 1.413554; max return: 5.113007\n",
      "\n",
      "max ever return: 6.788247\n",
      "loss comparison -1.7400712 0.4243085 0.06540884\n",
      "episode 181 in 1.65 sec\n",
      "mean reward: 2.677536\n",
      "return standard deviation: 0.620199\n",
      "min return: 1.037507; max return: 4.234527\n",
      "\n",
      "max ever return: 6.788247\n",
      "loss comparison -0.88539106 0.4041122 0.065606095\n",
      "episode 182 in 1.66 sec\n",
      "mean reward: 2.649434\n",
      "return standard deviation: 0.698446\n",
      "min return: 1.340538; max return: 5.126709\n",
      "\n",
      "max ever return: 6.788247\n",
      "loss comparison -0.9409988 0.4237264 0.06579612\n",
      "episode 183 in 1.64 sec\n",
      "mean reward: 2.616878\n",
      "return standard deviation: 0.583542\n",
      "min return: 1.328538; max return: 4.810228\n",
      "\n",
      "max ever return: 6.788247\n",
      "loss comparison -2.2781835 0.4297134 0.06597862\n",
      "episode 184 in 1.68 sec\n",
      "mean reward: 2.644246\n",
      "return standard deviation: 0.611222\n",
      "min return: 1.200591; max return: 4.541243\n",
      "\n",
      "max ever return: 6.788247\n",
      "loss comparison -2.5162728 0.41489473 0.06615265\n",
      "episode 185 in 1.77 sec\n",
      "mean reward: 2.652380\n",
      "return standard deviation: 0.568309\n",
      "min return: 1.228216; max return: 4.405890\n",
      "\n",
      "max ever return: 6.788247\n",
      "loss comparison -1.0658326 0.35191503 0.06633092\n",
      "episode 186 in 1.66 sec\n",
      "mean reward: 2.712730\n",
      "return standard deviation: 0.643641\n",
      "min return: 1.295666; max return: 4.799013\n",
      "\n",
      "max ever return: 6.788247\n",
      "loss comparison -1.0157504 0.33017755 0.0665134\n",
      "episode 187 in 1.75 sec\n",
      "mean reward: 2.680077\n",
      "return standard deviation: 0.613463\n",
      "min return: 1.103428; max return: 4.979833\n",
      "\n",
      "max ever return: 6.788247\n",
      "loss comparison -1.4080825 0.2988667 0.06669022\n",
      "episode 188 in 1.63 sec\n",
      "mean reward: 2.761425\n",
      "return standard deviation: 0.662933\n",
      "min return: 1.414068; max return: 5.269043\n",
      "\n",
      "max ever return: 6.788247\n",
      "loss comparison -1.2084529 0.29883778 0.06686157\n",
      "episode 189 in 1.64 sec\n",
      "mean reward: 2.734621\n",
      "return standard deviation: 0.645140\n",
      "min return: 1.457881; max return: 6.108958\n",
      "\n",
      "max ever return: 6.788247\n",
      "loss comparison -1.0292628 0.30199605 0.067029096\n",
      "episode 190 in 1.64 sec\n",
      "mean reward: 2.728980\n",
      "return standard deviation: 0.636603\n",
      "min return: 1.279349; max return: 4.677307\n",
      "\n",
      "max ever return: 6.788247\n",
      "loss comparison -1.9187939 0.3233711 0.06718052\n",
      "episode 191 in 1.62 sec\n",
      "mean reward: 2.794469\n",
      "return standard deviation: 0.630190\n",
      "min return: 1.375509; max return: 5.490732\n",
      "\n",
      "max ever return: 6.788247\n",
      "loss comparison -1.7250954 0.2966809 0.0673313\n",
      "episode 192 in 1.68 sec\n",
      "mean reward: 2.725278\n",
      "return standard deviation: 0.608513\n",
      "min return: 1.487952; max return: 4.542424\n",
      "\n",
      "max ever return: 6.788247\n",
      "loss comparison -1.6713259 0.27725303 0.0674713\n",
      "episode 193 in 1.67 sec\n",
      "mean reward: 2.756735\n",
      "return standard deviation: 0.607804\n",
      "min return: 1.226274; max return: 4.530367\n",
      "\n",
      "max ever return: 6.788247\n",
      "loss comparison -1.757911 0.25917676 0.067607015\n",
      "episode 194 in 1.63 sec\n",
      "mean reward: 2.799133\n",
      "return standard deviation: 0.722120\n",
      "min return: 1.200073; max return: 5.484242\n",
      "\n",
      "max ever return: 6.788247\n",
      "loss comparison -1.2156878 0.25194567 0.067745686\n",
      "episode 195 in 1.79 sec\n",
      "mean reward: 2.786633\n",
      "return standard deviation: 0.612971\n",
      "min return: 1.408496; max return: 4.536918\n",
      "\n",
      "max ever return: 6.788247\n",
      "loss comparison -1.434839 0.24166466 0.067874335\n",
      "episode 196 in 1.78 sec\n",
      "mean reward: 2.786899\n",
      "return standard deviation: 0.612575\n",
      "min return: 0.890182; max return: 4.413759\n",
      "\n",
      "max ever return: 6.788247\n",
      "loss comparison -1.6392407 0.24994615 0.06799434\n",
      "episode 197 in 1.74 sec\n",
      "mean reward: 2.771255\n",
      "return standard deviation: 0.612616\n",
      "min return: 1.298984; max return: 4.751631\n",
      "\n",
      "max ever return: 6.788247\n",
      "loss comparison -1.4741505 0.2428751 0.068114266\n",
      "episode 198 in 1.75 sec\n",
      "mean reward: 2.752004\n",
      "return standard deviation: 0.538296\n",
      "min return: 1.360826; max return: 4.255742\n",
      "\n",
      "max ever return: 6.788247\n",
      "loss comparison -2.4410386 0.23200144 0.06823127\n",
      "episode 199 in 1.72 sec\n",
      "mean reward: 2.820897\n",
      "return standard deviation: 0.670826\n",
      "min return: 1.147302; max return: 5.720903\n",
      "\n",
      "max ever return: 6.788247\n",
      "loss comparison -1.2320173 0.22992094 0.068351835\n",
      "episode 200 in 1.67 sec\n",
      "mean reward: 2.820981\n",
      "return standard deviation: 0.637969\n",
      "min return: 1.319263; max return: 4.973627\n",
      "\n",
      "max ever return: 6.788247\n",
      "loss comparison -1.2721108 0.18640392 0.06847071\n",
      "episode 201 in 1.79 sec\n",
      "mean reward: 2.833252\n",
      "return standard deviation: 0.606942\n",
      "min return: 1.582931; max return: 5.440487\n",
      "\n",
      "max ever return: 6.788247\n",
      "loss comparison -1.058384 0.17576419 0.06857975\n",
      "episode 202 in 1.68 sec\n",
      "mean reward: 2.839925\n",
      "return standard deviation: 0.637247\n",
      "min return: 1.476508; max return: 4.494698\n",
      "\n",
      "max ever return: 6.788247\n",
      "loss comparison -0.95138496 0.16327876 0.06868375\n",
      "episode 203 in 1.78 sec\n",
      "mean reward: 2.832440\n",
      "return standard deviation: 0.620985\n",
      "min return: 1.302643; max return: 4.722844\n",
      "\n",
      "max ever return: 6.788247\n",
      "loss comparison -1.0511012 0.1628663 0.068783276\n",
      "episode 204 in 1.74 sec\n",
      "mean reward: 2.900259\n",
      "return standard deviation: 0.604906\n",
      "min return: 1.291341; max return: 4.876027\n",
      "\n",
      "max ever return: 6.788247\n",
      "loss comparison -1.1541299 0.17958659 0.06887698\n",
      "episode 205 in 1.70 sec\n",
      "mean reward: 2.892404\n",
      "return standard deviation: 0.626664\n",
      "min return: 0.980752; max return: 4.883908\n",
      "\n",
      "max ever return: 6.788247\n",
      "loss comparison -1.8037424 0.18464583 0.06896817\n",
      "episode 206 in 1.75 sec\n",
      "mean reward: 2.797786\n",
      "return standard deviation: 0.596968\n",
      "min return: 1.197289; max return: 4.532994\n",
      "\n",
      "max ever return: 6.788247\n",
      "loss comparison -1.054256 0.19051005 0.06906272\n",
      "episode 207 in 1.72 sec\n",
      "mean reward: 2.832652\n",
      "return standard deviation: 0.582037\n",
      "min return: 1.367108; max return: 4.845599\n",
      "\n",
      "max ever return: 6.788247\n",
      "loss comparison -1.5918232 0.16714352 0.069151536\n",
      "episode 208 in 1.74 sec\n",
      "mean reward: 2.876197\n",
      "return standard deviation: 0.564358\n",
      "min return: 1.385815; max return: 4.904775\n",
      "\n",
      "max ever return: 6.788247\n",
      "loss comparison -0.50436586 0.14038174 0.06924295\n",
      "episode 209 in 1.69 sec\n",
      "mean reward: 2.903778\n",
      "return standard deviation: 0.607372\n",
      "min return: 1.395691; max return: 5.910901\n",
      "\n",
      "max ever return: 6.788247\n",
      "loss comparison -1.0170717 0.15341777 0.06932633\n",
      "episode 210 in 1.65 sec\n",
      "mean reward: 2.860212\n",
      "return standard deviation: 0.613100\n",
      "min return: 1.327477; max return: 4.594768\n",
      "\n",
      "max ever return: 6.788247\n",
      "loss comparison -1.4712116 0.15907341 0.06940538\n",
      "episode 211 in 1.74 sec\n",
      "mean reward: 2.936777\n",
      "return standard deviation: 0.649762\n",
      "min return: 0.799512; max return: 5.805521\n",
      "\n",
      "max ever return: 6.788247\n",
      "loss comparison -0.4631495 0.12844163 0.06948888\n",
      "episode 212 in 1.82 sec\n",
      "mean reward: 2.856178\n",
      "return standard deviation: 0.607514\n",
      "min return: 1.327929; max return: 4.872746\n",
      "\n",
      "max ever return: 6.788247\n",
      "loss comparison -0.7434221 0.13298175 0.06956035\n",
      "episode 213 in 1.80 sec\n",
      "mean reward: 2.865395\n",
      "return standard deviation: 0.586383\n",
      "min return: 1.586637; max return: 4.880548\n",
      "\n",
      "max ever return: 6.788247\n",
      "loss comparison -1.1157509 0.15427168 0.06962205\n",
      "episode 214 in 1.78 sec\n",
      "mean reward: 2.876031\n",
      "return standard deviation: 0.639246\n",
      "min return: 0.975889; max return: 5.775990\n",
      "\n",
      "max ever return: 6.788247\n",
      "loss comparison -1.6655989 0.16607635 0.06967478\n",
      "episode 215 in 1.69 sec\n",
      "mean reward: 2.859548\n",
      "return standard deviation: 0.577834\n",
      "min return: 1.385995; max return: 4.850242\n",
      "\n",
      "max ever return: 6.788247\n",
      "loss comparison -1.9583676 0.1779111 0.0697347\n",
      "episode 216 in 1.73 sec\n",
      "mean reward: 2.866824\n",
      "return standard deviation: 0.558470\n",
      "min return: 1.363060; max return: 5.166675\n",
      "\n",
      "max ever return: 6.788247\n",
      "loss comparison -1.4596698 0.15911815 0.06980075\n",
      "episode 217 in 1.81 sec\n",
      "mean reward: 2.838905\n",
      "return standard deviation: 0.549777\n",
      "min return: 1.333353; max return: 4.714958\n",
      "\n",
      "max ever return: 6.788247\n",
      "loss comparison -0.7697288 0.13217252 0.069863774\n",
      "episode 218 in 1.65 sec\n",
      "mean reward: 2.897568\n",
      "return standard deviation: 0.563848\n",
      "min return: 1.437024; max return: 4.764389\n",
      "\n",
      "max ever return: 6.788247\n",
      "loss comparison -1.0863324 0.13277073 0.069921546\n",
      "episode 219 in 1.66 sec\n",
      "mean reward: 2.857630\n",
      "return standard deviation: 0.602230\n",
      "min return: 1.418029; max return: 6.218262\n",
      "\n",
      "max ever return: 6.788247\n",
      "loss comparison -0.7659767 0.12534808 0.06997866\n",
      "episode 220 in 1.74 sec\n",
      "mean reward: 2.839161\n",
      "return standard deviation: 0.611750\n",
      "min return: 1.277482; max return: 4.650445\n",
      "\n",
      "max ever return: 6.788247\n",
      "loss comparison -0.7997437 0.12627779 0.07003141\n",
      "episode 221 in 1.68 sec\n",
      "mean reward: 2.887815\n",
      "return standard deviation: 0.604183\n",
      "min return: 1.455524; max return: 4.893070\n",
      "\n",
      "max ever return: 6.788247\n",
      "loss comparison -1.4155596 0.13988006 0.070079565\n",
      "episode 222 in 1.67 sec\n",
      "mean reward: 2.884028\n",
      "return standard deviation: 0.592122\n",
      "min return: 1.468194; max return: 4.864439\n",
      "\n",
      "max ever return: 6.788247\n",
      "loss comparison -1.3307843 0.14708492 0.070127964\n",
      "episode 223 in 1.65 sec\n",
      "mean reward: 2.873388\n",
      "return standard deviation: 0.582186\n",
      "min return: 1.621507; max return: 5.214461\n",
      "\n",
      "max ever return: 6.788247\n",
      "loss comparison -1.6119134 0.14807092 0.070175216\n",
      "episode 224 in 1.74 sec\n",
      "mean reward: 2.904761\n",
      "return standard deviation: 0.543967\n",
      "min return: 1.648751; max return: 5.684196\n",
      "\n",
      "max ever return: 6.788247\n",
      "loss comparison -1.9959011 0.15702778 0.07022426\n",
      "episode 225 in 1.60 sec\n",
      "mean reward: 2.841923\n",
      "return standard deviation: 0.543632\n",
      "min return: 1.309455; max return: 4.619032\n",
      "\n",
      "max ever return: 6.788247\n",
      "loss comparison -1.2020868 0.13650548 0.070285834\n",
      "episode 226 in 1.59 sec\n",
      "mean reward: 2.873805\n",
      "return standard deviation: 0.592923\n",
      "min return: 1.002593; max return: 4.751631\n",
      "\n",
      "max ever return: 6.788247\n",
      "loss comparison -1.128927 0.12618503 0.0703476\n",
      "episode 227 in 1.66 sec\n",
      "mean reward: 2.851392\n",
      "return standard deviation: 0.538686\n",
      "min return: 1.751219; max return: 4.475458\n",
      "\n",
      "max ever return: 6.788247\n",
      "loss comparison -0.36023852 0.115933776 0.070406005\n",
      "episode 228 in 1.65 sec\n",
      "mean reward: 2.995214\n",
      "return standard deviation: 0.581500\n",
      "min return: 1.402751; max return: 4.759028\n",
      "\n",
      "max ever return: 6.788247\n",
      "loss comparison -0.3002657 0.1014787 0.070451066\n",
      "episode 229 in 1.65 sec\n",
      "mean reward: 2.877052\n",
      "return standard deviation: 0.543578\n",
      "min return: 1.587515; max return: 4.410907\n",
      "\n",
      "max ever return: 6.788247\n",
      "loss comparison -0.39006472 0.11047393 0.07048906\n",
      "episode 230 in 1.62 sec\n",
      "mean reward: 2.907135\n",
      "return standard deviation: 0.577857\n",
      "min return: 1.406958; max return: 5.992494\n",
      "\n",
      "max ever return: 6.788247\n",
      "loss comparison -1.0358391 0.1302585 0.070512824\n",
      "episode 231 in 1.55 sec\n",
      "mean reward: 2.909954\n",
      "return standard deviation: 0.543238\n",
      "min return: 1.458342; max return: 4.784988\n",
      "\n",
      "max ever return: 6.788247\n",
      "loss comparison -1.3767501 0.12759866 0.070534214\n",
      "episode 232 in 1.75 sec\n",
      "mean reward: 2.883682\n",
      "return standard deviation: 0.544319\n",
      "min return: 1.284717; max return: 4.306071\n",
      "\n",
      "max ever return: 6.788247\n",
      "loss comparison -1.1649146 0.12926857 0.07056303\n",
      "episode 233 in 1.62 sec\n",
      "mean reward: 2.865341\n",
      "return standard deviation: 0.549330\n",
      "min return: 1.529208; max return: 4.539559\n",
      "\n",
      "max ever return: 6.788247\n",
      "loss comparison -1.7661146 0.14409342 0.07058861\n",
      "episode 234 in 1.51 sec\n",
      "mean reward: 2.886790\n",
      "return standard deviation: 0.542646\n",
      "min return: 1.597433; max return: 4.308809\n",
      "\n",
      "max ever return: 6.788247\n",
      "loss comparison -1.0987029 0.123356275 0.070617504\n",
      "episode 235 in 1.57 sec\n",
      "mean reward: 2.887100\n",
      "return standard deviation: 0.527560\n",
      "min return: 1.512111; max return: 4.248051\n",
      "\n",
      "max ever return: 6.788247\n",
      "loss comparison -0.9230754 0.12284218 0.07064677\n",
      "episode 236 in 1.65 sec\n",
      "mean reward: 2.886592\n",
      "return standard deviation: 0.509075\n",
      "min return: 1.121571; max return: 4.278364\n",
      "\n",
      "max ever return: 6.788247\n",
      "loss comparison -0.86252844 0.10279414 0.07067531\n",
      "episode 237 in 1.54 sec\n",
      "mean reward: 2.920623\n",
      "return standard deviation: 0.505972\n",
      "min return: 1.697824; max return: 4.198500\n",
      "\n",
      "max ever return: 6.788247\n",
      "loss comparison -0.45206246 0.09571479 0.07070501\n",
      "episode 238 in 1.63 sec\n",
      "mean reward: 2.922174\n",
      "return standard deviation: 0.577705\n",
      "min return: 1.473744; max return: 4.651474\n",
      "\n",
      "max ever return: 6.788247\n",
      "loss comparison -0.3203834 0.101234436 0.07072927\n",
      "episode 239 in 1.53 sec\n",
      "mean reward: 2.915747\n",
      "return standard deviation: 0.532882\n",
      "min return: 1.283377; max return: 4.957675\n",
      "\n",
      "max ever return: 6.788247\n",
      "loss comparison -0.6832336 0.10887441 0.070748076\n",
      "episode 240 in 1.61 sec\n",
      "mean reward: 2.901514\n",
      "return standard deviation: 0.597808\n",
      "min return: 1.469635; max return: 5.131042\n",
      "\n",
      "max ever return: 6.788247\n",
      "loss comparison -1.4038379 0.12619969 0.070762545\n",
      "episode 241 in 1.61 sec\n",
      "mean reward: 2.878386\n",
      "return standard deviation: 0.497932\n",
      "min return: 1.324602; max return: 4.357565\n",
      "\n",
      "max ever return: 6.788247\n",
      "loss comparison -1.5778157 0.14245252 0.070783176\n",
      "episode 242 in 1.62 sec\n",
      "mean reward: 2.887802\n",
      "return standard deviation: 0.520338\n",
      "min return: 1.294989; max return: 4.748115\n",
      "\n",
      "max ever return: 6.788247\n",
      "loss comparison -1.3199794 0.1344598 0.07081273\n",
      "episode 243 in 1.58 sec\n",
      "mean reward: 2.905718\n",
      "return standard deviation: 0.561717\n",
      "min return: 1.389231; max return: 4.923813\n",
      "\n",
      "max ever return: 6.788247\n",
      "loss comparison -1.1706905 0.12150362 0.07084572\n",
      "episode 244 in 1.64 sec\n",
      "mean reward: 2.941841\n",
      "return standard deviation: 0.518497\n",
      "min return: 1.585590; max return: 4.904775\n",
      "\n",
      "max ever return: 6.788247\n",
      "loss comparison -0.9609967 0.102772005 0.07087477\n",
      "episode 245 in 1.57 sec\n",
      "mean reward: 2.869831\n",
      "return standard deviation: 0.585560\n",
      "min return: 1.479463; max return: 4.594768\n",
      "\n",
      "max ever return: 6.788247\n",
      "loss comparison -0.40413633 0.08709239 0.07090063\n",
      "episode 246 in 1.59 sec\n",
      "mean reward: 2.932358\n",
      "return standard deviation: 0.505669\n",
      "min return: 1.697771; max return: 4.142313\n",
      "\n",
      "max ever return: 6.788247\n",
      "loss comparison -0.8107746 0.10614167 0.07091744\n",
      "episode 247 in 1.62 sec\n",
      "mean reward: 2.930542\n",
      "return standard deviation: 0.497080\n",
      "min return: 1.436942; max return: 4.405750\n",
      "\n",
      "max ever return: 6.788247\n",
      "loss comparison -0.462603 0.10364857 0.07093308\n",
      "episode 248 in 1.60 sec\n",
      "mean reward: 2.896192\n",
      "return standard deviation: 0.531831\n",
      "min return: 1.683334; max return: 4.641073\n",
      "\n",
      "max ever return: 6.788247\n",
      "loss comparison -0.6150192 0.10542907 0.070941545\n",
      "episode 249 in 1.59 sec\n",
      "mean reward: 2.971193\n",
      "return standard deviation: 0.598840\n",
      "min return: 1.370189; max return: 5.266409\n",
      "\n",
      "max ever return: 6.788247\n",
      "loss comparison -0.5335067 0.10374813 0.070944846\n",
      "episode 250 in 1.60 sec\n",
      "mean reward: 2.970547\n",
      "return standard deviation: 0.539914\n",
      "min return: 1.547909; max return: 4.306071\n",
      "\n",
      "max ever return: 6.788247\n",
      "loss comparison -1.2151535 0.14265697 0.070942834\n",
      "episode 251 in 1.59 sec\n",
      "mean reward: 2.885498\n",
      "return standard deviation: 0.554363\n",
      "min return: 1.307170; max return: 4.983701\n",
      "\n",
      "max ever return: 6.788247\n",
      "loss comparison -1.0995193 0.1343107 0.070944786\n",
      "episode 252 in 1.65 sec\n",
      "mean reward: 2.907264\n",
      "return standard deviation: 0.562293\n",
      "min return: 1.385423; max return: 4.821310\n",
      "\n",
      "max ever return: 6.788247\n",
      "loss comparison -1.156943 0.118809104 0.07094569\n",
      "episode 253 in 1.59 sec\n",
      "mean reward: 2.945616\n",
      "return standard deviation: 0.536313\n",
      "min return: 1.556914; max return: 4.594768\n",
      "\n",
      "max ever return: 6.788247\n",
      "loss comparison -0.847929 0.10464201 0.07094929\n",
      "episode 254 in 1.66 sec\n",
      "mean reward: 2.964507\n",
      "return standard deviation: 0.570756\n",
      "min return: 1.287696; max return: 4.809629\n",
      "\n",
      "max ever return: 6.788247\n",
      "loss comparison -1.1495823 0.09487815 0.07095643\n",
      "episode 255 in 1.64 sec\n",
      "mean reward: 2.935138\n",
      "return standard deviation: 0.539537\n",
      "min return: 1.464218; max return: 4.568682\n",
      "\n",
      "max ever return: 6.788247\n",
      "loss comparison -1.1293981 0.0934831 0.07096994\n",
      "episode 256 in 1.70 sec\n",
      "mean reward: 2.977172\n",
      "return standard deviation: 0.572847\n",
      "min return: 1.379236; max return: 5.596509\n",
      "\n",
      "max ever return: 6.788247\n",
      "loss comparison -0.6117901 0.08328458 0.070987\n",
      "episode 257 in 1.68 sec\n",
      "mean reward: 2.893920\n",
      "return standard deviation: 0.520358\n",
      "min return: 1.603438; max return: 4.298289\n",
      "\n",
      "max ever return: 6.788247\n",
      "loss comparison -0.2724915 0.088240236 0.07099881\n",
      "episode 258 in 1.63 sec\n",
      "mean reward: 2.958179\n",
      "return standard deviation: 0.599345\n",
      "min return: 1.751219; max return: 5.717593\n",
      "\n",
      "max ever return: 6.788247\n",
      "loss comparison -0.74788266 0.080131605 0.071002945\n",
      "episode 259 in 1.68 sec\n",
      "mean reward: 2.906252\n",
      "return standard deviation: 0.518283\n",
      "min return: 1.224624; max return: 4.199702\n",
      "\n",
      "max ever return: 6.788247\n",
      "loss comparison -0.87121534 0.09391137 0.07100638\n",
      "episode 260 in 1.58 sec\n",
      "mean reward: 2.911156\n",
      "return standard deviation: 0.579443\n",
      "min return: 1.446814; max return: 4.694781\n",
      "\n",
      "max ever return: 6.788247\n",
      "loss comparison -1.2854478 0.107129365 0.07101455\n",
      "episode 261 in 1.62 sec\n",
      "mean reward: 2.956986\n",
      "return standard deviation: 0.513187\n",
      "min return: 1.235538; max return: 4.084137\n",
      "\n",
      "max ever return: 6.788247\n",
      "loss comparison -1.2313197 0.11121302 0.071028076\n",
      "episode 262 in 1.56 sec\n",
      "mean reward: 2.977448\n",
      "return standard deviation: 0.507506\n",
      "min return: 1.439922; max return: 4.694781\n",
      "\n",
      "max ever return: 6.788247\n",
      "loss comparison -1.0965741 0.10242066 0.071049206\n",
      "episode 263 in 1.52 sec\n",
      "mean reward: 2.944325\n",
      "return standard deviation: 0.608813\n",
      "min return: 1.377985; max return: 5.246128\n",
      "\n",
      "max ever return: 6.788247\n",
      "loss comparison -1.5048102 0.114714436 0.071069404\n",
      "episode 264 in 1.59 sec\n",
      "mean reward: 2.917058\n",
      "return standard deviation: 0.542515\n",
      "min return: 1.301905; max return: 4.326940\n",
      "\n",
      "max ever return: 6.788247\n",
      "loss comparison -0.8820748 0.098104455 0.07109818\n",
      "episode 265 in 1.55 sec\n",
      "mean reward: 2.992038\n",
      "return standard deviation: 0.549861\n",
      "min return: 1.556518; max return: 5.006646\n",
      "\n",
      "max ever return: 6.788247\n",
      "loss comparison -0.801774 0.098509 0.07112921\n",
      "episode 266 in 1.54 sec\n",
      "mean reward: 2.941860\n",
      "return standard deviation: 0.518759\n",
      "min return: 1.077307; max return: 4.236475\n",
      "\n",
      "max ever return: 6.788247\n",
      "loss comparison -0.7963072 0.1060983 0.07115604\n",
      "episode 267 in 1.58 sec\n",
      "mean reward: 2.993073\n",
      "return standard deviation: 0.534546\n",
      "min return: 1.730743; max return: 4.405750\n",
      "\n",
      "max ever return: 6.788247\n",
      "loss comparison -0.8350788 0.08742131 0.07117757\n",
      "episode 268 in 1.57 sec\n",
      "mean reward: 2.903122\n",
      "return standard deviation: 0.516574\n",
      "min return: 1.569299; max return: 4.603856\n",
      "\n",
      "max ever return: 6.788247\n",
      "loss comparison -0.82427347 0.099412076 0.0711984\n",
      "episode 269 in 1.52 sec\n",
      "mean reward: 2.917058\n",
      "return standard deviation: 0.555599\n",
      "min return: 0.931266; max return: 4.594768\n",
      "\n",
      "max ever return: 6.788247\n",
      "loss comparison -0.7414371 0.087551884 0.07122012\n",
      "episode 270 in 1.60 sec\n",
      "mean reward: 2.963010\n",
      "return standard deviation: 0.546348\n",
      "min return: 1.654872; max return: 4.889187\n",
      "\n",
      "max ever return: 6.788247\n",
      "loss comparison -0.7333696 0.08416694 0.07124172\n",
      "episode 271 in 1.50 sec\n",
      "mean reward: 2.925362\n",
      "return standard deviation: 0.545223\n",
      "min return: 1.449130; max return: 4.753223\n",
      "\n",
      "max ever return: 6.788247\n",
      "loss comparison -1.184924 0.101087384 0.07125624\n",
      "episode 272 in 1.58 sec\n",
      "mean reward: 2.914351\n",
      "return standard deviation: 0.530628\n",
      "min return: 1.762339; max return: 4.694781\n",
      "\n",
      "max ever return: 6.788247\n",
      "loss comparison -0.8407459 0.10751613 0.07126695\n",
      "episode 273 in 1.51 sec\n",
      "mean reward: 2.955011\n",
      "return standard deviation: 0.515278\n",
      "min return: 1.700100; max return: 4.405750\n",
      "\n",
      "max ever return: 6.788247\n",
      "loss comparison -1.1955531 0.11556519 0.07127996\n",
      "episode 274 in 1.63 sec\n",
      "mean reward: 2.910371\n",
      "return standard deviation: 0.578973\n",
      "min return: 1.527189; max return: 5.101876\n",
      "\n",
      "max ever return: 6.788247\n",
      "loss comparison -1.2281207 0.09792047 0.07129552\n",
      "episode 275 in 1.60 sec\n",
      "mean reward: 2.961377\n",
      "return standard deviation: 0.508476\n",
      "min return: 1.671898; max return: 5.603992\n",
      "\n",
      "max ever return: 6.788247\n",
      "loss comparison -0.42226088 0.08442606 0.071312554\n",
      "episode 276 in 1.55 sec\n",
      "mean reward: 2.954159\n",
      "return standard deviation: 0.515461\n",
      "min return: 1.122161; max return: 4.405750\n",
      "\n",
      "max ever return: 6.788247\n",
      "loss comparison -0.43294045 0.08552679 0.07133192\n",
      "episode 277 in 1.54 sec\n",
      "mean reward: 2.959433\n",
      "return standard deviation: 0.517885\n",
      "min return: 1.678055; max return: 4.588941\n",
      "\n",
      "max ever return: 6.788247\n",
      "loss comparison -1.011165 0.096086696 0.07134156\n",
      "episode 278 in 1.56 sec\n",
      "mean reward: 2.878320\n",
      "return standard deviation: 0.514320\n",
      "min return: 1.409794; max return: 4.239723\n",
      "\n",
      "max ever return: 6.788247\n",
      "loss comparison -0.46497434 0.10446793 0.071355104\n",
      "episode 279 in 1.56 sec\n",
      "mean reward: 2.857961\n",
      "return standard deviation: 0.551504\n",
      "min return: 1.515320; max return: 5.706073\n",
      "\n",
      "max ever return: 6.788247\n",
      "loss comparison -1.1332605 0.0995504 0.07136221\n",
      "episode 280 in 1.67 sec\n",
      "mean reward: 2.979895\n",
      "return standard deviation: 0.527333\n",
      "min return: 1.479463; max return: 4.778709\n",
      "\n",
      "max ever return: 6.788247\n",
      "loss comparison -0.95443547 0.09809576 0.07136863\n",
      "episode 281 in 1.62 sec\n",
      "mean reward: 3.000135\n",
      "return standard deviation: 0.527470\n",
      "min return: 1.412839; max return: 4.797202\n",
      "\n",
      "max ever return: 6.788247\n",
      "loss comparison -0.77916366 0.098086834 0.07137241\n",
      "episode 282 in 1.59 sec\n",
      "mean reward: 2.991698\n",
      "return standard deviation: 0.526126\n",
      "min return: 1.704929; max return: 4.705056\n",
      "\n",
      "max ever return: 6.788247\n",
      "loss comparison -1.3055165 0.09914319 0.071377166\n",
      "episode 283 in 1.59 sec\n",
      "mean reward: 2.951862\n",
      "return standard deviation: 0.530557\n",
      "min return: 1.443478; max return: 4.666747\n",
      "\n",
      "max ever return: 6.788247\n",
      "loss comparison -0.64379144 0.091220215 0.07139053\n",
      "episode 284 in 1.53 sec\n",
      "mean reward: 3.003380\n",
      "return standard deviation: 0.533026\n",
      "min return: 1.563923; max return: 5.123803\n",
      "\n",
      "max ever return: 6.788247\n",
      "loss comparison -0.34267628 0.08905941 0.07139982\n",
      "episode 285 in 1.57 sec\n",
      "mean reward: 2.904158\n",
      "return standard deviation: 0.536378\n",
      "min return: 1.213652; max return: 4.694781\n",
      "\n",
      "max ever return: 6.788247\n",
      "loss comparison -0.42808318 0.07696296 0.07140245\n",
      "episode 286 in 1.59 sec\n",
      "mean reward: 3.015284\n",
      "return standard deviation: 0.546541\n",
      "min return: 1.743103; max return: 5.320055\n",
      "\n",
      "max ever return: 6.788247\n",
      "loss comparison -1.3094151 0.0842584 0.07140144\n",
      "episode 287 in 1.53 sec\n",
      "mean reward: 2.903497\n",
      "return standard deviation: 0.549978\n",
      "min return: 1.134207; max return: 4.374565\n",
      "\n",
      "max ever return: 6.788247\n",
      "loss comparison -0.41680396 0.08654395 0.071407914\n",
      "episode 288 in 1.66 sec\n",
      "mean reward: 2.937891\n",
      "return standard deviation: 0.501049\n",
      "min return: 1.635057; max return: 5.174144\n",
      "\n",
      "max ever return: 6.788247\n",
      "loss comparison -0.82201564 0.103666775 0.0714109\n",
      "episode 289 in 1.67 sec\n",
      "mean reward: 2.934836\n",
      "return standard deviation: 0.556993\n",
      "min return: 1.388380; max return: 4.694836\n",
      "\n",
      "max ever return: 6.788247\n",
      "loss comparison -1.2233161 0.10494578 0.07141877\n",
      "episode 290 in 1.58 sec\n",
      "mean reward: 2.968123\n",
      "return standard deviation: 0.520707\n",
      "min return: 1.781078; max return: 4.538571\n",
      "\n",
      "max ever return: 6.788247\n",
      "loss comparison -1.2281972 0.09329408 0.0714317\n",
      "episode 291 in 1.69 sec\n",
      "mean reward: 2.916603\n",
      "return standard deviation: 0.470606\n",
      "min return: 1.582798; max return: 4.346182\n",
      "\n",
      "max ever return: 6.788247\n",
      "loss comparison -0.7726605 0.09730077 0.071448416\n",
      "episode 292 in 1.63 sec\n",
      "mean reward: 2.943750\n",
      "return standard deviation: 0.509122\n",
      "min return: 1.525969; max return: 4.275045\n",
      "\n",
      "max ever return: 6.788247\n",
      "loss comparison -1.141333 0.07509609 0.07145529\n",
      "episode 293 in 1.59 sec\n",
      "mean reward: 2.952700\n",
      "return standard deviation: 0.523084\n",
      "min return: 1.287413; max return: 4.318274\n",
      "\n",
      "max ever return: 6.788247\n",
      "loss comparison -0.6920694 0.074594535 0.071468964\n",
      "episode 294 in 1.71 sec\n",
      "mean reward: 2.933143\n",
      "return standard deviation: 0.549576\n",
      "min return: 1.295913; max return: 4.390705\n",
      "\n",
      "max ever return: 6.788247\n",
      "loss comparison -0.3140374 0.07924788 0.071483426\n",
      "episode 295 in 1.57 sec\n",
      "mean reward: 2.966151\n",
      "return standard deviation: 0.521848\n",
      "min return: 1.751219; max return: 4.374565\n",
      "\n",
      "max ever return: 6.788247\n",
      "loss comparison -0.6252795 0.08221422 0.07148912\n",
      "episode 296 in 1.62 sec\n",
      "mean reward: 2.953740\n",
      "return standard deviation: 0.529800\n",
      "min return: 1.728197; max return: 4.318274\n",
      "\n",
      "max ever return: 6.788247\n",
      "loss comparison -0.75536805 0.095991135 0.07148541\n",
      "episode 297 in 1.52 sec\n",
      "mean reward: 2.951395\n",
      "return standard deviation: 0.491651\n",
      "min return: 1.310015; max return: 4.594768\n",
      "\n",
      "max ever return: 6.788247\n",
      "loss comparison -0.8673235 0.095101945 0.07148547\n",
      "episode 298 in 1.62 sec\n",
      "mean reward: 2.949195\n",
      "return standard deviation: 0.551923\n",
      "min return: 1.416263; max return: 5.255680\n",
      "\n",
      "max ever return: 6.788247\n",
      "loss comparison -0.9312308 0.09965779 0.07149748\n",
      "episode 299 in 1.58 sec\n",
      "mean reward: 2.971201\n",
      "return standard deviation: 0.494713\n",
      "min return: 1.444493; max return: 4.284657\n",
      "\n",
      "max ever return: 6.788247\n",
      "loss comparison -1.1020112 0.09249163 0.07151454\n",
      "episode 300 in 1.65 sec\n",
      "mean reward: 2.967776\n",
      "return standard deviation: 0.462365\n",
      "min return: 1.460308; max return: 4.648520\n",
      "\n",
      "max ever return: 6.788247\n",
      "loss comparison -0.9498632 0.09394444 0.071531534\n",
      "episode 301 in 1.54 sec\n",
      "mean reward: 3.012874\n",
      "return standard deviation: 0.526289\n",
      "min return: 1.058586; max return: 4.248051\n",
      "\n",
      "max ever return: 6.788247\n",
      "loss comparison -0.631823 0.080423735 0.0715466\n",
      "episode 302 in 1.65 sec\n",
      "mean reward: 2.976311\n",
      "return standard deviation: 0.546137\n",
      "min return: 1.185594; max return: 5.016841\n",
      "\n",
      "max ever return: 6.788247\n",
      "loss comparison -0.25500184 0.07639369 0.07155974\n",
      "episode 303 in 1.71 sec\n",
      "mean reward: 2.922112\n",
      "return standard deviation: 0.481428\n",
      "min return: 0.991864; max return: 4.602660\n",
      "\n",
      "max ever return: 6.788247\n",
      "loss comparison -0.48620778 0.071308106 0.071567\n",
      "episode 304 in 1.60 sec\n",
      "mean reward: 2.941860\n",
      "return standard deviation: 0.548431\n",
      "min return: 1.240448; max return: 4.594768\n",
      "\n",
      "max ever return: 6.788247\n",
      "loss comparison -0.65221876 0.086969055 0.07157115\n",
      "episode 305 in 1.60 sec\n",
      "mean reward: 2.975837\n",
      "return standard deviation: 0.506530\n",
      "min return: 1.728798; max return: 4.405750\n",
      "\n",
      "max ever return: 6.788247\n",
      "loss comparison -0.7792391 0.0827546 0.07156471\n",
      "episode 306 in 1.61 sec\n",
      "mean reward: 2.988588\n",
      "return standard deviation: 0.507987\n",
      "min return: 1.596573; max return: 4.318274\n",
      "\n",
      "max ever return: 6.788247\n",
      "loss comparison -0.6758382 0.1005941 0.07155759\n",
      "episode 307 in 1.58 sec\n",
      "mean reward: 2.953213\n",
      "return standard deviation: 0.501495\n",
      "min return: 1.745594; max return: 4.318274\n",
      "\n",
      "max ever return: 6.788247\n",
      "loss comparison -1.392997 0.10243015 0.07155428\n",
      "episode 308 in 1.64 sec\n",
      "mean reward: 2.967252\n",
      "return standard deviation: 0.547647\n",
      "min return: 1.649802; max return: 4.668301\n",
      "\n",
      "max ever return: 6.788247\n",
      "loss comparison -0.6134006 0.09217265 0.07155403\n",
      "episode 309 in 1.61 sec\n",
      "mean reward: 2.991058\n",
      "return standard deviation: 0.571981\n",
      "min return: 1.540471; max return: 5.990378\n",
      "\n",
      "max ever return: 6.788247\n",
      "loss comparison -0.7089194 0.09260897 0.07154571\n",
      "episode 310 in 1.62 sec\n",
      "mean reward: 2.999846\n",
      "return standard deviation: 0.510641\n",
      "min return: 1.751219; max return: 4.809870\n",
      "\n",
      "max ever return: 6.788247\n",
      "loss comparison -0.7380506 0.07714555 0.07153471\n",
      "episode 311 in 1.57 sec\n",
      "mean reward: 2.988535\n",
      "return standard deviation: 0.492970\n",
      "min return: 1.802181; max return: 4.229733\n",
      "\n",
      "max ever return: 6.788247\n",
      "loss comparison -0.31796408 0.08194059 0.071532935\n",
      "episode 312 in 1.59 sec\n",
      "mean reward: 2.997534\n",
      "return standard deviation: 0.505998\n",
      "min return: 1.802181; max return: 4.467254\n",
      "\n",
      "max ever return: 6.788247\n",
      "loss comparison -0.6992913 0.078694545 0.07152768\n",
      "episode 313 in 1.63 sec\n",
      "mean reward: 2.950411\n",
      "return standard deviation: 0.484596\n",
      "min return: 1.124506; max return: 4.039708\n",
      "\n",
      "max ever return: 6.788247\n",
      "loss comparison -0.16969776 0.070652835 0.07152626\n",
      "episode 314 in 1.54 sec\n",
      "mean reward: 2.942309\n",
      "return standard deviation: 0.520576\n",
      "min return: 1.403960; max return: 4.199702\n",
      "\n",
      "max ever return: 6.788247\n",
      "loss comparison -0.19410461 0.0664691 0.07152206\n",
      "episode 315 in 1.62 sec\n",
      "mean reward: 2.952947\n",
      "return standard deviation: 0.459969\n",
      "min return: 1.751219; max return: 4.405750\n",
      "\n",
      "max ever return: 6.788247\n",
      "loss comparison -0.7431185 0.081659794 0.07150711\n",
      "episode 316 in 1.62 sec\n",
      "mean reward: 2.938009\n",
      "return standard deviation: 0.499748\n",
      "min return: 1.497445; max return: 4.442508\n",
      "\n",
      "max ever return: 6.788247\n",
      "loss comparison -0.5657485 0.102513015 0.07149617\n",
      "episode 317 in 1.61 sec\n",
      "mean reward: 2.953122\n",
      "return standard deviation: 0.480422\n",
      "min return: 1.751219; max return: 4.694781\n",
      "\n",
      "max ever return: 6.788247\n",
      "loss comparison -0.5427782 0.097105175 0.0714761\n",
      "episode 318 in 1.57 sec\n",
      "mean reward: 3.008696\n",
      "return standard deviation: 0.456724\n",
      "min return: 1.360973; max return: 4.174179\n",
      "\n",
      "max ever return: 6.788247\n",
      "loss comparison -0.90381724 0.091897465 0.07146671\n",
      "episode 319 in 1.54 sec\n",
      "mean reward: 2.990548\n",
      "return standard deviation: 0.466397\n",
      "min return: 1.728127; max return: 4.211299\n",
      "\n",
      "max ever return: 6.788247\n",
      "loss comparison -0.95745045 0.09320826 0.071454294\n",
      "episode 320 in 1.62 sec\n",
      "mean reward: 3.016950\n",
      "return standard deviation: 0.431560\n",
      "min return: 1.398664; max return: 4.504838\n",
      "\n",
      "max ever return: 6.788247\n",
      "loss comparison -0.6264037 0.09868835 0.07145108\n",
      "episode 321 in 1.59 sec\n",
      "mean reward: 2.963739\n",
      "return standard deviation: 0.453759\n",
      "min return: 1.751219; max return: 4.326940\n",
      "\n",
      "max ever return: 6.788247\n",
      "loss comparison -1.0469869 0.088440515 0.07144943\n",
      "episode 322 in 1.59 sec\n",
      "mean reward: 2.960832\n",
      "return standard deviation: 0.505297\n",
      "min return: 1.736205; max return: 4.101450\n",
      "\n",
      "max ever return: 6.788247\n",
      "loss comparison -0.56418765 0.07114693 0.071455084\n",
      "episode 323 in 1.61 sec\n",
      "mean reward: 2.970672\n",
      "return standard deviation: 0.489366\n",
      "min return: 1.725181; max return: 4.248051\n",
      "\n",
      "max ever return: 6.788247\n",
      "loss comparison -0.66918033 0.07546477 0.07145744\n",
      "episode 324 in 1.58 sec\n",
      "mean reward: 2.992510\n",
      "return standard deviation: 0.470161\n",
      "min return: 1.629881; max return: 4.375111\n",
      "\n",
      "max ever return: 6.788247\n",
      "loss comparison -0.79695624 0.07282527 0.071465924\n",
      "episode 325 in 1.61 sec\n",
      "mean reward: 2.981311\n",
      "return standard deviation: 0.493829\n",
      "min return: 1.435861; max return: 4.707833\n",
      "\n",
      "max ever return: 6.788247\n",
      "loss comparison -0.21433108 0.07453285 0.07147451\n",
      "episode 326 in 1.57 sec\n",
      "mean reward: 2.979131\n",
      "return standard deviation: 0.521303\n",
      "min return: 1.238561; max return: 4.306071\n",
      "\n",
      "max ever return: 6.788247\n",
      "loss comparison -0.7192818 0.06962548 0.071481116\n",
      "episode 327 in 1.55 sec\n",
      "mean reward: 2.993721\n",
      "return standard deviation: 0.481219\n",
      "min return: 1.572806; max return: 4.294452\n",
      "\n",
      "max ever return: 6.788247\n",
      "loss comparison -0.44571853 0.061222576 0.07148671\n",
      "episode 328 in 1.61 sec\n",
      "mean reward: 2.959411\n",
      "return standard deviation: 0.519457\n",
      "min return: 1.209442; max return: 4.559384\n",
      "\n",
      "max ever return: 6.788247\n",
      "loss comparison -0.50480044 0.07007171 0.07148931\n",
      "episode 329 in 1.57 sec\n",
      "mean reward: 2.997072\n",
      "return standard deviation: 0.526353\n",
      "min return: 1.482593; max return: 4.594768\n",
      "\n",
      "max ever return: 6.788247\n",
      "loss comparison -0.5092627 0.080420636 0.071487136\n",
      "episode 330 in 1.67 sec\n",
      "mean reward: 2.934432\n",
      "return standard deviation: 0.502311\n",
      "min return: 1.751219; max return: 4.260731\n",
      "\n",
      "max ever return: 6.788247\n",
      "loss comparison -0.71893674 0.08228317 0.07148839\n",
      "episode 331 in 1.60 sec\n",
      "mean reward: 2.978012\n",
      "return standard deviation: 0.426424\n",
      "min return: 1.751219; max return: 4.079113\n",
      "\n",
      "max ever return: 6.788247\n",
      "loss comparison -0.7224356 0.07833126 0.0714915\n",
      "episode 332 in 1.58 sec\n",
      "mean reward: 2.943581\n",
      "return standard deviation: 0.489828\n",
      "min return: 1.384408; max return: 4.442508\n",
      "\n",
      "max ever return: 6.788247\n",
      "loss comparison -1.0317254 0.082418896 0.071495876\n",
      "episode 333 in 1.52 sec\n",
      "mean reward: 3.015809\n",
      "return standard deviation: 0.485562\n",
      "min return: 1.578293; max return: 4.168715\n",
      "\n",
      "max ever return: 6.788247\n",
      "loss comparison -0.50861514 0.0731828 0.07150549\n",
      "episode 334 in 1.60 sec\n",
      "mean reward: 3.027879\n",
      "return standard deviation: 0.459125\n",
      "min return: 1.700957; max return: 4.694781\n",
      "\n",
      "max ever return: 6.788247\n",
      "loss comparison -0.22177768 0.0683344 0.071516186\n",
      "episode 335 in 1.60 sec\n",
      "mean reward: 3.056509\n",
      "return standard deviation: 0.492912\n",
      "min return: 1.414880; max return: 4.719822\n",
      "\n",
      "max ever return: 6.788247\n",
      "loss comparison -0.57477796 0.07366405 0.071516424\n",
      "episode 336 in 1.56 sec\n",
      "mean reward: 2.991664\n",
      "return standard deviation: 0.516984\n",
      "min return: 1.595756; max return: 4.674325\n",
      "\n",
      "max ever return: 6.788247\n",
      "loss comparison 0.23541129 0.05678209 0.07152011\n",
      "episode 337 in 1.58 sec\n",
      "mean reward: 3.053313\n",
      "return standard deviation: 0.453737\n",
      "min return: 1.751219; max return: 4.344661\n",
      "\n",
      "max ever return: 6.788247\n",
      "loss comparison -0.3092475 0.06296282 0.071506895\n",
      "episode 338 in 1.57 sec\n",
      "mean reward: 2.983034\n",
      "return standard deviation: 0.451906\n",
      "min return: 2.072175; max return: 4.199702\n",
      "\n",
      "max ever return: 6.788247\n",
      "loss comparison -0.8313978 0.060786735 0.07149281\n",
      "episode 339 in 1.54 sec\n",
      "mean reward: 2.959265\n",
      "return standard deviation: 0.527705\n",
      "min return: 1.605500; max return: 4.442508\n",
      "\n",
      "max ever return: 6.788247\n",
      "loss comparison -0.521688 0.06585825 0.071487434\n",
      "episode 340 in 1.64 sec\n",
      "mean reward: 3.009778\n",
      "return standard deviation: 0.490695\n",
      "min return: 1.604484; max return: 4.801439\n",
      "\n",
      "max ever return: 6.788247\n",
      "loss comparison -0.50053525 0.060414735 0.071481556\n",
      "episode 341 in 1.52 sec\n",
      "mean reward: 3.039252\n",
      "return standard deviation: 0.477880\n",
      "min return: 1.619711; max return: 4.568682\n",
      "\n",
      "max ever return: 6.788247\n",
      "loss comparison -0.5978391 0.076018415 0.07146912\n",
      "episode 342 in 1.61 sec\n",
      "mean reward: 2.949004\n",
      "return standard deviation: 0.449247\n",
      "min return: 1.776782; max return: 4.168715\n",
      "\n",
      "max ever return: 6.788247\n",
      "loss comparison -0.63607556 0.06644607 0.071458474\n",
      "episode 343 in 1.60 sec\n",
      "mean reward: 2.978994\n",
      "return standard deviation: 0.448119\n",
      "min return: 1.652450; max return: 4.248051\n",
      "\n",
      "max ever return: 6.788247\n",
      "loss comparison -0.09814991 0.057451632 0.07144332\n",
      "episode 344 in 1.59 sec\n",
      "mean reward: 3.064038\n",
      "return standard deviation: 0.456599\n",
      "min return: 2.062329; max return: 4.306071\n",
      "\n",
      "max ever return: 6.788247\n",
      "loss comparison -0.5295736 0.06321335 0.071416475\n",
      "episode 345 in 1.57 sec\n",
      "mean reward: 2.961967\n",
      "return standard deviation: 0.508954\n",
      "min return: 1.727049; max return: 4.694781\n",
      "\n",
      "max ever return: 6.788247\n",
      "loss comparison -0.019962728 0.06487377 0.071385525\n",
      "new optimal trajectory encountered:\n",
      "episode 346 in 1.54 sec\n",
      "mean reward: 3.049958\n",
      "return standard deviation: 0.544462\n",
      "min return: 1.688274; max return: 6.929264\n",
      "\n",
      "max ever return: 6.929264\n",
      "loss comparison -0.58716154 0.06547161 0.07134595\n",
      "episode 347 in 1.67 sec\n",
      "mean reward: 2.991731\n",
      "return standard deviation: 0.491403\n",
      "min return: 1.302688; max return: 4.568682\n",
      "\n",
      "max ever return: 6.929264\n",
      "loss comparison -0.6575076 0.07620624 0.07130799\n",
      "episode 348 in 1.61 sec\n",
      "mean reward: 3.003204\n",
      "return standard deviation: 0.499887\n",
      "min return: 1.675550; max return: 4.694781\n",
      "\n",
      "max ever return: 6.929264\n",
      "loss comparison -0.62186706 0.06767788 0.071273535\n",
      "new optimal trajectory encountered:\n",
      "episode 349 in 1.60 sec\n",
      "mean reward: 2.972483\n",
      "return standard deviation: 0.528057\n",
      "min return: 1.447986; max return: 7.366199\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.4772369 0.071106 0.0712573\n",
      "episode 350 in 1.57 sec\n",
      "mean reward: 2.967280\n",
      "return standard deviation: 0.492057\n",
      "min return: 1.751219; max return: 4.220027\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.40523687 0.06669102 0.07124352\n",
      "episode 351 in 1.61 sec\n",
      "mean reward: 2.980451\n",
      "return standard deviation: 0.482564\n",
      "min return: 1.635626; max return: 4.405750\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.5179575 0.061997686 0.07122401\n",
      "episode 352 in 1.63 sec\n",
      "mean reward: 3.005951\n",
      "return standard deviation: 0.481289\n",
      "min return: 1.751219; max return: 4.238695\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.6601057 0.0670028 0.07120376\n",
      "episode 353 in 1.63 sec\n",
      "mean reward: 2.961854\n",
      "return standard deviation: 0.421895\n",
      "min return: 1.648180; max return: 4.243397\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.20877132 0.05494654 0.07118771\n",
      "episode 354 in 1.61 sec\n",
      "mean reward: 3.043548\n",
      "return standard deviation: 0.501071\n",
      "min return: 1.751219; max return: 4.694781\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.3292448 0.060493812 0.07116021\n",
      "episode 355 in 1.55 sec\n",
      "mean reward: 3.012602\n",
      "return standard deviation: 0.447627\n",
      "min return: 1.751219; max return: 4.326940\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.7563353 0.075127915 0.07113033\n",
      "episode 356 in 1.56 sec\n",
      "mean reward: 3.001695\n",
      "return standard deviation: 0.481976\n",
      "min return: 1.582061; max return: 4.350762\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -1.1616186 0.07688635 0.07110889\n",
      "episode 357 in 1.63 sec\n",
      "mean reward: 2.980047\n",
      "return standard deviation: 0.493930\n",
      "min return: 1.589503; max return: 4.442508\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.61981463 0.06744901 0.071097955\n",
      "episode 358 in 1.54 sec\n",
      "mean reward: 3.019510\n",
      "return standard deviation: 0.445277\n",
      "min return: 1.905840; max return: 4.318274\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.6664807 0.07086976 0.07108801\n",
      "episode 359 in 1.59 sec\n",
      "mean reward: 2.965625\n",
      "return standard deviation: 0.474240\n",
      "min return: 1.751219; max return: 4.186609\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.3886742 0.0638224 0.07107617\n",
      "episode 360 in 1.69 sec\n",
      "mean reward: 3.024037\n",
      "return standard deviation: 0.536925\n",
      "min return: 1.439690; max return: 4.694781\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison 0.04033947 0.05617892 0.07106701\n",
      "episode 361 in 1.59 sec\n",
      "mean reward: 2.991906\n",
      "return standard deviation: 0.502795\n",
      "min return: 1.751219; max return: 4.813308\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.2085388 0.0672777 0.07104539\n",
      "episode 362 in 1.49 sec\n",
      "mean reward: 2.971026\n",
      "return standard deviation: 0.494979\n",
      "min return: 1.589047; max return: 4.594768\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.24561527 0.06588796 0.07102469\n",
      "episode 363 in 1.62 sec\n",
      "mean reward: 2.989228\n",
      "return standard deviation: 0.480786\n",
      "min return: 1.665594; max return: 4.255808\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.7222019 0.071631975 0.07100226\n",
      "episode 364 in 1.62 sec\n",
      "mean reward: 3.028271\n",
      "return standard deviation: 0.442593\n",
      "min return: 1.389066; max return: 4.266285\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.5687284 0.07625405 0.070984475\n",
      "episode 365 in 1.62 sec\n",
      "mean reward: 2.993846\n",
      "return standard deviation: 0.436200\n",
      "min return: 1.803740; max return: 4.170275\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -1.014196 0.07456838 0.07096975\n",
      "episode 366 in 1.63 sec\n",
      "mean reward: 2.988220\n",
      "return standard deviation: 0.507000\n",
      "min return: 1.712319; max return: 4.568682\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -1.0302762 0.06757767 0.070953116\n",
      "episode 367 in 1.57 sec\n",
      "mean reward: 3.041270\n",
      "return standard deviation: 0.496993\n",
      "min return: 0.960666; max return: 4.405750\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.50265837 0.060667753 0.070949554\n",
      "episode 368 in 1.64 sec\n",
      "mean reward: 3.013695\n",
      "return standard deviation: 0.457132\n",
      "min return: 1.891453; max return: 4.405750\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.31921118 0.062004317 0.070939355\n",
      "episode 369 in 1.59 sec\n",
      "mean reward: 2.991710\n",
      "return standard deviation: 0.482096\n",
      "min return: 0.801359; max return: 4.703114\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.057761617 0.058574338 0.07093453\n",
      "episode 370 in 1.56 sec\n",
      "mean reward: 2.984746\n",
      "return standard deviation: 0.510041\n",
      "min return: 1.574813; max return: 5.029030\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.54916257 0.0594787 0.07091925\n",
      "episode 371 in 1.62 sec\n",
      "mean reward: 2.995625\n",
      "return standard deviation: 0.459321\n",
      "min return: 1.553078; max return: 4.368109\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.6460947 0.07495944 0.07090406\n",
      "episode 372 in 1.55 sec\n",
      "mean reward: 2.991090\n",
      "return standard deviation: 0.465693\n",
      "min return: 1.740469; max return: 4.326940\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.33317327 0.06436926 0.07088799\n",
      "episode 373 in 1.62 sec\n",
      "mean reward: 2.948829\n",
      "return standard deviation: 0.442760\n",
      "min return: 1.396557; max return: 4.172207\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.6271363 0.07081968 0.07087122\n",
      "episode 374 in 1.60 sec\n",
      "mean reward: 3.012132\n",
      "return standard deviation: 0.472226\n",
      "min return: 1.143001; max return: 4.422493\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.9188733 0.07084972 0.07085515\n",
      "episode 375 in 1.61 sec\n",
      "mean reward: 2.955004\n",
      "return standard deviation: 0.489976\n",
      "min return: 0.681519; max return: 4.278896\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.9748035 0.07519261 0.070850305\n",
      "episode 376 in 1.54 sec\n",
      "mean reward: 2.983143\n",
      "return standard deviation: 0.450827\n",
      "min return: 1.706118; max return: 4.694781\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.6707604 0.07077518 0.07085119\n",
      "episode 377 in 1.64 sec\n",
      "mean reward: 2.982641\n",
      "return standard deviation: 0.508868\n",
      "min return: 1.704979; max return: 6.174956\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.33079728 0.059841003 0.070851095\n",
      "episode 378 in 1.59 sec\n",
      "mean reward: 3.049994\n",
      "return standard deviation: 0.458967\n",
      "min return: 1.636225; max return: 4.318274\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.15024877 0.04298915 0.07084757\n",
      "episode 379 in 1.67 sec\n",
      "mean reward: 3.041584\n",
      "return standard deviation: 0.528708\n",
      "min return: 1.346700; max return: 4.442508\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.10900439 0.05089575 0.070835896\n",
      "episode 380 in 1.63 sec\n",
      "mean reward: 2.946661\n",
      "return standard deviation: 0.484502\n",
      "min return: 1.727110; max return: 4.299512\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison 0.13122281 0.052566268 0.070818156\n",
      "episode 381 in 1.66 sec\n",
      "mean reward: 2.998143\n",
      "return standard deviation: 0.486980\n",
      "min return: 1.511570; max return: 5.108338\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.31464303 0.050700475 0.07079197\n",
      "episode 382 in 1.77 sec\n",
      "mean reward: 3.026774\n",
      "return standard deviation: 0.418513\n",
      "min return: 1.863086; max return: 4.248051\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.8282281 0.06880036 0.07075679\n",
      "episode 383 in 1.68 sec\n",
      "mean reward: 3.040976\n",
      "return standard deviation: 0.468900\n",
      "min return: 1.528889; max return: 4.548883\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.36859748 0.060601436 0.07073557\n",
      "episode 384 in 1.57 sec\n",
      "mean reward: 3.033451\n",
      "return standard deviation: 0.447292\n",
      "min return: 1.751219; max return: 4.245302\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -1.0213774 0.06932454 0.07071436\n",
      "episode 385 in 1.58 sec\n",
      "mean reward: 2.943062\n",
      "return standard deviation: 0.483040\n",
      "min return: 1.190165; max return: 5.061155\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.6716473 0.07347146 0.07070422\n",
      "episode 386 in 1.62 sec\n",
      "mean reward: 3.003454\n",
      "return standard deviation: 0.474336\n",
      "min return: 1.610238; max return: 4.403723\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.9092883 0.06666159 0.0707021\n",
      "episode 387 in 1.66 sec\n",
      "mean reward: 2.969550\n",
      "return standard deviation: 0.460817\n",
      "min return: 1.404234; max return: 4.199702\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.37657407 0.059684787 0.07071484\n",
      "episode 388 in 1.65 sec\n",
      "mean reward: 3.026377\n",
      "return standard deviation: 0.445507\n",
      "min return: 1.776782; max return: 4.168715\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.17999317 0.055374846 0.070724316\n",
      "episode 389 in 1.59 sec\n",
      "mean reward: 2.976198\n",
      "return standard deviation: 0.465990\n",
      "min return: 1.751219; max return: 4.374565\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.4051546 0.055040814 0.07072278\n",
      "episode 390 in 1.58 sec\n",
      "mean reward: 2.983365\n",
      "return standard deviation: 0.444351\n",
      "min return: 1.479463; max return: 4.374565\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.59518945 0.05842822 0.07071607\n",
      "episode 391 in 1.53 sec\n",
      "mean reward: 2.960510\n",
      "return standard deviation: 0.480787\n",
      "min return: 1.463970; max return: 4.405750\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.35118413 0.05996912 0.07070992\n",
      "episode 392 in 1.62 sec\n",
      "mean reward: 3.002366\n",
      "return standard deviation: 0.450752\n",
      "min return: 1.751219; max return: 4.380250\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.23687813 0.054441113 0.070703834\n",
      "episode 393 in 1.56 sec\n",
      "mean reward: 2.994180\n",
      "return standard deviation: 0.423695\n",
      "min return: 1.751219; max return: 4.159999\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.5440408 0.06690225 0.0706935\n",
      "episode 394 in 1.57 sec\n",
      "mean reward: 2.995110\n",
      "return standard deviation: 0.487322\n",
      "min return: 1.600328; max return: 4.751631\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.6431257 0.073409736 0.07067554\n",
      "episode 395 in 1.50 sec\n",
      "mean reward: 3.008565\n",
      "return standard deviation: 0.407912\n",
      "min return: 1.716230; max return: 4.211299\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.7386856 0.06732527 0.07065684\n",
      "episode 396 in 1.64 sec\n",
      "mean reward: 3.035059\n",
      "return standard deviation: 0.467028\n",
      "min return: 1.370891; max return: 4.568682\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.61868775 0.0591692 0.07063707\n",
      "episode 397 in 1.59 sec\n",
      "mean reward: 3.018548\n",
      "return standard deviation: 0.434069\n",
      "min return: 1.897830; max return: 4.405750\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.10165727 0.05735315 0.07061957\n",
      "episode 398 in 1.51 sec\n",
      "mean reward: 2.983115\n",
      "return standard deviation: 0.426982\n",
      "min return: 1.855516; max return: 4.079837\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.5902364 0.0542729 0.070594706\n",
      "episode 399 in 1.57 sec\n",
      "mean reward: 2.978874\n",
      "return standard deviation: 0.440809\n",
      "min return: 1.479463; max return: 4.237622\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.6307591 0.05717293 0.0705728\n",
      "episode 400 in 1.62 sec\n",
      "mean reward: 3.019305\n",
      "return standard deviation: 0.453224\n",
      "min return: 0.799395; max return: 4.128112\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison 0.06753653 0.049797934 0.0705577\n",
      "episode 401 in 1.63 sec\n",
      "mean reward: 2.993693\n",
      "return standard deviation: 0.448510\n",
      "min return: 1.760769; max return: 4.694781\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.4829815 0.05495404 0.07053042\n",
      "episode 402 in 1.53 sec\n",
      "mean reward: 3.018894\n",
      "return standard deviation: 0.461933\n",
      "min return: 1.588607; max return: 4.248051\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -1.1435022 0.07108761 0.07050233\n",
      "episode 403 in 1.74 sec\n",
      "mean reward: 2.931040\n",
      "return standard deviation: 0.497758\n",
      "min return: 0.818600; max return: 4.110481\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.7710322 0.06059902 0.07050212\n",
      "episode 404 in 1.72 sec\n",
      "mean reward: 2.979249\n",
      "return standard deviation: 0.473310\n",
      "min return: 1.715778; max return: 4.688489\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.5831317 0.053883333 0.070508964\n",
      "episode 405 in 1.80 sec\n",
      "mean reward: 2.927234\n",
      "return standard deviation: 0.447002\n",
      "min return: 1.751219; max return: 4.172338\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.05576518 0.054701556 0.07051365\n",
      "episode 406 in 1.65 sec\n",
      "mean reward: 3.002071\n",
      "return standard deviation: 0.465385\n",
      "min return: 1.751219; max return: 4.575768\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.18113494 0.046744723 0.07050615\n",
      "episode 407 in 1.64 sec\n",
      "mean reward: 3.029526\n",
      "return standard deviation: 0.435643\n",
      "min return: 1.929685; max return: 4.319618\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison 0.04422356 0.044097453 0.07049719\n",
      "episode 408 in 1.57 sec\n",
      "mean reward: 3.007511\n",
      "return standard deviation: 0.478212\n",
      "min return: 1.397829; max return: 4.410907\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.41576958 0.052399416 0.07047868\n",
      "episode 409 in 1.69 sec\n",
      "mean reward: 3.055134\n",
      "return standard deviation: 0.454021\n",
      "min return: 1.636709; max return: 4.205716\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.7104956 0.056342706 0.07046307\n",
      "episode 410 in 1.54 sec\n",
      "mean reward: 2.992275\n",
      "return standard deviation: 0.468239\n",
      "min return: 1.224527; max return: 4.620878\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.53850347 0.055713408 0.07045706\n",
      "episode 411 in 1.68 sec\n",
      "mean reward: 3.016645\n",
      "return standard deviation: 0.474930\n",
      "min return: 1.751219; max return: 4.594768\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.57109225 0.04746548 0.07045345\n",
      "episode 412 in 1.53 sec\n",
      "mean reward: 3.057198\n",
      "return standard deviation: 0.440767\n",
      "min return: 1.614583; max return: 4.405750\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.5075475 0.058392294 0.070451625\n",
      "episode 413 in 1.58 sec\n",
      "mean reward: 3.027515\n",
      "return standard deviation: 0.458608\n",
      "min return: 1.668738; max return: 4.352841\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.3286172 0.04507851 0.070449375\n",
      "episode 414 in 1.58 sec\n",
      "mean reward: 2.978665\n",
      "return standard deviation: 0.457924\n",
      "min return: 1.751219; max return: 4.174294\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.028809607 0.029828213 0.07044215\n",
      "episode 415 in 1.55 sec\n",
      "mean reward: 2.940021\n",
      "return standard deviation: 0.462294\n",
      "min return: 1.394480; max return: 4.211299\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison 0.25319695 0.03687998 0.07043099\n",
      "episode 416 in 1.61 sec\n",
      "mean reward: 3.021826\n",
      "return standard deviation: 0.478931\n",
      "min return: 1.666389; max return: 5.803371\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.24095164 0.048413407 0.07040819\n",
      "episode 417 in 1.64 sec\n",
      "mean reward: 3.045080\n",
      "return standard deviation: 0.440285\n",
      "min return: 1.827202; max return: 4.405750\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.27608377 0.05051364 0.07038077\n",
      "episode 418 in 1.64 sec\n",
      "mean reward: 3.037692\n",
      "return standard deviation: 0.482867\n",
      "min return: 0.931686; max return: 4.568682\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.5708123 0.056885738 0.07034978\n",
      "episode 419 in 1.62 sec\n",
      "mean reward: 2.970073\n",
      "return standard deviation: 0.436022\n",
      "min return: 1.610593; max return: 4.276799\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.34748808 0.05041215 0.07032545\n",
      "episode 420 in 1.60 sec\n",
      "mean reward: 2.990509\n",
      "return standard deviation: 0.490581\n",
      "min return: 1.776782; max return: 4.469770\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.5889391 0.056838844 0.07029259\n",
      "episode 421 in 1.55 sec\n",
      "mean reward: 2.965421\n",
      "return standard deviation: 0.421473\n",
      "min return: 2.178031; max return: 4.125949\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.36660704 0.045717318 0.07026585\n",
      "episode 422 in 1.59 sec\n",
      "mean reward: 3.007970\n",
      "return standard deviation: 0.427339\n",
      "min return: 2.002691; max return: 4.282301\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.22361717 0.049470518 0.07024179\n",
      "episode 423 in 1.59 sec\n",
      "mean reward: 3.020707\n",
      "return standard deviation: 0.393221\n",
      "min return: 1.751219; max return: 4.197223\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison 0.056502715 0.04312462 0.070210256\n",
      "episode 424 in 1.58 sec\n",
      "mean reward: 3.008422\n",
      "return standard deviation: 0.423385\n",
      "min return: 1.751219; max return: 4.374565\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.1908823 0.039662614 0.070170514\n",
      "episode 425 in 1.54 sec\n",
      "mean reward: 2.982202\n",
      "return standard deviation: 0.439266\n",
      "min return: 1.674067; max return: 4.694781\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison 0.28226137 0.042201642 0.070130065\n",
      "episode 426 in 1.50 sec\n",
      "mean reward: 3.038470\n",
      "return standard deviation: 0.479491\n",
      "min return: 1.751219; max return: 4.954123\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.20088536 0.044319212 0.07007777\n",
      "episode 427 in 1.53 sec\n",
      "mean reward: 3.025278\n",
      "return standard deviation: 0.459422\n",
      "min return: 1.829832; max return: 4.737148\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.5822965 0.04697934 0.070024185\n",
      "episode 428 in 1.52 sec\n",
      "mean reward: 2.978112\n",
      "return standard deviation: 0.451365\n",
      "min return: 0.881047; max return: 4.694781\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.51488644 0.05355263 0.06998384\n",
      "episode 429 in 1.49 sec\n",
      "mean reward: 2.936134\n",
      "return standard deviation: 0.446276\n",
      "min return: 0.699834; max return: 4.172338\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison 0.012270203 0.04518455 0.06995055\n",
      "episode 430 in 1.50 sec\n",
      "mean reward: 3.045288\n",
      "return standard deviation: 0.394048\n",
      "min return: 1.938950; max return: 4.069154\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.45726237 0.05031424 0.069908835\n",
      "episode 431 in 1.51 sec\n",
      "mean reward: 3.028306\n",
      "return standard deviation: 0.439920\n",
      "min return: 1.540854; max return: 5.139652\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.68288004 0.06461376 0.069869734\n",
      "episode 432 in 1.52 sec\n",
      "mean reward: 2.973956\n",
      "return standard deviation: 0.507656\n",
      "min return: 1.776225; max return: 4.568682\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.56327 0.05563411 0.06984005\n",
      "episode 433 in 1.50 sec\n",
      "mean reward: 3.026648\n",
      "return standard deviation: 0.438605\n",
      "min return: 1.328497; max return: 4.594768\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.16875662 0.05466169 0.06982175\n",
      "episode 434 in 1.57 sec\n",
      "mean reward: 3.020355\n",
      "return standard deviation: 0.467834\n",
      "min return: 1.832616; max return: 4.263072\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.22438842 0.050665334 0.06980023\n",
      "episode 435 in 1.53 sec\n",
      "mean reward: 3.002770\n",
      "return standard deviation: 0.438890\n",
      "min return: 1.751219; max return: 4.568682\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.30227786 0.04533464 0.06977609\n",
      "episode 436 in 1.53 sec\n",
      "mean reward: 2.981814\n",
      "return standard deviation: 0.499249\n",
      "min return: 0.750617; max return: 4.362874\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.37803534 0.05056592 0.06975021\n",
      "episode 437 in 1.56 sec\n",
      "mean reward: 3.029309\n",
      "return standard deviation: 0.412248\n",
      "min return: 1.929685; max return: 4.279666\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison 0.05993779 0.048090205 0.069721356\n",
      "episode 438 in 1.57 sec\n",
      "mean reward: 3.039527\n",
      "return standard deviation: 0.441404\n",
      "min return: 1.803740; max return: 4.694781\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.41628814 0.053709377 0.06968394\n",
      "episode 439 in 1.58 sec\n",
      "mean reward: 2.992240\n",
      "return standard deviation: 0.432907\n",
      "min return: 1.589547; max return: 4.694781\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.8426384 0.06587209 0.06964792\n",
      "episode 440 in 1.57 sec\n",
      "mean reward: 2.992562\n",
      "return standard deviation: 0.423240\n",
      "min return: 1.659199; max return: 4.263072\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.49609727 0.07127834 0.06961962\n",
      "episode 441 in 1.50 sec\n",
      "mean reward: 2.988863\n",
      "return standard deviation: 0.467418\n",
      "min return: 1.624133; max return: 4.594768\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.57038015 0.05617126 0.069595076\n",
      "episode 442 in 1.50 sec\n",
      "mean reward: 3.008133\n",
      "return standard deviation: 0.407707\n",
      "min return: 1.776782; max return: 4.405750\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.41503945 0.067538306 0.06957372\n",
      "episode 443 in 1.52 sec\n",
      "mean reward: 3.006162\n",
      "return standard deviation: 0.477620\n",
      "min return: 0.963354; max return: 4.370521\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison 0.03317581 0.04370053 0.069555566\n",
      "episode 444 in 1.58 sec\n",
      "mean reward: 3.053585\n",
      "return standard deviation: 0.447905\n",
      "min return: 1.751219; max return: 4.405750\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison 0.040807582 0.056270704 0.06952989\n",
      "episode 445 in 1.52 sec\n",
      "mean reward: 2.986099\n",
      "return standard deviation: 0.443051\n",
      "min return: 1.751219; max return: 4.283089\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.47909185 0.056927577 0.06950361\n",
      "episode 446 in 1.50 sec\n",
      "mean reward: 3.013638\n",
      "return standard deviation: 0.461146\n",
      "min return: 1.751219; max return: 4.327921\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.56947726 0.06372544 0.069481686\n",
      "episode 447 in 1.49 sec\n",
      "mean reward: 3.002780\n",
      "return standard deviation: 0.448983\n",
      "min return: 1.497938; max return: 4.145792\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.20657161 0.05837887 0.06946476\n",
      "episode 448 in 1.49 sec\n",
      "mean reward: 3.004720\n",
      "return standard deviation: 0.466255\n",
      "min return: 1.776782; max return: 4.925442\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.6041008 0.062055036 0.06945151\n",
      "episode 449 in 1.59 sec\n",
      "mean reward: 3.010897\n",
      "return standard deviation: 0.425773\n",
      "min return: 1.929685; max return: 4.694781\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.87323034 0.07382891 0.06944435\n",
      "episode 450 in 1.51 sec\n",
      "mean reward: 3.011621\n",
      "return standard deviation: 0.497565\n",
      "min return: 1.202281; max return: 4.382706\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.74823225 0.063258894 0.06944294\n",
      "episode 451 in 1.51 sec\n",
      "mean reward: 3.058223\n",
      "return standard deviation: 0.459454\n",
      "min return: 1.322320; max return: 5.078979\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.61586154 0.05560641 0.0694456\n",
      "episode 452 in 1.50 sec\n",
      "mean reward: 3.061963\n",
      "return standard deviation: 0.481688\n",
      "min return: 0.915313; max return: 5.226710\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison 0.121304244 0.05032034 0.069450326\n",
      "episode 453 in 1.53 sec\n",
      "mean reward: 3.073487\n",
      "return standard deviation: 0.401528\n",
      "min return: 2.151548; max return: 4.154750\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.5631372 0.062396098 0.06944035\n",
      "episode 454 in 1.51 sec\n",
      "mean reward: 2.989226\n",
      "return standard deviation: 0.495482\n",
      "min return: 0.934215; max return: 4.306071\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison 0.048632212 0.050827805 0.06943643\n",
      "episode 455 in 1.49 sec\n",
      "mean reward: 3.057158\n",
      "return standard deviation: 0.462059\n",
      "min return: 1.751219; max return: 4.594768\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.20174617 0.06270106 0.06942629\n",
      "episode 456 in 1.50 sec\n",
      "mean reward: 3.008309\n",
      "return standard deviation: 0.456617\n",
      "min return: 1.751219; max return: 4.405750\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.69118005 0.06575325 0.06942192\n",
      "episode 457 in 1.54 sec\n",
      "mean reward: 3.011100\n",
      "return standard deviation: 0.420777\n",
      "min return: 1.729833; max return: 4.112154\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -1.2982309 0.073815405 0.06942749\n",
      "episode 458 in 1.49 sec\n",
      "mean reward: 2.976069\n",
      "return standard deviation: 0.466462\n",
      "min return: 1.030209; max return: 4.277074\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.6332079 0.07447454 0.069447994\n",
      "episode 459 in 1.50 sec\n",
      "mean reward: 3.050086\n",
      "return standard deviation: 0.449814\n",
      "min return: 1.517299; max return: 4.306071\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -1.0700132 0.07107812 0.0694818\n",
      "episode 460 in 1.48 sec\n",
      "mean reward: 3.002157\n",
      "return standard deviation: 0.457940\n",
      "min return: 1.956644; max return: 6.887558\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.5356541 0.056302883 0.069529414\n",
      "episode 461 in 1.48 sec\n",
      "mean reward: 3.083134\n",
      "return standard deviation: 0.456402\n",
      "min return: 1.200982; max return: 4.632265\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.25080717 0.054378778 0.06958023\n",
      "episode 462 in 1.54 sec\n",
      "mean reward: 2.991114\n",
      "return standard deviation: 0.469164\n",
      "min return: 0.962506; max return: 4.594768\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.2350514 0.052686203 0.06963008\n",
      "episode 463 in 1.49 sec\n",
      "mean reward: 3.034800\n",
      "return standard deviation: 0.480952\n",
      "min return: 0.977830; max return: 4.137720\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.0070895553 0.046267603 0.069669135\n",
      "episode 464 in 1.54 sec\n",
      "mean reward: 3.069229\n",
      "return standard deviation: 0.482160\n",
      "min return: 1.119076; max return: 4.335297\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.17502311 0.049079042 0.069693685\n",
      "episode 465 in 1.51 sec\n",
      "mean reward: 3.045209\n",
      "return standard deviation: 0.449152\n",
      "min return: 1.105011; max return: 4.318274\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.54101855 0.05473675 0.06971745\n",
      "episode 466 in 1.49 sec\n",
      "mean reward: 3.007636\n",
      "return standard deviation: 0.451154\n",
      "min return: 1.108117; max return: 4.215534\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.8728142 0.056390222 0.069737345\n",
      "episode 467 in 1.49 sec\n",
      "mean reward: 3.016166\n",
      "return standard deviation: 0.476486\n",
      "min return: 1.191774; max return: 5.046110\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.8162684 0.055470023 0.069759645\n",
      "episode 468 in 1.46 sec\n",
      "mean reward: 3.047458\n",
      "return standard deviation: 0.509080\n",
      "min return: 0.967693; max return: 4.568682\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.8753655 0.050720043 0.06978787\n",
      "episode 469 in 1.49 sec\n",
      "mean reward: 3.025636\n",
      "return standard deviation: 0.518132\n",
      "min return: 1.046850; max return: 4.588566\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.6528295 0.054745574 0.06979739\n",
      "episode 470 in 1.54 sec\n",
      "mean reward: 3.026530\n",
      "return standard deviation: 0.488858\n",
      "min return: 1.289418; max return: 4.599730\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.94065785 0.06062307 0.06980536\n",
      "episode 471 in 1.51 sec\n",
      "mean reward: 3.049381\n",
      "return standard deviation: 0.469901\n",
      "min return: 1.052351; max return: 4.188648\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.32521838 0.046653755 0.069822684\n",
      "episode 472 in 1.63 sec\n",
      "mean reward: 3.038881\n",
      "return standard deviation: 0.434834\n",
      "min return: 1.108199; max return: 4.191194\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.24689838 0.04804682 0.06982896\n",
      "episode 473 in 1.51 sec\n",
      "mean reward: 3.023785\n",
      "return standard deviation: 0.426046\n",
      "min return: 1.482648; max return: 4.174272\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.47119388 0.04728584 0.069837086\n",
      "episode 474 in 1.49 sec\n",
      "mean reward: 3.038842\n",
      "return standard deviation: 0.467457\n",
      "min return: 1.097428; max return: 4.263072\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison 0.012738369 0.04522899 0.06984933\n",
      "episode 475 in 1.56 sec\n",
      "mean reward: 3.061393\n",
      "return standard deviation: 0.448310\n",
      "min return: 1.704037; max return: 4.568682\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.2968077 0.05789361 0.069857664\n",
      "episode 476 in 1.57 sec\n",
      "mean reward: 3.025460\n",
      "return standard deviation: 0.434690\n",
      "min return: 1.751219; max return: 4.216338\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.8917599 0.05867737 0.069865435\n",
      "episode 477 in 1.58 sec\n",
      "mean reward: 3.064622\n",
      "return standard deviation: 0.468059\n",
      "min return: 1.259704; max return: 4.188648\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.90839475 0.06922806 0.0698984\n",
      "episode 478 in 1.53 sec\n",
      "mean reward: 3.021269\n",
      "return standard deviation: 0.431371\n",
      "min return: 1.997045; max return: 4.306071\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.6855585 0.06171164 0.069936045\n",
      "episode 479 in 1.51 sec\n",
      "mean reward: 2.992682\n",
      "return standard deviation: 0.432554\n",
      "min return: 1.109897; max return: 4.347682\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.8841586 0.06171476 0.06997547\n",
      "episode 480 in 1.55 sec\n",
      "mean reward: 3.038870\n",
      "return standard deviation: 0.453589\n",
      "min return: 1.751219; max return: 4.249596\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.5577426 0.055716846 0.07002805\n",
      "episode 481 in 1.50 sec\n",
      "mean reward: 3.079638\n",
      "return standard deviation: 0.441955\n",
      "min return: 0.961941; max return: 4.752229\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.060120814 0.04887704 0.070075944\n",
      "episode 482 in 1.57 sec\n",
      "mean reward: 3.057364\n",
      "return standard deviation: 0.427461\n",
      "min return: 0.962498; max return: 4.147240\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.5184518 0.045115575 0.07011876\n",
      "episode 483 in 1.51 sec\n",
      "mean reward: 3.072422\n",
      "return standard deviation: 0.435084\n",
      "min return: 1.223473; max return: 4.583293\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.18105999 0.04898069 0.07016524\n",
      "episode 484 in 1.55 sec\n",
      "mean reward: 3.062234\n",
      "return standard deviation: 0.492433\n",
      "min return: 1.313848; max return: 4.914762\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison 0.15606636 0.040659286 0.07021029\n",
      "episode 485 in 1.50 sec\n",
      "mean reward: 3.092658\n",
      "return standard deviation: 0.459412\n",
      "min return: 1.776782; max return: 6.498815\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.68994415 0.05753608 0.07024255\n",
      "episode 486 in 1.51 sec\n",
      "mean reward: 3.038938\n",
      "return standard deviation: 0.418907\n",
      "min return: 1.276119; max return: 4.318274\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.489827 0.04567138 0.070271395\n",
      "episode 487 in 1.53 sec\n",
      "mean reward: 3.090751\n",
      "return standard deviation: 0.421222\n",
      "min return: 2.179163; max return: 4.594768\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.46945077 0.047199707 0.07030573\n",
      "episode 488 in 1.59 sec\n",
      "mean reward: 3.036665\n",
      "return standard deviation: 0.406985\n",
      "min return: 1.751219; max return: 4.190912\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.6267202 0.05533679 0.07033823\n",
      "episode 489 in 1.53 sec\n",
      "mean reward: 3.060676\n",
      "return standard deviation: 0.483572\n",
      "min return: 1.751219; max return: 4.374565\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.36378425 0.04338283 0.070375204\n",
      "episode 490 in 1.52 sec\n",
      "mean reward: 3.059187\n",
      "return standard deviation: 0.363869\n",
      "min return: 1.751219; max return: 4.163929\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.51577973 0.049362198 0.0704095\n",
      "episode 491 in 1.52 sec\n",
      "mean reward: 3.096408\n",
      "return standard deviation: 0.453115\n",
      "min return: 1.751219; max return: 4.248051\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.33352122 0.044108026 0.07044181\n",
      "episode 492 in 1.49 sec\n",
      "mean reward: 3.062773\n",
      "return standard deviation: 0.395497\n",
      "min return: 1.989786; max return: 4.405750\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.3130535 0.038966198 0.07047191\n",
      "episode 493 in 1.47 sec\n",
      "mean reward: 3.066013\n",
      "return standard deviation: 0.448262\n",
      "min return: 1.140636; max return: 4.216338\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.2736413 0.040030144 0.070497334\n",
      "episode 494 in 1.48 sec\n",
      "mean reward: 3.084166\n",
      "return standard deviation: 0.435937\n",
      "min return: 1.028836; max return: 4.276471\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.36722234 0.038555477 0.070522055\n",
      "episode 495 in 1.50 sec\n",
      "mean reward: 3.097848\n",
      "return standard deviation: 0.450458\n",
      "min return: 0.988416; max return: 4.853221\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.7037063 0.038568806 0.070541635\n",
      "episode 496 in 1.53 sec\n",
      "mean reward: 3.032091\n",
      "return standard deviation: 0.513229\n",
      "min return: 1.090965; max return: 4.471509\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.076462284 0.032434437 0.07056437\n",
      "episode 497 in 1.48 sec\n",
      "mean reward: 3.094174\n",
      "return standard deviation: 0.456127\n",
      "min return: 1.414087; max return: 4.594768\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.49992645 0.03481949 0.07058569\n",
      "episode 498 in 1.48 sec\n",
      "mean reward: 3.076689\n",
      "return standard deviation: 0.452025\n",
      "min return: 1.250847; max return: 4.203954\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.4247979 0.035420667 0.07061548\n",
      "episode 499 in 1.53 sec\n",
      "mean reward: 3.085705\n",
      "return standard deviation: 0.424667\n",
      "min return: 1.067245; max return: 4.163929\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.7364147 0.037980873 0.07064898\n",
      "episode 500 in 1.47 sec\n",
      "mean reward: 3.031733\n",
      "return standard deviation: 0.456395\n",
      "min return: 1.139623; max return: 4.774454\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.56192446 0.03406217 0.070690595\n",
      "episode 501 in 1.48 sec\n",
      "mean reward: 3.067732\n",
      "return standard deviation: 0.445180\n",
      "min return: 1.861618; max return: 4.216338\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.49754792 0.03486179 0.07072878\n",
      "episode 502 in 1.51 sec\n",
      "mean reward: 3.047274\n",
      "return standard deviation: 0.388402\n",
      "min return: 2.069914; max return: 4.160548\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.44456303 0.037967246 0.07076263\n",
      "episode 503 in 1.51 sec\n",
      "mean reward: 3.028754\n",
      "return standard deviation: 0.474312\n",
      "min return: 1.051729; max return: 4.405750\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.18728434 0.03121552 0.07079965\n",
      "episode 504 in 1.54 sec\n",
      "mean reward: 3.106474\n",
      "return standard deviation: 0.430536\n",
      "min return: 1.124990; max return: 4.329541\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.19158526 0.026880976 0.07082325\n",
      "episode 505 in 1.48 sec\n",
      "mean reward: 3.046006\n",
      "return standard deviation: 0.439933\n",
      "min return: 1.383888; max return: 4.594768\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.21285383 0.027687212 0.07084264\n",
      "episode 506 in 1.47 sec\n",
      "mean reward: 3.085693\n",
      "return standard deviation: 0.430443\n",
      "min return: 0.824886; max return: 4.405750\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.027127925 0.030823005 0.07085295\n",
      "episode 507 in 1.47 sec\n",
      "mean reward: 3.078643\n",
      "return standard deviation: 0.454104\n",
      "min return: 1.260013; max return: 4.374565\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.35932678 0.034263305 0.07085408\n",
      "episode 508 in 1.52 sec\n",
      "mean reward: 3.070738\n",
      "return standard deviation: 0.477057\n",
      "min return: 1.061024; max return: 4.517053\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.52800727 0.03153327 0.07085038\n",
      "episode 509 in 1.51 sec\n",
      "mean reward: 3.049082\n",
      "return standard deviation: 0.482375\n",
      "min return: 1.038424; max return: 5.800941\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.51541424 0.038127683 0.07085305\n",
      "episode 510 in 1.54 sec\n",
      "mean reward: 3.078847\n",
      "return standard deviation: 0.454530\n",
      "min return: 1.691149; max return: 4.160548\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.40688032 0.041174468 0.070860416\n",
      "episode 511 in 1.58 sec\n",
      "mean reward: 3.059700\n",
      "return standard deviation: 0.451478\n",
      "min return: 1.022807; max return: 4.405750\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.57888764 0.044577297 0.07086093\n",
      "episode 512 in 1.53 sec\n",
      "mean reward: 3.043120\n",
      "return standard deviation: 0.423508\n",
      "min return: 2.148125; max return: 4.405750\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.7237925 0.047066223 0.07086823\n",
      "episode 513 in 1.48 sec\n",
      "mean reward: 3.068640\n",
      "return standard deviation: 0.423031\n",
      "min return: 2.077960; max return: 4.216790\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.45736927 0.042294607 0.070887566\n",
      "episode 514 in 1.52 sec\n",
      "mean reward: 3.121534\n",
      "return standard deviation: 0.411707\n",
      "min return: 1.897142; max return: 4.216338\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.38241306 0.041388363 0.07091188\n",
      "episode 515 in 1.49 sec\n",
      "mean reward: 3.020518\n",
      "return standard deviation: 0.430742\n",
      "min return: 1.827942; max return: 4.405750\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.09546717 0.03433823 0.07092846\n",
      "episode 516 in 1.50 sec\n",
      "mean reward: 3.016413\n",
      "return standard deviation: 0.426209\n",
      "min return: 1.751219; max return: 4.405750\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.06570542 0.03187559 0.07093672\n",
      "episode 517 in 1.56 sec\n",
      "mean reward: 3.029635\n",
      "return standard deviation: 0.396712\n",
      "min return: 1.548923; max return: 4.160548\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.19674885 0.031145306 0.07093507\n",
      "episode 518 in 1.55 sec\n",
      "mean reward: 3.055104\n",
      "return standard deviation: 0.422373\n",
      "min return: 1.360593; max return: 4.156528\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.07726618 0.033576906 0.07093532\n",
      "episode 519 in 1.52 sec\n",
      "mean reward: 3.059414\n",
      "return standard deviation: 0.378960\n",
      "min return: 1.751219; max return: 4.141416\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.12281907 0.039837442 0.07092851\n",
      "episode 520 in 1.60 sec\n",
      "mean reward: 3.044571\n",
      "return standard deviation: 0.446992\n",
      "min return: 1.735833; max return: 4.405750\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.35733116 0.037632667 0.07092084\n",
      "episode 521 in 1.52 sec\n",
      "mean reward: 3.047006\n",
      "return standard deviation: 0.359008\n",
      "min return: 2.008085; max return: 4.155881\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.5739341 0.051838852 0.07091729\n",
      "episode 522 in 1.53 sec\n",
      "mean reward: 3.028170\n",
      "return standard deviation: 0.388772\n",
      "min return: 1.640054; max return: 4.557809\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.57484514 0.04228878 0.07091493\n",
      "episode 523 in 1.48 sec\n",
      "mean reward: 3.112259\n",
      "return standard deviation: 0.420060\n",
      "min return: 1.696825; max return: 4.405750\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.22393706 0.038926262 0.07091674\n",
      "episode 524 in 1.55 sec\n",
      "mean reward: 3.080935\n",
      "return standard deviation: 0.412820\n",
      "min return: 2.134475; max return: 4.989947\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.22304672 0.04246491 0.07091893\n",
      "episode 525 in 1.52 sec\n",
      "mean reward: 3.013425\n",
      "return standard deviation: 0.398862\n",
      "min return: 1.616813; max return: 4.778531\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.005746208 0.031761862 0.07091242\n",
      "episode 526 in 1.51 sec\n",
      "mean reward: 3.084103\n",
      "return standard deviation: 0.384223\n",
      "min return: 1.776782; max return: 4.405750\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.1540385 0.043212943 0.07090074\n",
      "episode 527 in 1.48 sec\n",
      "mean reward: 3.113622\n",
      "return standard deviation: 0.451748\n",
      "min return: 1.259530; max return: 4.320519\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.1616917 0.03189183 0.07088706\n",
      "episode 528 in 1.49 sec\n",
      "mean reward: 3.066550\n",
      "return standard deviation: 0.449478\n",
      "min return: 2.112121; max return: 4.405750\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.5115144 0.03444711 0.07086994\n",
      "episode 529 in 1.46 sec\n",
      "mean reward: 2.999133\n",
      "return standard deviation: 0.523424\n",
      "min return: 0.887932; max return: 4.594768\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.42578986 0.034513365 0.070848554\n",
      "episode 530 in 1.48 sec\n",
      "mean reward: 3.085365\n",
      "return standard deviation: 0.434332\n",
      "min return: 1.224481; max return: 4.160548\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.023509532 0.038047764 0.07082953\n",
      "episode 531 in 1.48 sec\n",
      "mean reward: 3.065830\n",
      "return standard deviation: 0.414072\n",
      "min return: 1.148844; max return: 4.509747\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.44676533 0.0395088 0.0708024\n",
      "episode 532 in 1.49 sec\n",
      "mean reward: 3.040081\n",
      "return standard deviation: 0.394697\n",
      "min return: 1.776782; max return: 4.568682\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.46140015 0.045744363 0.07078001\n",
      "episode 533 in 1.49 sec\n",
      "mean reward: 3.085440\n",
      "return standard deviation: 0.420183\n",
      "min return: 2.031725; max return: 4.199702\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.42596027 0.04090301 0.07077015\n",
      "episode 534 in 1.46 sec\n",
      "mean reward: 3.044434\n",
      "return standard deviation: 0.382020\n",
      "min return: 1.974878; max return: 4.163929\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.38005564 0.03252979 0.07076812\n",
      "episode 535 in 1.48 sec\n",
      "mean reward: 3.040061\n",
      "return standard deviation: 0.388471\n",
      "min return: 1.751219; max return: 4.306769\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.18594027 0.036177203 0.070765465\n",
      "episode 536 in 1.57 sec\n",
      "mean reward: 3.073449\n",
      "return standard deviation: 0.466647\n",
      "min return: 1.283949; max return: 4.405750\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.5437005 0.034610074 0.07076139\n",
      "episode 537 in 1.47 sec\n",
      "mean reward: 3.072461\n",
      "return standard deviation: 0.416120\n",
      "min return: 1.690012; max return: 4.155881\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.37540358 0.03518296 0.07076541\n",
      "episode 538 in 1.48 sec\n",
      "mean reward: 3.103264\n",
      "return standard deviation: 0.429797\n",
      "min return: 1.798687; max return: 4.839312\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.7033712 0.038192075 0.07077007\n",
      "episode 539 in 1.50 sec\n",
      "mean reward: 3.086319\n",
      "return standard deviation: 0.449370\n",
      "min return: 1.377668; max return: 4.160548\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.19801141 0.030574067 0.07078523\n",
      "episode 540 in 1.49 sec\n",
      "mean reward: 3.078560\n",
      "return standard deviation: 0.461535\n",
      "min return: 1.751219; max return: 4.160548\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.23336133 0.02745111 0.07079317\n",
      "episode 541 in 1.56 sec\n",
      "mean reward: 3.024320\n",
      "return standard deviation: 0.442138\n",
      "min return: 1.776782; max return: 4.306071\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.41632935 0.028196625 0.07078989\n",
      "episode 542 in 1.51 sec\n",
      "mean reward: 3.045857\n",
      "return standard deviation: 0.432438\n",
      "min return: 1.751219; max return: 4.160548\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.59254026 0.029873976 0.070785016\n",
      "episode 543 in 1.54 sec\n",
      "mean reward: 3.065947\n",
      "return standard deviation: 0.450407\n",
      "min return: 1.220645; max return: 4.248051\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.8741518 0.036997218 0.07078333\n",
      "episode 544 in 1.52 sec\n",
      "mean reward: 3.112786\n",
      "return standard deviation: 0.495901\n",
      "min return: 1.393838; max return: 4.363351\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.34566656 0.02825381 0.070802584\n",
      "episode 545 in 1.48 sec\n",
      "mean reward: 3.130395\n",
      "return standard deviation: 0.456679\n",
      "min return: 1.751219; max return: 4.594768\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.3244806 0.027835902 0.070819855\n",
      "episode 546 in 1.49 sec\n",
      "mean reward: 3.070351\n",
      "return standard deviation: 0.449570\n",
      "min return: 1.749734; max return: 4.216338\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.23768224 0.025195163 0.07083407\n",
      "episode 547 in 1.49 sec\n",
      "mean reward: 3.081730\n",
      "return standard deviation: 0.420467\n",
      "min return: 1.978862; max return: 4.363351\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.38877204 0.028942943 0.07084433\n",
      "episode 548 in 1.48 sec\n",
      "mean reward: 3.073692\n",
      "return standard deviation: 0.386654\n",
      "min return: 1.833755; max return: 4.160548\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.39667684 0.027228184 0.07084984\n",
      "episode 549 in 1.57 sec\n",
      "mean reward: 3.073209\n",
      "return standard deviation: 0.403036\n",
      "min return: 1.925556; max return: 4.196696\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.4428413 0.029476577 0.07085956\n",
      "episode 550 in 1.50 sec\n",
      "mean reward: 3.079365\n",
      "return standard deviation: 0.488706\n",
      "min return: 1.133118; max return: 4.605452\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.29064685 0.024133842 0.07086286\n",
      "episode 551 in 1.51 sec\n",
      "mean reward: 3.073952\n",
      "return standard deviation: 0.439293\n",
      "min return: 1.762298; max return: 4.248051\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.5587724 0.030874446 0.07086388\n",
      "episode 552 in 1.49 sec\n",
      "mean reward: 3.069789\n",
      "return standard deviation: 0.427890\n",
      "min return: 1.751219; max return: 4.725141\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.5958221 0.022604687 0.07087122\n",
      "episode 553 in 1.55 sec\n",
      "mean reward: 3.037205\n",
      "return standard deviation: 0.443736\n",
      "min return: 1.267508; max return: 4.160548\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.9320657 0.03045004 0.07088302\n",
      "episode 554 in 1.48 sec\n",
      "mean reward: 3.045732\n",
      "return standard deviation: 0.450333\n",
      "min return: 1.069899; max return: 4.160548\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.31300184 0.03396717 0.07090819\n",
      "episode 555 in 1.52 sec\n",
      "mean reward: 3.049781\n",
      "return standard deviation: 0.450259\n",
      "min return: 2.168022; max return: 4.753722\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.19977242 0.030962314 0.07092647\n",
      "episode 556 in 1.52 sec\n",
      "mean reward: 3.110048\n",
      "return standard deviation: 0.425183\n",
      "min return: 1.963120; max return: 4.211299\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.45552275 0.032072205 0.07093812\n",
      "episode 557 in 1.48 sec\n",
      "mean reward: 3.046686\n",
      "return standard deviation: 0.440429\n",
      "min return: 1.796609; max return: 4.694781\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.5204259 0.033310916 0.07094742\n",
      "episode 558 in 1.55 sec\n",
      "mean reward: 3.134766\n",
      "return standard deviation: 0.414058\n",
      "min return: 1.776782; max return: 4.216790\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.36498022 0.029160883 0.07096528\n",
      "episode 559 in 1.52 sec\n",
      "mean reward: 3.090353\n",
      "return standard deviation: 0.392033\n",
      "min return: 1.720534; max return: 4.188648\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.2756704 0.035414807 0.070985384\n",
      "episode 560 in 1.50 sec\n",
      "mean reward: 3.039579\n",
      "return standard deviation: 0.430699\n",
      "min return: 1.850051; max return: 4.591735\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.10872683 0.029036961 0.071001135\n",
      "episode 561 in 1.48 sec\n",
      "mean reward: 3.105526\n",
      "return standard deviation: 0.445900\n",
      "min return: 1.751219; max return: 4.694781\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.228218 0.031388663 0.071007624\n",
      "episode 562 in 1.49 sec\n",
      "mean reward: 3.089288\n",
      "return standard deviation: 0.393981\n",
      "min return: 2.164495; max return: 4.568682\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.29170945 0.040559296 0.07101142\n",
      "episode 563 in 1.50 sec\n",
      "mean reward: 3.012427\n",
      "return standard deviation: 0.428705\n",
      "min return: 1.549910; max return: 4.211299\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.3348086 0.042820733 0.07102136\n",
      "episode 564 in 1.47 sec\n",
      "mean reward: 3.117642\n",
      "return standard deviation: 0.420721\n",
      "min return: 2.075710; max return: 4.383935\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.4947133 0.042108413 0.07103502\n",
      "episode 565 in 1.55 sec\n",
      "mean reward: 3.045527\n",
      "return standard deviation: 0.381179\n",
      "min return: 1.776782; max return: 4.160548\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.475366 0.040216677 0.07105194\n",
      "episode 566 in 1.57 sec\n",
      "mean reward: 3.049814\n",
      "return standard deviation: 0.404970\n",
      "min return: 2.086073; max return: 4.216790\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.52935994 0.036814317 0.07107507\n",
      "episode 567 in 1.48 sec\n",
      "mean reward: 3.005396\n",
      "return standard deviation: 0.409446\n",
      "min return: 1.135196; max return: 4.163929\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.34404737 0.03376169 0.07110637\n",
      "episode 568 in 1.48 sec\n",
      "mean reward: 3.076182\n",
      "return standard deviation: 0.409787\n",
      "min return: 1.212615; max return: 4.188648\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.007616639 0.029894123 0.07113206\n",
      "episode 569 in 1.46 sec\n",
      "mean reward: 3.117782\n",
      "return standard deviation: 0.384062\n",
      "min return: 1.958194; max return: 4.306071\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.22194676 0.034561627 0.07115187\n",
      "episode 570 in 1.47 sec\n",
      "mean reward: 3.094660\n",
      "return standard deviation: 0.424702\n",
      "min return: 1.751219; max return: 4.492890\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.35654962 0.036009938 0.07116731\n",
      "episode 571 in 1.46 sec\n",
      "mean reward: 3.051180\n",
      "return standard deviation: 0.423241\n",
      "min return: 1.431030; max return: 4.163929\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.25335342 0.03196065 0.07118175\n",
      "episode 572 in 1.46 sec\n",
      "mean reward: 3.078679\n",
      "return standard deviation: 0.424219\n",
      "min return: 1.448850; max return: 4.160548\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.35776466 0.035098847 0.071197174\n",
      "episode 573 in 1.45 sec\n",
      "mean reward: 3.071158\n",
      "return standard deviation: 0.368624\n",
      "min return: 2.167862; max return: 4.442508\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.5479273 0.03901472 0.07121358\n",
      "episode 574 in 1.49 sec\n",
      "mean reward: 3.042767\n",
      "return standard deviation: 0.371629\n",
      "min return: 1.323431; max return: 4.160548\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.4136039 0.03559291 0.07123338\n",
      "episode 575 in 1.58 sec\n",
      "mean reward: 3.095035\n",
      "return standard deviation: 0.435901\n",
      "min return: 2.006641; max return: 4.225237\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.14599712 0.026885394 0.07125129\n",
      "episode 576 in 1.59 sec\n",
      "mean reward: 3.076572\n",
      "return standard deviation: 0.350080\n",
      "min return: 1.803740; max return: 4.090727\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.3523056 0.029454002 0.07126133\n",
      "episode 577 in 1.50 sec\n",
      "mean reward: 3.016311\n",
      "return standard deviation: 0.365369\n",
      "min return: 1.751219; max return: 4.168999\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.27630347 0.029720448 0.07126707\n",
      "episode 578 in 1.55 sec\n",
      "mean reward: 3.084557\n",
      "return standard deviation: 0.461131\n",
      "min return: 1.354503; max return: 4.294452\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.14182124 0.026387898 0.07127444\n",
      "episode 579 in 1.58 sec\n",
      "mean reward: 3.084697\n",
      "return standard deviation: 0.518153\n",
      "min return: 1.487849; max return: 6.833318\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.23237157 0.029195119 0.07127332\n",
      "episode 580 in 1.52 sec\n",
      "mean reward: 3.042834\n",
      "return standard deviation: 0.364603\n",
      "min return: 2.175970; max return: 4.160548\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison 0.06682767 0.027038502 0.07127014\n",
      "episode 581 in 1.57 sec\n",
      "mean reward: 3.137573\n",
      "return standard deviation: 0.397401\n",
      "min return: 1.751219; max return: 4.538593\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.69830453 0.033012778 0.07126064\n",
      "episode 582 in 1.48 sec\n",
      "mean reward: 3.050880\n",
      "return standard deviation: 0.435009\n",
      "min return: 0.756359; max return: 4.223368\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.30029255 0.028808381 0.07126405\n",
      "episode 583 in 1.47 sec\n",
      "mean reward: 3.113481\n",
      "return standard deviation: 0.419341\n",
      "min return: 1.843734; max return: 4.216338\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.6133621 0.036521234 0.07127006\n",
      "episode 584 in 1.48 sec\n",
      "mean reward: 3.045045\n",
      "return standard deviation: 0.384537\n",
      "min return: 1.574466; max return: 4.216338\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.45257095 0.036759343 0.071290374\n",
      "episode 585 in 1.54 sec\n",
      "mean reward: 3.054435\n",
      "return standard deviation: 0.370043\n",
      "min return: 1.800994; max return: 4.190999\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.17966533 0.030079734 0.071314536\n",
      "episode 586 in 1.47 sec\n",
      "mean reward: 3.088782\n",
      "return standard deviation: 0.379204\n",
      "min return: 2.067214; max return: 4.405750\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.20317295 0.026593702 0.071333736\n",
      "episode 587 in 1.51 sec\n",
      "mean reward: 3.049980\n",
      "return standard deviation: 0.406546\n",
      "min return: 0.789889; max return: 4.144032\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.30805424 0.028111938 0.07134516\n",
      "episode 588 in 1.49 sec\n",
      "mean reward: 3.040736\n",
      "return standard deviation: 0.480398\n",
      "min return: 0.984491; max return: 4.216338\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.1721349 0.026997052 0.071351014\n",
      "episode 589 in 1.48 sec\n",
      "mean reward: 3.075423\n",
      "return standard deviation: 0.381288\n",
      "min return: 1.855050; max return: 4.196696\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.09186756 0.02916849 0.07134831\n",
      "episode 590 in 1.48 sec\n",
      "mean reward: 3.088425\n",
      "return standard deviation: 0.417881\n",
      "min return: 1.562673; max return: 4.405750\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.022933371 0.027157046 0.071341105\n",
      "episode 591 in 1.57 sec\n",
      "mean reward: 3.133915\n",
      "return standard deviation: 0.373019\n",
      "min return: 1.892201; max return: 4.216338\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.37239748 0.039592274 0.07132958\n",
      "episode 592 in 1.49 sec\n",
      "mean reward: 3.054824\n",
      "return standard deviation: 0.400031\n",
      "min return: 1.984526; max return: 4.188648\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.3861711 0.033954404 0.07132289\n",
      "episode 593 in 1.47 sec\n",
      "mean reward: 3.100499\n",
      "return standard deviation: 0.433678\n",
      "min return: 0.875113; max return: 4.216338\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.4104159 0.03763212 0.07132294\n",
      "episode 594 in 1.48 sec\n",
      "mean reward: 3.110357\n",
      "return standard deviation: 0.420435\n",
      "min return: 1.320199; max return: 4.207473\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.5252192 0.03736257 0.0713329\n",
      "episode 595 in 1.54 sec\n",
      "mean reward: 3.075179\n",
      "return standard deviation: 0.428803\n",
      "min return: 1.675366; max return: 4.163929\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.1385583 0.031347293 0.071350925\n",
      "episode 596 in 1.52 sec\n",
      "mean reward: 3.089253\n",
      "return standard deviation: 0.401354\n",
      "min return: 2.037282; max return: 4.405750\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.22460477 0.031894468 0.071359\n",
      "episode 597 in 1.55 sec\n",
      "mean reward: 3.112804\n",
      "return standard deviation: 0.416359\n",
      "min return: 2.070430; max return: 4.374565\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.08170938 0.026278723 0.07136101\n",
      "episode 598 in 1.48 sec\n",
      "mean reward: 3.114731\n",
      "return standard deviation: 0.395898\n",
      "min return: 1.263439; max return: 4.275255\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.21780682 0.028026292 0.07135723\n",
      "episode 599 in 1.47 sec\n",
      "mean reward: 3.126043\n",
      "return standard deviation: 0.401034\n",
      "min return: 0.891292; max return: 4.160548\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison 0.015415825 0.025702525 0.07134992\n",
      "episode 600 in 1.49 sec\n",
      "mean reward: 3.116903\n",
      "return standard deviation: 0.461818\n",
      "min return: 1.751219; max return: 4.175912\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.1548441 0.034714237 0.071331985\n",
      "episode 601 in 1.50 sec\n",
      "mean reward: 3.059045\n",
      "return standard deviation: 0.392919\n",
      "min return: 1.751219; max return: 4.155881\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.06899451 0.02822855 0.071310736\n",
      "episode 602 in 1.51 sec\n",
      "mean reward: 3.088692\n",
      "return standard deviation: 0.392062\n",
      "min return: 1.751219; max return: 4.188648\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.18787207 0.03042415 0.07128713\n",
      "episode 603 in 1.54 sec\n",
      "mean reward: 3.088428\n",
      "return standard deviation: 0.383172\n",
      "min return: 2.181829; max return: 4.221879\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.21676034 0.032630406 0.071264245\n",
      "episode 604 in 1.52 sec\n",
      "mean reward: 3.094529\n",
      "return standard deviation: 0.400899\n",
      "min return: 1.457941; max return: 4.216338\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.40681487 0.03877145 0.07124722\n",
      "episode 605 in 1.53 sec\n",
      "mean reward: 3.100257\n",
      "return standard deviation: 0.442790\n",
      "min return: 2.083895; max return: 4.815094\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.48925003 0.040413935 0.07123873\n",
      "episode 606 in 1.53 sec\n",
      "mean reward: 3.125496\n",
      "return standard deviation: 0.430046\n",
      "min return: 1.209084; max return: 4.415377\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.21220784 0.037176434 0.07124114\n",
      "episode 607 in 1.57 sec\n",
      "mean reward: 3.087808\n",
      "return standard deviation: 0.398745\n",
      "min return: 1.959194; max return: 4.442508\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.30896652 0.03293726 0.07124102\n",
      "episode 608 in 1.50 sec\n",
      "mean reward: 3.067325\n",
      "return standard deviation: 0.420039\n",
      "min return: 1.349377; max return: 4.163929\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison 0.014886044 0.026328012 0.07124422\n",
      "episode 609 in 1.51 sec\n",
      "mean reward: 3.120263\n",
      "return standard deviation: 0.369610\n",
      "min return: 2.181829; max return: 4.163929\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.4696274 0.032301553 0.07124318\n",
      "episode 610 in 1.48 sec\n",
      "mean reward: 3.075034\n",
      "return standard deviation: 0.386256\n",
      "min return: 2.181829; max return: 4.160548\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.64374596 0.03906478 0.071244225\n",
      "episode 611 in 1.58 sec\n",
      "mean reward: 3.094337\n",
      "return standard deviation: 0.421891\n",
      "min return: 1.445621; max return: 4.216338\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.109722994 0.029802136 0.07126125\n",
      "episode 612 in 1.49 sec\n",
      "mean reward: 3.103701\n",
      "return standard deviation: 0.375891\n",
      "min return: 2.131357; max return: 4.160548\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.40107155 0.034383066 0.07127576\n",
      "episode 613 in 1.66 sec\n",
      "mean reward: 3.084912\n",
      "return standard deviation: 0.414460\n",
      "min return: 1.918625; max return: 4.216941\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.27585742 0.031033343 0.07129245\n",
      "episode 614 in 1.58 sec\n",
      "mean reward: 3.085721\n",
      "return standard deviation: 0.437572\n",
      "min return: 1.664821; max return: 4.155881\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.22014262 0.03851288 0.071304314\n",
      "episode 615 in 1.53 sec\n",
      "mean reward: 3.104721\n",
      "return standard deviation: 0.421768\n",
      "min return: 1.751219; max return: 4.351012\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.54795563 0.042515986 0.07132023\n",
      "episode 616 in 1.60 sec\n",
      "mean reward: 3.101943\n",
      "return standard deviation: 0.389876\n",
      "min return: 2.179163; max return: 4.174272\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.29551017 0.044274982 0.07134542\n",
      "episode 617 in 1.49 sec\n",
      "mean reward: 3.109181\n",
      "return standard deviation: 0.429377\n",
      "min return: 1.213003; max return: 4.984188\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.43192405 0.044362597 0.071373455\n",
      "episode 618 in 1.50 sec\n",
      "mean reward: 3.095465\n",
      "return standard deviation: 0.447252\n",
      "min return: 1.854284; max return: 4.741085\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.34517848 0.04373186 0.07139816\n",
      "episode 619 in 1.52 sec\n",
      "mean reward: 3.086311\n",
      "return standard deviation: 0.414980\n",
      "min return: 1.900614; max return: 5.177614\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.24152726 0.039546352 0.07143138\n",
      "episode 620 in 1.55 sec\n",
      "mean reward: 3.091011\n",
      "return standard deviation: 0.436599\n",
      "min return: 1.265761; max return: 4.670057\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.18106121 0.036273457 0.07145596\n",
      "episode 621 in 1.52 sec\n",
      "mean reward: 3.109801\n",
      "return standard deviation: 0.400142\n",
      "min return: 1.833755; max return: 4.169178\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.1505574 0.041789692 0.07147323\n",
      "episode 622 in 1.51 sec\n",
      "mean reward: 3.118672\n",
      "return standard deviation: 0.435367\n",
      "min return: 1.480546; max return: 5.379588\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.29106843 0.04271309 0.07148889\n",
      "episode 623 in 1.57 sec\n",
      "mean reward: 3.091046\n",
      "return standard deviation: 0.387269\n",
      "min return: 1.905785; max return: 4.216338\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.22547153 0.04044129 0.07150229\n",
      "episode 624 in 1.52 sec\n",
      "mean reward: 3.063708\n",
      "return standard deviation: 0.426212\n",
      "min return: 1.855050; max return: 4.491286\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.37707776 0.03878217 0.07150237\n",
      "episode 625 in 1.52 sec\n",
      "mean reward: 3.114059\n",
      "return standard deviation: 0.383562\n",
      "min return: 1.833755; max return: 4.355720\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.5511574 0.048455574 0.07151472\n",
      "episode 626 in 1.52 sec\n",
      "mean reward: 3.075007\n",
      "return standard deviation: 0.442166\n",
      "min return: 1.342617; max return: 4.493817\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.25107634 0.043197326 0.07154522\n",
      "episode 627 in 1.48 sec\n",
      "mean reward: 3.112333\n",
      "return standard deviation: 0.430376\n",
      "min return: 1.833755; max return: 4.264056\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.43294683 0.047408048 0.07157182\n",
      "episode 628 in 1.48 sec\n",
      "mean reward: 3.072451\n",
      "return standard deviation: 0.387958\n",
      "min return: 1.854653; max return: 4.216338\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.66752946 0.050760802 0.071590215\n",
      "episode 629 in 1.49 sec\n",
      "mean reward: 3.127885\n",
      "return standard deviation: 0.440196\n",
      "min return: 2.151169; max return: 4.561999\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.1681798 0.043091457 0.07161435\n",
      "episode 630 in 1.56 sec\n",
      "mean reward: 3.112103\n",
      "return standard deviation: 0.403200\n",
      "min return: 1.929685; max return: 4.156900\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.31577227 0.046927996 0.07163281\n",
      "episode 631 in 1.55 sec\n",
      "mean reward: 3.141669\n",
      "return standard deviation: 0.402405\n",
      "min return: 2.131652; max return: 4.219132\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.4612248 0.050870974 0.07164902\n",
      "episode 632 in 1.53 sec\n",
      "mean reward: 3.116724\n",
      "return standard deviation: 0.422876\n",
      "min return: 2.104049; max return: 5.429618\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.29446003 0.039638966 0.07165938\n",
      "episode 633 in 1.56 sec\n",
      "mean reward: 3.097558\n",
      "return standard deviation: 0.447516\n",
      "min return: 1.884345; max return: 4.674536\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.39485794 0.04705871 0.07166403\n",
      "episode 634 in 1.51 sec\n",
      "mean reward: 3.069044\n",
      "return standard deviation: 0.456191\n",
      "min return: 1.646247; max return: 4.713396\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.2975052 0.04753126 0.071671695\n",
      "episode 635 in 1.53 sec\n",
      "mean reward: 3.119506\n",
      "return standard deviation: 0.422100\n",
      "min return: 1.862144; max return: 4.155881\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.5321188 0.041835766 0.07167525\n",
      "episode 636 in 1.52 sec\n",
      "mean reward: 3.058308\n",
      "return standard deviation: 0.392101\n",
      "min return: 2.181829; max return: 4.188648\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.24988711 0.048078753 0.071677275\n",
      "episode 637 in 1.58 sec\n",
      "mean reward: 3.078781\n",
      "return standard deviation: 0.413147\n",
      "min return: 1.983839; max return: 5.412104\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.48524266 0.04975229 0.07167434\n",
      "episode 638 in 1.54 sec\n",
      "mean reward: 3.093865\n",
      "return standard deviation: 0.388317\n",
      "min return: 1.931198; max return: 4.160548\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.47622803 0.050857447 0.07167293\n",
      "episode 639 in 1.52 sec\n",
      "mean reward: 3.125958\n",
      "return standard deviation: 0.424632\n",
      "min return: 1.918315; max return: 4.698797\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.7822826 0.04849597 0.07167586\n",
      "episode 640 in 1.50 sec\n",
      "mean reward: 3.094812\n",
      "return standard deviation: 0.404189\n",
      "min return: 2.017071; max return: 4.554929\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.14450341 0.0534083 0.07169197\n",
      "episode 641 in 1.52 sec\n",
      "mean reward: 3.132933\n",
      "return standard deviation: 0.440480\n",
      "min return: 2.100789; max return: 5.520507\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.1883418 0.047933124 0.07170553\n",
      "episode 642 in 1.58 sec\n",
      "mean reward: 3.097717\n",
      "return standard deviation: 0.418434\n",
      "min return: 1.977260; max return: 4.163929\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.23142636 0.048714772 0.07170681\n",
      "episode 643 in 1.51 sec\n",
      "mean reward: 3.068407\n",
      "return standard deviation: 0.447737\n",
      "min return: 1.850051; max return: 5.027015\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.5794174 0.05376656 0.07170588\n",
      "episode 644 in 1.48 sec\n",
      "mean reward: 3.084944\n",
      "return standard deviation: 0.476984\n",
      "min return: 0.803614; max return: 5.278308\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.34359726 0.048453484 0.07171385\n",
      "episode 645 in 1.52 sec\n",
      "mean reward: 3.107763\n",
      "return standard deviation: 0.419463\n",
      "min return: 1.730065; max return: 5.540617\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.5867898 0.057017177 0.07172289\n",
      "episode 646 in 1.50 sec\n",
      "mean reward: 3.128928\n",
      "return standard deviation: 0.434826\n",
      "min return: 1.986554; max return: 4.984188\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.4322222 0.050315928 0.07174597\n",
      "episode 647 in 1.49 sec\n",
      "mean reward: 3.110414\n",
      "return standard deviation: 0.457159\n",
      "min return: 1.827942; max return: 4.525830\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.54888827 0.05428491 0.07176231\n",
      "episode 648 in 1.46 sec\n",
      "mean reward: 3.104159\n",
      "return standard deviation: 0.423030\n",
      "min return: 1.755847; max return: 4.640856\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.5708833 0.05628978 0.07178219\n",
      "episode 649 in 1.48 sec\n",
      "mean reward: 3.097724\n",
      "return standard deviation: 0.379618\n",
      "min return: 1.967649; max return: 4.175912\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.9310414 0.057792254 0.07179879\n",
      "episode 650 in 1.52 sec\n",
      "mean reward: 3.139019\n",
      "return standard deviation: 0.414257\n",
      "min return: 1.943298; max return: 4.226363\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.4111281 0.058454745 0.07182718\n",
      "episode 651 in 1.58 sec\n",
      "mean reward: 3.158950\n",
      "return standard deviation: 0.454601\n",
      "min return: 1.844884; max return: 4.854396\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.16654535 0.0489624 0.07185754\n",
      "episode 652 in 1.57 sec\n",
      "mean reward: 3.190658\n",
      "return standard deviation: 0.443153\n",
      "min return: 1.548223; max return: 5.077801\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.3941442 0.047522955 0.071881965\n",
      "episode 653 in 1.59 sec\n",
      "mean reward: 3.153939\n",
      "return standard deviation: 0.443274\n",
      "min return: 1.802181; max return: 5.536780\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.36809725 0.05067621 0.07190301\n",
      "episode 654 in 1.51 sec\n",
      "mean reward: 3.176342\n",
      "return standard deviation: 0.509782\n",
      "min return: 1.749485; max return: 5.005274\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.33693725 0.058565103 0.07191415\n",
      "episode 655 in 1.51 sec\n",
      "mean reward: 3.095092\n",
      "return standard deviation: 0.475604\n",
      "min return: 1.987799; max return: 4.850935\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.77607805 0.063291706 0.07191871\n",
      "episode 656 in 1.52 sec\n",
      "mean reward: 3.150398\n",
      "return standard deviation: 0.441194\n",
      "min return: 1.823786; max return: 5.150856\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.5049349 0.060930826 0.07192116\n",
      "episode 657 in 1.53 sec\n",
      "mean reward: 3.128215\n",
      "return standard deviation: 0.430895\n",
      "min return: 1.751219; max return: 5.262188\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.70064116 0.05844533 0.07193601\n",
      "episode 658 in 1.54 sec\n",
      "mean reward: 3.130335\n",
      "return standard deviation: 0.422058\n",
      "min return: 1.734079; max return: 4.489494\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.34931582 0.05973601 0.07194686\n",
      "episode 659 in 1.58 sec\n",
      "mean reward: 3.153870\n",
      "return standard deviation: 0.458879\n",
      "min return: 1.662851; max return: 5.604359\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -1.1391827 0.0667343 0.07193858\n",
      "episode 660 in 1.49 sec\n",
      "mean reward: 3.102559\n",
      "return standard deviation: 0.435637\n",
      "min return: 1.855189; max return: 4.149235\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.7032838 0.05661093 0.07193385\n",
      "episode 661 in 1.50 sec\n",
      "mean reward: 3.072044\n",
      "return standard deviation: 0.464243\n",
      "min return: 1.790519; max return: 4.233635\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.7485323 0.060479507 0.071927674\n",
      "episode 662 in 1.54 sec\n",
      "mean reward: 3.165831\n",
      "return standard deviation: 0.489660\n",
      "min return: 1.847705; max return: 6.108438\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.16290782 0.052361585 0.07193678\n",
      "episode 663 in 1.52 sec\n",
      "mean reward: 3.156943\n",
      "return standard deviation: 0.475253\n",
      "min return: 1.161330; max return: 4.885938\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.4462661 0.046363115 0.07194045\n",
      "episode 664 in 1.55 sec\n",
      "mean reward: 3.096549\n",
      "return standard deviation: 0.455680\n",
      "min return: 1.517339; max return: 4.539696\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.5599921 0.04888774 0.07194151\n",
      "episode 665 in 1.54 sec\n",
      "mean reward: 3.101975\n",
      "return standard deviation: 0.451145\n",
      "min return: 1.024208; max return: 4.647261\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.54449904 0.04751266 0.07195238\n",
      "episode 666 in 1.55 sec\n",
      "mean reward: 3.087492\n",
      "return standard deviation: 0.434302\n",
      "min return: 0.990433; max return: 4.401335\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.12145208 0.041787993 0.071956865\n",
      "episode 667 in 1.46 sec\n",
      "mean reward: 3.118156\n",
      "return standard deviation: 0.357021\n",
      "min return: 1.833755; max return: 4.155881\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.34841818 0.050355665 0.07195681\n",
      "episode 668 in 1.50 sec\n",
      "mean reward: 3.092852\n",
      "return standard deviation: 0.426306\n",
      "min return: 1.244871; max return: 4.216790\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.905792 0.06243013 0.07195889\n",
      "episode 669 in 1.58 sec\n",
      "mean reward: 3.094259\n",
      "return standard deviation: 0.423126\n",
      "min return: 0.857284; max return: 4.645958\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.8411341 0.056844387 0.071973234\n",
      "episode 670 in 1.54 sec\n",
      "mean reward: 3.111061\n",
      "return standard deviation: 0.441391\n",
      "min return: 1.480407; max return: 4.872962\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.5873264 0.053728104 0.07200325\n",
      "episode 671 in 1.53 sec\n",
      "mean reward: 3.093599\n",
      "return standard deviation: 0.400866\n",
      "min return: 1.245880; max return: 4.605452\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.2613817 0.04192622 0.07204173\n",
      "episode 672 in 1.54 sec\n",
      "mean reward: 3.070152\n",
      "return standard deviation: 0.390108\n",
      "min return: 1.407541; max return: 4.163929\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison 0.14297174 0.03888607 0.07207879\n",
      "episode 673 in 1.57 sec\n",
      "mean reward: 3.118500\n",
      "return standard deviation: 0.392416\n",
      "min return: 2.054466; max return: 4.478690\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison 0.08786419 0.036112238 0.0721022\n",
      "episode 674 in 1.50 sec\n",
      "mean reward: 3.031657\n",
      "return standard deviation: 0.425226\n",
      "min return: 1.751219; max return: 4.133982\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison 0.011870861 0.044548832 0.072104126\n",
      "episode 675 in 1.47 sec\n",
      "mean reward: 3.131494\n",
      "return standard deviation: 0.446906\n",
      "min return: 2.028997; max return: 6.330193\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.19675206 0.04098844 0.07210864\n",
      "episode 676 in 1.53 sec\n",
      "mean reward: 3.143210\n",
      "return standard deviation: 0.376211\n",
      "min return: 2.143122; max return: 4.705056\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.22887547 0.04103402 0.07211643\n",
      "episode 677 in 1.50 sec\n",
      "mean reward: 3.098821\n",
      "return standard deviation: 0.410146\n",
      "min return: 2.050159; max return: 5.181750\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.53676045 0.045215886 0.07212486\n",
      "episode 678 in 1.58 sec\n",
      "mean reward: 3.114293\n",
      "return standard deviation: 0.383955\n",
      "min return: 2.123950; max return: 4.490820\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.53157794 0.043036357 0.072142094\n",
      "episode 679 in 1.65 sec\n",
      "mean reward: 3.118579\n",
      "return standard deviation: 0.407154\n",
      "min return: 1.860254; max return: 4.492899\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.5871406 0.03948167 0.07216099\n",
      "episode 680 in 1.58 sec\n",
      "mean reward: 3.110283\n",
      "return standard deviation: 0.386969\n",
      "min return: 1.456501; max return: 4.421516\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.590878 0.046472277 0.07219214\n",
      "episode 681 in 1.57 sec\n",
      "mean reward: 3.097236\n",
      "return standard deviation: 0.422330\n",
      "min return: 2.026092; max return: 4.275755\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.41527808 0.039893165 0.07222561\n",
      "episode 682 in 1.51 sec\n",
      "mean reward: 3.135154\n",
      "return standard deviation: 0.366519\n",
      "min return: 2.122338; max return: 4.197197\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.2971766 0.037262548 0.07225878\n",
      "episode 683 in 1.57 sec\n",
      "mean reward: 3.115188\n",
      "return standard deviation: 0.417144\n",
      "min return: 1.570845; max return: 4.216338\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.29352468 0.035711344 0.072291695\n",
      "episode 684 in 1.64 sec\n",
      "mean reward: 3.084016\n",
      "return standard deviation: 0.395834\n",
      "min return: 1.932434; max return: 4.155881\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.13136058 0.039456595 0.07231704\n",
      "episode 685 in 1.61 sec\n",
      "mean reward: 3.073059\n",
      "return standard deviation: 0.425556\n",
      "min return: 1.751219; max return: 4.319057\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.5697229 0.039552037 0.07233465\n",
      "episode 686 in 1.57 sec\n",
      "mean reward: 3.082722\n",
      "return standard deviation: 0.447489\n",
      "min return: 1.187625; max return: 4.908745\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.5316546 0.040205885 0.072352365\n",
      "episode 687 in 1.51 sec\n",
      "mean reward: 3.132545\n",
      "return standard deviation: 0.400001\n",
      "min return: 1.864296; max return: 4.122612\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.27569464 0.04074873 0.07237554\n",
      "episode 688 in 1.50 sec\n",
      "mean reward: 3.158425\n",
      "return standard deviation: 0.377602\n",
      "min return: 1.853537; max return: 4.155881\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.48350227 0.04100025 0.07239641\n",
      "episode 689 in 1.50 sec\n",
      "mean reward: 3.131015\n",
      "return standard deviation: 0.405312\n",
      "min return: 2.010987; max return: 4.360545\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.3607657 0.04049855 0.072424464\n",
      "episode 690 in 1.54 sec\n",
      "mean reward: 3.099467\n",
      "return standard deviation: 0.430152\n",
      "min return: 1.863527; max return: 4.580033\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.6622015 0.040797774 0.07245025\n",
      "episode 691 in 1.48 sec\n",
      "mean reward: 3.120046\n",
      "return standard deviation: 0.434270\n",
      "min return: 0.909103; max return: 4.216338\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.36593983 0.04466398 0.07247569\n",
      "episode 692 in 1.57 sec\n",
      "mean reward: 3.132557\n",
      "return standard deviation: 0.353161\n",
      "min return: 1.943108; max return: 4.524479\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.2883808 0.045794897 0.07250453\n",
      "episode 693 in 1.47 sec\n",
      "mean reward: 3.122926\n",
      "return standard deviation: 0.413185\n",
      "min return: 1.833755; max return: 4.133478\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.49486297 0.049244866 0.07252193\n",
      "episode 694 in 1.47 sec\n",
      "mean reward: 3.138610\n",
      "return standard deviation: 0.453092\n",
      "min return: 1.534424; max return: 4.313274\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.11453605 0.04230106 0.072542615\n",
      "episode 695 in 1.47 sec\n",
      "mean reward: 3.158894\n",
      "return standard deviation: 0.401164\n",
      "min return: 1.827942; max return: 4.608000\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.26529187 0.04729179 0.07256966\n",
      "episode 696 in 1.54 sec\n",
      "mean reward: 3.189171\n",
      "return standard deviation: 0.415724\n",
      "min return: 1.955519; max return: 4.956733\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.47659636 0.05521752 0.07259905\n",
      "episode 697 in 1.52 sec\n",
      "mean reward: 3.179871\n",
      "return standard deviation: 0.443946\n",
      "min return: 1.991001; max return: 4.659865\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -1.1688298 0.06737612 0.072629705\n",
      "episode 698 in 1.54 sec\n",
      "mean reward: 3.118652\n",
      "return standard deviation: 0.480170\n",
      "min return: 1.284682; max return: 4.615592\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.63426834 0.051306587 0.07269269\n",
      "episode 699 in 1.48 sec\n",
      "mean reward: 3.139548\n",
      "return standard deviation: 0.415112\n",
      "min return: 1.839310; max return: 4.095850\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.69323415 0.059896626 0.072752394\n",
      "episode 700 in 1.55 sec\n",
      "mean reward: 3.120532\n",
      "return standard deviation: 0.396960\n",
      "min return: 1.952537; max return: 4.408750\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.21925265 0.049517717 0.072808266\n",
      "episode 701 in 1.51 sec\n",
      "mean reward: 3.159074\n",
      "return standard deviation: 0.410276\n",
      "min return: 1.827942; max return: 4.848061\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.49136955 0.04712968 0.0728563\n",
      "episode 702 in 1.49 sec\n",
      "mean reward: 3.108368\n",
      "return standard deviation: 0.407956\n",
      "min return: 1.442657; max return: 4.642959\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.6861 0.058559053 0.07290314\n",
      "episode 703 in 1.47 sec\n",
      "mean reward: 3.096519\n",
      "return standard deviation: 0.410923\n",
      "min return: 1.985410; max return: 4.738209\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.4838419 0.044607684 0.07294544\n",
      "episode 704 in 1.53 sec\n",
      "mean reward: 3.135204\n",
      "return standard deviation: 0.381044\n",
      "min return: 1.918315; max return: 4.160548\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.57408553 0.05240888 0.07297987\n",
      "episode 705 in 1.51 sec\n",
      "mean reward: 3.124268\n",
      "return standard deviation: 0.379767\n",
      "min return: 1.875625; max return: 4.090765\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.38197213 0.050526597 0.07300719\n",
      "episode 706 in 1.56 sec\n",
      "mean reward: 3.152645\n",
      "return standard deviation: 0.411485\n",
      "min return: 2.104535; max return: 4.342296\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.6111549 0.061660014 0.07303937\n",
      "episode 707 in 1.48 sec\n",
      "mean reward: 3.131119\n",
      "return standard deviation: 0.427762\n",
      "min return: 1.129057; max return: 4.503407\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.6127566 0.05539032 0.073072836\n",
      "episode 708 in 1.48 sec\n",
      "mean reward: 3.112875\n",
      "return standard deviation: 0.390179\n",
      "min return: 1.943108; max return: 4.190556\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.82204825 0.05156915 0.073108286\n",
      "episode 709 in 1.54 sec\n",
      "mean reward: 3.139183\n",
      "return standard deviation: 0.402152\n",
      "min return: 1.453844; max return: 4.463099\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.59151894 0.04591787 0.0731488\n",
      "episode 710 in 1.49 sec\n",
      "mean reward: 3.089220\n",
      "return standard deviation: 0.378045\n",
      "min return: 1.892140; max return: 4.387722\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.59194803 0.050976977 0.07319582\n",
      "episode 711 in 1.54 sec\n",
      "mean reward: 3.117649\n",
      "return standard deviation: 0.402613\n",
      "min return: 1.936280; max return: 4.448966\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.120106325 0.043156784 0.073245496\n",
      "episode 712 in 1.48 sec\n",
      "mean reward: 3.160589\n",
      "return standard deviation: 0.416453\n",
      "min return: 2.000935; max return: 4.970806\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.37172788 0.043668352 0.073285595\n",
      "episode 713 in 1.48 sec\n",
      "mean reward: 3.137564\n",
      "return standard deviation: 0.408188\n",
      "min return: 1.884125; max return: 4.442964\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.23641092 0.043858506 0.07332412\n",
      "episode 714 in 1.48 sec\n",
      "mean reward: 3.195631\n",
      "return standard deviation: 0.413054\n",
      "min return: 1.792277; max return: 4.840456\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.5101333 0.040913902 0.07336444\n",
      "episode 715 in 1.46 sec\n",
      "mean reward: 3.144296\n",
      "return standard deviation: 0.381202\n",
      "min return: 1.930774; max return: 4.240149\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.41356105 0.043554988 0.07340012\n",
      "episode 716 in 1.47 sec\n",
      "mean reward: 3.181323\n",
      "return standard deviation: 0.404816\n",
      "min return: 1.988481; max return: 4.590315\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.03318923 0.045010775 0.07343212\n",
      "episode 717 in 1.47 sec\n",
      "mean reward: 3.149697\n",
      "return standard deviation: 0.406472\n",
      "min return: 1.903620; max return: 4.674957\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.35807148 0.047317304 0.0734564\n",
      "episode 718 in 1.50 sec\n",
      "mean reward: 3.133944\n",
      "return standard deviation: 0.387473\n",
      "min return: 2.134661; max return: 4.499064\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.69480795 0.05246712 0.07347509\n",
      "episode 719 in 1.48 sec\n",
      "mean reward: 3.136094\n",
      "return standard deviation: 0.398213\n",
      "min return: 1.514284; max return: 4.155881\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.4648064 0.052660678 0.07350007\n",
      "episode 720 in 1.47 sec\n",
      "mean reward: 3.150080\n",
      "return standard deviation: 0.459389\n",
      "min return: 2.137856; max return: 4.826207\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.24818729 0.04788661 0.07353238\n",
      "episode 721 in 1.48 sec\n",
      "mean reward: 3.197717\n",
      "return standard deviation: 0.397581\n",
      "min return: 1.943108; max return: 5.107089\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.46121153 0.05089493 0.073566\n",
      "episode 722 in 1.49 sec\n",
      "mean reward: 3.097251\n",
      "return standard deviation: 0.443128\n",
      "min return: 2.066902; max return: 5.604359\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.18049307 0.045071777 0.073600605\n",
      "episode 723 in 1.57 sec\n",
      "mean reward: 3.145175\n",
      "return standard deviation: 0.430689\n",
      "min return: 1.443164; max return: 4.851117\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.3307302 0.046631314 0.07362072\n",
      "episode 724 in 1.55 sec\n",
      "mean reward: 3.152958\n",
      "return standard deviation: 0.439750\n",
      "min return: 2.054466; max return: 4.883886\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.63909376 0.050152194 0.07362365\n",
      "episode 725 in 1.51 sec\n",
      "mean reward: 3.104280\n",
      "return standard deviation: 0.381449\n",
      "min return: 2.033103; max return: 4.704100\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.6399237 0.05059046 0.07362433\n",
      "episode 726 in 1.52 sec\n",
      "mean reward: 3.102043\n",
      "return standard deviation: 0.400480\n",
      "min return: 1.698482; max return: 4.592643\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.49661604 0.050999977 0.07362585\n",
      "episode 727 in 1.51 sec\n",
      "mean reward: 3.121602\n",
      "return standard deviation: 0.453243\n",
      "min return: 0.772241; max return: 4.908745\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.26204157 0.04408056 0.07364738\n",
      "episode 728 in 1.56 sec\n",
      "mean reward: 3.156976\n",
      "return standard deviation: 0.372471\n",
      "min return: 1.953904; max return: 4.459374\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.34246203 0.043864492 0.073669754\n",
      "episode 729 in 1.56 sec\n",
      "mean reward: 3.163155\n",
      "return standard deviation: 0.414111\n",
      "min return: 2.082613; max return: 5.521173\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.35724866 0.045583293 0.07369757\n",
      "episode 730 in 1.51 sec\n",
      "mean reward: 3.102103\n",
      "return standard deviation: 0.370005\n",
      "min return: 2.033103; max return: 4.075326\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.4184876 0.04982624 0.07371932\n",
      "episode 731 in 1.55 sec\n",
      "mean reward: 3.186660\n",
      "return standard deviation: 0.401182\n",
      "min return: 2.127098; max return: 4.500478\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.22351454 0.04424313 0.07373915\n",
      "episode 732 in 1.53 sec\n",
      "mean reward: 3.206037\n",
      "return standard deviation: 0.395296\n",
      "min return: 1.263444; max return: 4.512519\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.40085602 0.04659491 0.07376795\n",
      "episode 733 in 1.52 sec\n",
      "mean reward: 3.154077\n",
      "return standard deviation: 0.394776\n",
      "min return: 2.026092; max return: 4.533111\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.401725 0.052869413 0.07379572\n",
      "episode 734 in 1.54 sec\n",
      "mean reward: 3.145580\n",
      "return standard deviation: 0.404622\n",
      "min return: 1.389467; max return: 4.340498\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.3608099 0.05054904 0.07382782\n",
      "episode 735 in 1.49 sec\n",
      "mean reward: 3.111669\n",
      "return standard deviation: 0.406653\n",
      "min return: 1.931198; max return: 4.640779\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.38221884 0.05540067 0.07384917\n",
      "episode 736 in 1.57 sec\n",
      "mean reward: 3.127810\n",
      "return standard deviation: 0.379014\n",
      "min return: 2.056559; max return: 4.365236\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.65867037 0.054118834 0.073875375\n",
      "episode 737 in 1.49 sec\n",
      "mean reward: 3.174717\n",
      "return standard deviation: 0.428254\n",
      "min return: 1.210055; max return: 4.589537\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.4429965 0.056798633 0.07390637\n",
      "episode 738 in 1.52 sec\n",
      "mean reward: 3.174012\n",
      "return standard deviation: 0.435458\n",
      "min return: 1.662269; max return: 4.660217\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.48726785 0.05977917 0.073940046\n",
      "episode 739 in 1.55 sec\n",
      "mean reward: 3.137669\n",
      "return standard deviation: 0.412979\n",
      "min return: 2.026789; max return: 4.545463\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.78390443 0.060158245 0.07397629\n",
      "episode 740 in 1.52 sec\n",
      "mean reward: 3.114701\n",
      "return standard deviation: 0.436717\n",
      "min return: 2.042790; max return: 4.960722\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.5286305 0.055525023 0.074008025\n",
      "episode 741 in 1.51 sec\n",
      "mean reward: 3.225873\n",
      "return standard deviation: 0.407677\n",
      "min return: 2.060388; max return: 4.713195\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.59656847 0.06513393 0.074049234\n",
      "episode 742 in 1.55 sec\n",
      "mean reward: 3.124253\n",
      "return standard deviation: 0.410209\n",
      "min return: 2.216190; max return: 4.478690\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.5220027 0.058432423 0.0740909\n",
      "episode 743 in 1.56 sec\n",
      "mean reward: 3.174275\n",
      "return standard deviation: 0.464398\n",
      "min return: 1.931198; max return: 4.807197\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.57958466 0.057980068 0.074125886\n",
      "episode 744 in 1.60 sec\n",
      "mean reward: 3.144623\n",
      "return standard deviation: 0.424136\n",
      "min return: 1.949527; max return: 4.720403\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.5924836 0.056721374 0.07416071\n",
      "episode 745 in 1.55 sec\n",
      "mean reward: 3.137402\n",
      "return standard deviation: 0.414742\n",
      "min return: 2.009871; max return: 4.714657\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.42231935 0.050966028 0.074187994\n",
      "episode 746 in 1.56 sec\n",
      "mean reward: 3.142998\n",
      "return standard deviation: 0.430671\n",
      "min return: 1.557174; max return: 4.336713\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.5854163 0.05315104 0.074216984\n",
      "episode 747 in 1.55 sec\n",
      "mean reward: 3.127764\n",
      "return standard deviation: 0.434550\n",
      "min return: 1.371284; max return: 4.244441\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.5155347 0.05471955 0.07425396\n",
      "episode 748 in 1.48 sec\n",
      "mean reward: 3.119542\n",
      "return standard deviation: 0.383475\n",
      "min return: 2.075829; max return: 4.476550\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.19164868 0.045301706 0.07428123\n",
      "episode 749 in 1.53 sec\n",
      "mean reward: 3.246352\n",
      "return standard deviation: 0.421337\n",
      "min return: 2.066550; max return: 4.772823\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.618106 0.05491188 0.07430508\n",
      "episode 750 in 1.48 sec\n",
      "mean reward: 3.162601\n",
      "return standard deviation: 0.468711\n",
      "min return: 0.902757; max return: 5.604359\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.4975234 0.0549484 0.07433901\n",
      "episode 751 in 1.55 sec\n",
      "mean reward: 3.178426\n",
      "return standard deviation: 0.401308\n",
      "min return: 2.157010; max return: 4.601180\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.39964798 0.05246101 0.074374095\n",
      "episode 752 in 1.58 sec\n",
      "mean reward: 3.192547\n",
      "return standard deviation: 0.426572\n",
      "min return: 1.506293; max return: 4.565175\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.17494923 0.04825919 0.07440697\n",
      "episode 753 in 1.55 sec\n",
      "mean reward: 3.144315\n",
      "return standard deviation: 0.369460\n",
      "min return: 2.006378; max return: 4.440203\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.43214384 0.054068483 0.0744363\n",
      "episode 754 in 1.48 sec\n",
      "mean reward: 3.152285\n",
      "return standard deviation: 0.412932\n",
      "min return: 1.844884; max return: 4.642254\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.3925053 0.063500725 0.074464805\n",
      "episode 755 in 1.48 sec\n",
      "mean reward: 3.190251\n",
      "return standard deviation: 0.443330\n",
      "min return: 1.883646; max return: 5.094140\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.2579224 0.06024024 0.07449828\n",
      "episode 756 in 1.47 sec\n",
      "mean reward: 3.147101\n",
      "return standard deviation: 0.444184\n",
      "min return: 1.950616; max return: 4.750453\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.6665314 0.050793473 0.074516855\n",
      "episode 757 in 1.47 sec\n",
      "mean reward: 3.125997\n",
      "return standard deviation: 0.404749\n",
      "min return: 1.946376; max return: 5.129100\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.39331478 0.05788884 0.074540496\n",
      "episode 758 in 1.48 sec\n",
      "mean reward: 3.237441\n",
      "return standard deviation: 0.429011\n",
      "min return: 0.983365; max return: 4.851964\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.30196175 0.048942897 0.07456982\n",
      "episode 759 in 1.51 sec\n",
      "mean reward: 3.155199\n",
      "return standard deviation: 0.468148\n",
      "min return: 1.774446; max return: 5.513443\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.5948213 0.059840415 0.07460595\n",
      "episode 760 in 1.57 sec\n",
      "mean reward: 3.155070\n",
      "return standard deviation: 0.436190\n",
      "min return: 1.778341; max return: 4.803909\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.72625303 0.058626097 0.07464801\n",
      "episode 761 in 1.52 sec\n",
      "mean reward: 3.148531\n",
      "return standard deviation: 0.489026\n",
      "min return: 1.122445; max return: 4.622118\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.3044605 0.058236357 0.074683994\n",
      "episode 762 in 1.57 sec\n",
      "mean reward: 3.201509\n",
      "return standard deviation: 0.448870\n",
      "min return: 1.905568; max return: 5.265669\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.7743102 0.06715845 0.0747106\n",
      "episode 763 in 1.50 sec\n",
      "mean reward: 3.166369\n",
      "return standard deviation: 0.530777\n",
      "min return: 1.964278; max return: 4.974879\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.7784752 0.06887647 0.07473599\n",
      "episode 764 in 1.52 sec\n",
      "mean reward: 3.090269\n",
      "return standard deviation: 0.450340\n",
      "min return: 1.888931; max return: 4.575461\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.6384495 0.065194406 0.07476105\n",
      "episode 765 in 1.58 sec\n",
      "mean reward: 3.149416\n",
      "return standard deviation: 0.515185\n",
      "min return: 1.853292; max return: 4.917819\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.90952116 0.06908612 0.07479337\n",
      "episode 766 in 1.54 sec\n",
      "mean reward: 3.134281\n",
      "return standard deviation: 0.485635\n",
      "min return: 1.767199; max return: 4.984188\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.4274854 0.06282948 0.07482945\n",
      "episode 767 in 1.56 sec\n",
      "mean reward: 3.157513\n",
      "return standard deviation: 0.466613\n",
      "min return: 1.858811; max return: 5.098357\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.45679528 0.06063453 0.07487126\n",
      "episode 768 in 1.53 sec\n",
      "mean reward: 3.163727\n",
      "return standard deviation: 0.490793\n",
      "min return: 1.848102; max return: 4.739902\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.3544084 0.060339633 0.07490304\n",
      "episode 769 in 1.53 sec\n",
      "mean reward: 3.175906\n",
      "return standard deviation: 0.431738\n",
      "min return: 1.943108; max return: 4.653509\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.4106483 0.06214344 0.074939884\n",
      "episode 770 in 1.55 sec\n",
      "mean reward: 3.194700\n",
      "return standard deviation: 0.511460\n",
      "min return: 1.810776; max return: 6.227926\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.4246669 0.06254037 0.074985854\n",
      "episode 771 in 1.57 sec\n",
      "mean reward: 3.146139\n",
      "return standard deviation: 0.530630\n",
      "min return: 2.033103; max return: 7.009816\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.5905239 0.06508037 0.07503119\n",
      "episode 772 in 1.57 sec\n",
      "mean reward: 3.214407\n",
      "return standard deviation: 0.462789\n",
      "min return: 1.423644; max return: 5.521173\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.85072124 0.07256753 0.075086914\n",
      "episode 773 in 1.50 sec\n",
      "mean reward: 3.142745\n",
      "return standard deviation: 0.477620\n",
      "min return: 1.694326; max return: 4.405468\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.9645514 0.07812854 0.07515957\n",
      "episode 774 in 1.54 sec\n",
      "mean reward: 3.237586\n",
      "return standard deviation: 0.512200\n",
      "min return: 2.061089; max return: 4.546489\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.4983656 0.072737746 0.075249\n",
      "episode 775 in 1.58 sec\n",
      "mean reward: 3.190969\n",
      "return standard deviation: 0.523839\n",
      "min return: 1.717296; max return: 5.640087\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.8495642 0.07195209 0.07533537\n",
      "episode 776 in 1.57 sec\n",
      "mean reward: 3.149704\n",
      "return standard deviation: 0.562503\n",
      "min return: 1.844803; max return: 5.137503\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -1.0311347 0.06797512 0.07539892\n",
      "episode 777 in 1.50 sec\n",
      "mean reward: 3.178659\n",
      "return standard deviation: 0.565091\n",
      "min return: 1.614388; max return: 5.619391\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.65047437 0.06349942 0.07545685\n",
      "episode 778 in 1.50 sec\n",
      "mean reward: 3.209186\n",
      "return standard deviation: 0.475998\n",
      "min return: 2.089510; max return: 4.572958\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.8737891 0.07024326 0.07550954\n",
      "episode 779 in 1.54 sec\n",
      "mean reward: 3.210320\n",
      "return standard deviation: 0.492443\n",
      "min return: 1.905679; max return: 5.742077\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.46361965 0.06310713 0.07556239\n",
      "episode 780 in 1.57 sec\n",
      "mean reward: 3.226483\n",
      "return standard deviation: 0.493892\n",
      "min return: 1.267249; max return: 5.407445\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.1965068 0.06342772 0.07561718\n",
      "episode 781 in 1.50 sec\n",
      "mean reward: 3.202704\n",
      "return standard deviation: 0.493120\n",
      "min return: 1.663629; max return: 5.408825\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.37210605 0.052552518 0.0756679\n",
      "episode 782 in 1.53 sec\n",
      "mean reward: 3.206912\n",
      "return standard deviation: 0.471080\n",
      "min return: 1.730749; max return: 4.955809\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.36587286 0.0589798 0.07573091\n",
      "episode 783 in 1.49 sec\n",
      "mean reward: 3.212220\n",
      "return standard deviation: 0.530461\n",
      "min return: 1.455018; max return: 6.319355\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.19320919 0.055346765 0.07579966\n",
      "episode 784 in 1.48 sec\n",
      "mean reward: 3.257192\n",
      "return standard deviation: 0.484205\n",
      "min return: 1.825246; max return: 5.659162\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.4093902 0.056739636 0.07586028\n",
      "episode 785 in 1.50 sec\n",
      "mean reward: 3.213302\n",
      "return standard deviation: 0.451490\n",
      "min return: 1.975980; max return: 4.532471\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.44215816 0.056804217 0.07592362\n",
      "episode 786 in 1.54 sec\n",
      "mean reward: 3.217750\n",
      "return standard deviation: 0.526747\n",
      "min return: 2.006031; max return: 5.928903\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.49679208 0.05656842 0.07597927\n",
      "episode 787 in 1.48 sec\n",
      "mean reward: 3.225448\n",
      "return standard deviation: 0.509243\n",
      "min return: 1.320983; max return: 4.777832\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.79863715 0.064294495 0.076038\n",
      "episode 788 in 1.51 sec\n",
      "mean reward: 3.145728\n",
      "return standard deviation: 0.534180\n",
      "min return: 1.938829; max return: 5.138361\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.6663264 0.05867605 0.07608737\n",
      "episode 789 in 1.48 sec\n",
      "mean reward: 3.228643\n",
      "return standard deviation: 0.501021\n",
      "min return: 2.042681; max return: 4.777832\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.43763146 0.05636727 0.076152965\n",
      "episode 790 in 1.53 sec\n",
      "mean reward: 3.293295\n",
      "return standard deviation: 0.485589\n",
      "min return: 1.894806; max return: 5.545010\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.5776785 0.055391483 0.07622488\n",
      "episode 791 in 1.53 sec\n",
      "mean reward: 3.230139\n",
      "return standard deviation: 0.556726\n",
      "min return: 1.688555; max return: 5.522038\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.75616366 0.06246998 0.07629968\n",
      "episode 792 in 1.50 sec\n",
      "mean reward: 3.224285\n",
      "return standard deviation: 0.612851\n",
      "min return: 1.657201; max return: 6.668736\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -1.1515131 0.058363438 0.07636921\n",
      "episode 793 in 1.56 sec\n",
      "mean reward: 3.251028\n",
      "return standard deviation: 0.574641\n",
      "min return: 1.653171; max return: 5.947112\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.9867868 0.057690307 0.07644301\n",
      "episode 794 in 1.49 sec\n",
      "mean reward: 3.245842\n",
      "return standard deviation: 0.569818\n",
      "min return: 1.389050; max return: 5.217525\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.7507728 0.052999724 0.076532215\n",
      "episode 795 in 1.47 sec\n",
      "mean reward: 3.199047\n",
      "return standard deviation: 0.490633\n",
      "min return: 1.788071; max return: 4.777832\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.73746264 0.052561086 0.07662771\n",
      "episode 796 in 1.49 sec\n",
      "mean reward: 3.236519\n",
      "return standard deviation: 0.502869\n",
      "min return: 1.998906; max return: 5.947650\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.8916394 0.05410219 0.07672941\n",
      "episode 797 in 1.55 sec\n",
      "mean reward: 3.244108\n",
      "return standard deviation: 0.553696\n",
      "min return: 1.736595; max return: 5.540541\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.7118539 0.04823147 0.076846\n",
      "episode 798 in 1.54 sec\n",
      "mean reward: 3.276802\n",
      "return standard deviation: 0.622899\n",
      "min return: 1.458026; max return: 5.742077\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.2846047 0.049783505 0.07696699\n",
      "episode 799 in 1.58 sec\n",
      "mean reward: 3.220790\n",
      "return standard deviation: 0.524758\n",
      "min return: 2.076414; max return: 5.035675\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.4376642 0.04688344 0.07707085\n",
      "episode 800 in 1.60 sec\n",
      "mean reward: 3.187911\n",
      "return standard deviation: 0.529580\n",
      "min return: 1.974666; max return: 4.929935\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.44956824 0.048524953 0.0771695\n",
      "episode 801 in 1.58 sec\n",
      "mean reward: 3.248712\n",
      "return standard deviation: 0.537006\n",
      "min return: 1.956122; max return: 4.929935\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.48358244 0.040222958 0.07725836\n",
      "episode 802 in 1.59 sec\n",
      "mean reward: 3.280840\n",
      "return standard deviation: 0.567983\n",
      "min return: 1.729563; max return: 5.965184\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.70707124 0.046995 0.07736151\n",
      "episode 803 in 1.57 sec\n",
      "mean reward: 3.222759\n",
      "return standard deviation: 0.509451\n",
      "min return: 1.649102; max return: 4.777832\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.52937835 0.046270933 0.07748387\n",
      "episode 804 in 1.51 sec\n",
      "mean reward: 3.252429\n",
      "return standard deviation: 0.531957\n",
      "min return: 2.087283; max return: 5.443997\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.5469763 0.04258349 0.07759657\n",
      "episode 805 in 1.55 sec\n",
      "mean reward: 3.246979\n",
      "return standard deviation: 0.577667\n",
      "min return: 1.549433; max return: 5.870427\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.61315167 0.044544164 0.0777093\n",
      "episode 806 in 1.58 sec\n",
      "mean reward: 3.272728\n",
      "return standard deviation: 0.557580\n",
      "min return: 1.834494; max return: 5.407433\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.65438867 0.04313644 0.07781165\n",
      "episode 807 in 1.54 sec\n",
      "mean reward: 3.276721\n",
      "return standard deviation: 0.564848\n",
      "min return: 1.967727; max return: 6.203456\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.37813288 0.039600164 0.077913016\n",
      "episode 808 in 1.55 sec\n",
      "mean reward: 3.298373\n",
      "return standard deviation: 0.587740\n",
      "min return: 1.747912; max return: 6.089178\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.5814654 0.040434718 0.07800767\n",
      "episode 809 in 1.53 sec\n",
      "mean reward: 3.169882\n",
      "return standard deviation: 0.594933\n",
      "min return: 1.743010; max return: 6.668736\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.5577824 0.046504498 0.07808205\n",
      "episode 810 in 1.51 sec\n",
      "mean reward: 3.200234\n",
      "return standard deviation: 0.523478\n",
      "min return: 1.735591; max return: 4.905190\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.45584837 0.0394673 0.078155726\n",
      "episode 811 in 1.49 sec\n",
      "mean reward: 3.265414\n",
      "return standard deviation: 0.527138\n",
      "min return: 1.778220; max return: 5.336863\n",
      "\n",
      "max ever return: 7.366199\n",
      "loss comparison -0.13937414 0.041930977 0.07822592\n",
      "new optimal trajectory encountered:\n",
      "episode 812 in 1.52 sec\n",
      "mean reward: 3.304178\n",
      "return standard deviation: 0.592488\n",
      "min return: 1.740681; max return: 7.524780\n",
      "\n",
      "max ever return: 7.524780\n",
      "loss comparison -0.4296667 0.040161006 0.07830021\n",
      "episode 813 in 1.53 sec\n",
      "mean reward: 3.220156\n",
      "return standard deviation: 0.479080\n",
      "min return: 1.510144; max return: 5.443997\n",
      "\n",
      "max ever return: 7.524780\n",
      "loss comparison -0.4189201 0.039562296 0.078388356\n",
      "episode 814 in 1.50 sec\n",
      "mean reward: 3.275632\n",
      "return standard deviation: 0.493159\n",
      "min return: 2.161765; max return: 4.777832\n",
      "\n",
      "max ever return: 7.524780\n",
      "loss comparison -0.49319375 0.036730126 0.078482985\n",
      "episode 815 in 1.50 sec\n",
      "mean reward: 3.258911\n",
      "return standard deviation: 0.522533\n",
      "min return: 2.162403; max return: 5.540541\n",
      "\n",
      "max ever return: 7.524780\n",
      "loss comparison -0.46498847 0.042283807 0.078582644\n",
      "episode 816 in 1.47 sec\n",
      "mean reward: 3.277478\n",
      "return standard deviation: 0.536666\n",
      "min return: 2.054597; max return: 5.947112\n",
      "\n",
      "max ever return: 7.524780\n",
      "loss comparison -0.70351845 0.040428787 0.0786764\n",
      "episode 817 in 1.50 sec\n",
      "mean reward: 3.181141\n",
      "return standard deviation: 0.558730\n",
      "min return: 1.880903; max return: 5.390998\n",
      "\n",
      "max ever return: 7.524780\n",
      "loss comparison -0.5885298 0.041618753 0.07876012\n",
      "episode 818 in 1.53 sec\n",
      "mean reward: 3.201016\n",
      "return standard deviation: 0.513494\n",
      "min return: 2.122675; max return: 5.921623\n",
      "\n",
      "max ever return: 7.524780\n",
      "loss comparison -0.6039075 0.04463651 0.07883251\n",
      "episode 819 in 1.50 sec\n",
      "mean reward: 3.212696\n",
      "return standard deviation: 0.519930\n",
      "min return: 2.026999; max return: 5.035675\n",
      "\n",
      "max ever return: 7.524780\n",
      "loss comparison -0.47307855 0.036601644 0.078910835\n",
      "episode 820 in 1.57 sec\n",
      "mean reward: 3.344252\n",
      "return standard deviation: 0.571700\n",
      "min return: 1.938829; max return: 5.838280\n",
      "\n",
      "max ever return: 7.524780\n",
      "loss comparison -0.57945114 0.03998551 0.07899541\n",
      "episode 821 in 1.54 sec\n",
      "mean reward: 3.332983\n",
      "return standard deviation: 0.647214\n",
      "min return: 1.341504; max return: 6.089178\n",
      "\n",
      "max ever return: 7.524780\n",
      "loss comparison -0.6027278 0.036923397 0.079084285\n",
      "episode 822 in 1.58 sec\n",
      "mean reward: 3.303658\n",
      "return standard deviation: 0.544230\n",
      "min return: 2.132200; max return: 5.035675\n",
      "\n",
      "max ever return: 7.524780\n",
      "loss comparison -0.68589616 0.04040448 0.0791869\n",
      "episode 823 in 1.54 sec\n",
      "mean reward: 3.213992\n",
      "return standard deviation: 0.561038\n",
      "min return: 1.655295; max return: 7.524780\n",
      "\n",
      "max ever return: 7.524780\n",
      "loss comparison -0.5233679 0.04083572 0.07929195\n",
      "episode 824 in 1.55 sec\n",
      "mean reward: 3.281888\n",
      "return standard deviation: 0.556742\n",
      "min return: 1.938829; max return: 5.390998\n",
      "\n",
      "max ever return: 7.524780\n",
      "loss comparison -0.4477427 0.035239447 0.07938412\n",
      "episode 825 in 1.54 sec\n",
      "mean reward: 3.281964\n",
      "return standard deviation: 0.546993\n",
      "min return: 1.871684; max return: 5.407433\n",
      "\n",
      "max ever return: 7.524780\n",
      "loss comparison -0.691436 0.039056495 0.079476066\n",
      "episode 826 in 1.59 sec\n",
      "mean reward: 3.258131\n",
      "return standard deviation: 0.554564\n",
      "min return: 1.728440; max return: 4.824881\n",
      "\n",
      "max ever return: 7.524780\n",
      "loss comparison -0.6703016 0.038979314 0.07956742\n",
      "episode 827 in 1.58 sec\n",
      "mean reward: 3.270007\n",
      "return standard deviation: 0.550211\n",
      "min return: 2.011283; max return: 5.336863\n",
      "\n",
      "max ever return: 7.524780\n",
      "loss comparison -0.57296205 0.03754076 0.079662755\n",
      "episode 828 in 1.55 sec\n",
      "mean reward: 3.294041\n",
      "return standard deviation: 0.558933\n",
      "min return: 2.100170; max return: 5.838280\n",
      "\n",
      "max ever return: 7.524780\n",
      "loss comparison -0.6308739 0.036392234 0.07975711\n",
      "episode 829 in 1.59 sec\n",
      "mean reward: 3.306247\n",
      "return standard deviation: 0.560858\n",
      "min return: 2.046120; max return: 5.336863\n",
      "\n",
      "max ever return: 7.524780\n",
      "loss comparison -0.48963544 0.037434924 0.07985194\n",
      "episode 830 in 1.53 sec\n",
      "mean reward: 3.318393\n",
      "return standard deviation: 0.561279\n",
      "min return: 1.804775; max return: 5.742077\n",
      "\n",
      "max ever return: 7.524780\n",
      "loss comparison -0.7674664 0.04098314 0.079960674\n",
      "episode 831 in 1.51 sec\n",
      "mean reward: 3.276788\n",
      "return standard deviation: 0.588037\n",
      "min return: 2.076414; max return: 6.668736\n",
      "\n",
      "max ever return: 7.524780\n",
      "loss comparison -0.50562775 0.039213706 0.08006441\n",
      "episode 832 in 1.55 sec\n",
      "mean reward: 3.225356\n",
      "return standard deviation: 0.565800\n",
      "min return: 1.996898; max return: 5.167717\n",
      "\n",
      "max ever return: 7.524780\n",
      "loss comparison -0.4991234 0.035073113 0.080165826\n",
      "episode 833 in 1.50 sec\n",
      "mean reward: 3.281778\n",
      "return standard deviation: 0.555867\n",
      "min return: 2.070399; max return: 4.956543\n",
      "\n",
      "max ever return: 7.524780\n",
      "loss comparison -0.42230356 0.040128224 0.08026267\n",
      "episode 834 in 1.57 sec\n",
      "mean reward: 3.273949\n",
      "return standard deviation: 0.541729\n",
      "min return: 1.939656; max return: 5.456095\n",
      "\n",
      "max ever return: 7.524780\n",
      "loss comparison -0.43129843 0.03307963 0.08034309\n",
      "episode 835 in 1.57 sec\n",
      "mean reward: 3.300659\n",
      "return standard deviation: 0.548576\n",
      "min return: 1.751729; max return: 5.167717\n",
      "\n",
      "max ever return: 7.524780\n",
      "loss comparison -0.5234209 0.036147743 0.08043407\n",
      "episode 836 in 1.52 sec\n",
      "mean reward: 3.274127\n",
      "return standard deviation: 0.546150\n",
      "min return: 1.938829; max return: 5.838280\n",
      "\n",
      "max ever return: 7.524780\n",
      "loss comparison -0.4210819 0.03289079 0.08052011\n",
      "episode 837 in 1.53 sec\n",
      "mean reward: 3.284300\n",
      "return standard deviation: 0.539225\n",
      "min return: 2.147303; max return: 5.870427\n",
      "\n",
      "max ever return: 7.524780\n",
      "loss comparison -0.6563713 0.040022682 0.08060484\n",
      "episode 838 in 1.52 sec\n",
      "mean reward: 3.317382\n",
      "return standard deviation: 0.578943\n",
      "min return: 2.094244; max return: 5.941530\n",
      "\n",
      "max ever return: 7.524780\n",
      "loss comparison -0.7981198 0.036540333 0.08069771\n",
      "episode 839 in 1.53 sec\n",
      "mean reward: 3.291582\n",
      "return standard deviation: 0.587036\n",
      "min return: 2.184306; max return: 5.651464\n",
      "\n",
      "max ever return: 7.524780\n",
      "loss comparison -0.59173787 0.035744973 0.08080967\n",
      "episode 840 in 1.56 sec\n",
      "mean reward: 3.315241\n",
      "return standard deviation: 0.504902\n",
      "min return: 2.028832; max return: 5.838280\n",
      "\n",
      "max ever return: 7.524780\n",
      "loss comparison -0.54071456 0.038452726 0.08091211\n",
      "episode 841 in 1.49 sec\n",
      "mean reward: 3.257554\n",
      "return standard deviation: 0.507937\n",
      "min return: 1.989795; max return: 4.777832\n",
      "\n",
      "max ever return: 7.524780\n",
      "loss comparison -0.48949102 0.035577036 0.081008635\n",
      "episode 842 in 1.50 sec\n",
      "mean reward: 3.290064\n",
      "return standard deviation: 0.569747\n",
      "min return: 1.846478; max return: 5.392497\n",
      "\n",
      "max ever return: 7.524780\n",
      "loss comparison -0.7375246 0.0398692 0.08110258\n",
      "episode 843 in 1.57 sec\n",
      "mean reward: 3.304476\n",
      "return standard deviation: 0.612171\n",
      "min return: 1.960668; max return: 6.203456\n",
      "\n",
      "max ever return: 7.524780\n",
      "loss comparison -0.3853687 0.03480002 0.081215195\n",
      "episode 844 in 1.54 sec\n",
      "mean reward: 3.297094\n",
      "return standard deviation: 0.532891\n",
      "min return: 2.136980; max return: 5.947112\n",
      "\n",
      "max ever return: 7.524780\n",
      "loss comparison -0.7764053 0.038568955 0.081315085\n",
      "episode 845 in 1.51 sec\n",
      "mean reward: 3.266631\n",
      "return standard deviation: 0.497583\n",
      "min return: 2.137038; max return: 4.824881\n",
      "\n",
      "max ever return: 7.524780\n",
      "loss comparison -0.5239284 0.03710051 0.081420735\n",
      "episode 846 in 1.58 sec\n",
      "mean reward: 3.217574\n",
      "return standard deviation: 0.535254\n",
      "min return: 1.747912; max return: 5.522038\n",
      "\n",
      "max ever return: 7.524780\n",
      "loss comparison -0.6002181 0.034314334 0.08152055\n",
      "episode 847 in 1.52 sec\n",
      "mean reward: 3.288044\n",
      "return standard deviation: 0.566656\n",
      "min return: 1.949479; max return: 5.374446\n",
      "\n",
      "max ever return: 7.524780\n",
      "loss comparison -0.77116644 0.03917858 0.08162891\n",
      "episode 848 in 1.56 sec\n",
      "mean reward: 3.292588\n",
      "return standard deviation: 0.586671\n",
      "min return: 1.963230; max return: 6.015109\n",
      "\n",
      "max ever return: 7.524780\n",
      "loss comparison -0.7264149 0.03458468 0.08175094\n",
      "episode 849 in 1.49 sec\n",
      "mean reward: 3.306901\n",
      "return standard deviation: 0.498548\n",
      "min return: 2.246919; max return: 4.777832\n",
      "\n",
      "max ever return: 7.524780\n",
      "loss comparison -0.85409147 0.035281554 0.081879124\n",
      "episode 850 in 1.53 sec\n",
      "mean reward: 3.274596\n",
      "return standard deviation: 0.577073\n",
      "min return: 1.317390; max return: 5.167717\n",
      "\n",
      "max ever return: 7.524780\n",
      "loss comparison -0.48664922 0.032184195 0.08200897\n",
      "episode 851 in 1.46 sec\n",
      "mean reward: 3.299461\n",
      "return standard deviation: 0.565280\n",
      "min return: 1.967710; max return: 5.947112\n",
      "\n",
      "max ever return: 7.524780\n",
      "loss comparison -0.5032836 0.032024782 0.08211809\n",
      "episode 852 in 1.47 sec\n",
      "mean reward: 3.313062\n",
      "return standard deviation: 0.637684\n",
      "min return: 2.102237; max return: 7.465399\n",
      "\n",
      "max ever return: 7.524780\n",
      "loss comparison -0.7677926 0.032012597 0.08221653\n",
      "episode 853 in 1.54 sec\n",
      "mean reward: 3.271216\n",
      "return standard deviation: 0.567004\n",
      "min return: 1.956070; max return: 6.089178\n",
      "\n",
      "max ever return: 7.524780\n",
      "loss comparison -0.7761253 0.0365565 0.08231213\n",
      "episode 854 in 1.49 sec\n",
      "mean reward: 3.287517\n",
      "return standard deviation: 0.595158\n",
      "min return: 1.871360; max return: 5.035675\n",
      "\n",
      "max ever return: 7.524780\n",
      "loss comparison -0.5087516 0.033210758 0.08242362\n",
      "episode 855 in 1.47 sec\n",
      "mean reward: 3.330083\n",
      "return standard deviation: 0.554032\n",
      "min return: 1.944300; max return: 6.192917\n",
      "\n",
      "max ever return: 7.524780\n",
      "loss comparison -0.4967925 0.031534277 0.08253091\n",
      "episode 856 in 1.49 sec\n",
      "mean reward: 3.271209\n",
      "return standard deviation: 0.545291\n",
      "min return: 1.912089; max return: 5.838280\n",
      "\n",
      "max ever return: 7.524780\n",
      "loss comparison -0.57365143 0.034859873 0.08264602\n",
      "episode 857 in 1.49 sec\n",
      "mean reward: 3.298272\n",
      "return standard deviation: 0.553809\n",
      "min return: 2.227498; max return: 5.445217\n",
      "\n",
      "max ever return: 7.524780\n",
      "loss comparison -0.21934384 0.032678675 0.08277146\n",
      "episode 858 in 1.48 sec\n",
      "mean reward: 3.382355\n",
      "return standard deviation: 0.572161\n",
      "min return: 1.916880; max return: 7.162629\n",
      "\n",
      "max ever return: 7.524780\n",
      "loss comparison -0.48459136 0.031663977 0.08289058\n",
      "episode 859 in 1.52 sec\n",
      "mean reward: 3.319350\n",
      "return standard deviation: 0.535235\n",
      "min return: 1.981063; max return: 5.921623\n",
      "\n",
      "max ever return: 7.524780\n",
      "loss comparison -0.57542855 0.031986225 0.08300476\n",
      "episode 860 in 1.51 sec\n",
      "mean reward: 3.299321\n",
      "return standard deviation: 0.567387\n",
      "min return: 1.996898; max return: 6.203456\n",
      "\n",
      "max ever return: 7.524780\n",
      "loss comparison -0.40856242 0.027454078 0.08312846\n",
      "episode 861 in 1.54 sec\n",
      "mean reward: 3.308442\n",
      "return standard deviation: 0.518446\n",
      "min return: 2.163115; max return: 5.472629\n",
      "\n",
      "max ever return: 7.524780\n",
      "loss comparison -0.66753566 0.03331683 0.083251625\n",
      "episode 862 in 1.52 sec\n",
      "mean reward: 3.309777\n",
      "return standard deviation: 0.575810\n",
      "min return: 1.993721; max return: 5.838280\n",
      "\n",
      "max ever return: 7.524780\n",
      "loss comparison -0.5435312 0.03352797 0.08336303\n",
      "episode 863 in 1.57 sec\n",
      "mean reward: 3.301308\n",
      "return standard deviation: 0.575304\n",
      "min return: 2.070399; max return: 5.035675\n",
      "\n",
      "max ever return: 7.524780\n",
      "loss comparison -0.8312485 0.035389997 0.08346265\n",
      "episode 864 in 1.57 sec\n",
      "mean reward: 3.342681\n",
      "return standard deviation: 0.606140\n",
      "min return: 1.944300; max return: 6.668736\n",
      "\n",
      "max ever return: 7.524780\n",
      "loss comparison -0.78187495 0.037066083 0.08357406\n",
      "episode 865 in 1.48 sec\n",
      "mean reward: 3.345739\n",
      "return standard deviation: 0.599445\n",
      "min return: 2.076414; max return: 5.044232\n",
      "\n",
      "max ever return: 7.524780\n",
      "loss comparison -0.7263936 0.032300577 0.08368194\n",
      "episode 866 in 1.47 sec\n",
      "mean reward: 3.406610\n",
      "return standard deviation: 0.612356\n",
      "min return: 2.020536; max return: 5.443997\n",
      "\n",
      "max ever return: 7.524780\n",
      "loss comparison -0.8620713 0.033138618 0.08379093\n",
      "episode 867 in 1.48 sec\n",
      "mean reward: 3.287004\n",
      "return standard deviation: 0.552240\n",
      "min return: 1.605805; max return: 4.777832\n",
      "\n",
      "max ever return: 7.524780\n",
      "loss comparison -0.7217451 0.03134912 0.0839251\n",
      "episode 868 in 1.49 sec\n",
      "mean reward: 3.369636\n",
      "return standard deviation: 0.587350\n",
      "min return: 2.200502; max return: 4.929935\n",
      "\n",
      "max ever return: 7.524780\n",
      "loss comparison -0.3374283 0.028933637 0.08405729\n",
      "episode 869 in 1.49 sec\n",
      "mean reward: 3.297313\n",
      "return standard deviation: 0.494730\n",
      "min return: 2.076414; max return: 5.445217\n",
      "\n",
      "max ever return: 7.524780\n",
      "loss comparison -0.7446846 0.031797737 0.08417175\n",
      "episode 870 in 1.49 sec\n",
      "mean reward: 3.313526\n",
      "return standard deviation: 0.545922\n",
      "min return: 1.750548; max return: 4.777832\n",
      "\n",
      "max ever return: 7.524780\n",
      "loss comparison -0.57111275 0.031190235 0.08428958\n",
      "episode 871 in 1.46 sec\n",
      "mean reward: 3.322508\n",
      "return standard deviation: 0.536856\n",
      "min return: 2.246320; max return: 4.929935\n",
      "\n",
      "max ever return: 7.524780\n",
      "loss comparison -0.62620014 0.031415083 0.084417865\n",
      "episode 872 in 1.48 sec\n",
      "mean reward: 3.342346\n",
      "return standard deviation: 0.548868\n",
      "min return: 1.696182; max return: 5.947112\n",
      "\n",
      "max ever return: 7.524780\n",
      "loss comparison -0.4312129 0.02695128 0.08454391\n",
      "episode 873 in 1.45 sec\n",
      "mean reward: 3.399257\n",
      "return standard deviation: 0.566251\n",
      "min return: 2.089510; max return: 7.162629\n",
      "\n",
      "max ever return: 7.524780\n",
      "loss comparison -0.85733014 0.03083881 0.08466609\n",
      "episode 874 in 1.52 sec\n",
      "mean reward: 3.367791\n",
      "return standard deviation: 0.654420\n",
      "min return: 2.186980; max return: 5.947112\n",
      "\n",
      "max ever return: 7.524780\n",
      "loss comparison -0.7535664 0.029463895 0.0847973\n",
      "episode 875 in 1.47 sec\n",
      "mean reward: 3.358386\n",
      "return standard deviation: 0.567573\n",
      "min return: 1.964339; max return: 4.929935\n",
      "\n",
      "max ever return: 7.524780\n",
      "loss comparison -0.6764465 0.028468993 0.08493399\n",
      "episode 876 in 1.49 sec\n",
      "mean reward: 3.331307\n",
      "return standard deviation: 0.604936\n",
      "min return: 1.986453; max return: 5.947112\n",
      "\n",
      "max ever return: 7.524780\n",
      "loss comparison -0.62702227 0.029296936 0.08506326\n",
      "episode 877 in 1.53 sec\n",
      "mean reward: 3.299200\n",
      "return standard deviation: 0.539010\n",
      "min return: 2.164928; max return: 5.167717\n",
      "\n",
      "max ever return: 7.524780\n",
      "loss comparison -0.5123231 0.02768628 0.08519001\n",
      "episode 878 in 1.52 sec\n",
      "mean reward: 3.335104\n",
      "return standard deviation: 0.575349\n",
      "min return: 2.049962; max return: 6.015109\n",
      "\n",
      "max ever return: 7.524780\n",
      "loss comparison -0.29702434 0.02497271 0.08529992\n",
      "episode 879 in 1.50 sec\n",
      "mean reward: 3.395079\n",
      "return standard deviation: 0.581797\n",
      "min return: 2.046334; max return: 6.273467\n",
      "\n",
      "max ever return: 7.524780\n",
      "loss comparison -0.5468807 0.02544887 0.085390724\n",
      "episode 880 in 1.50 sec\n",
      "mean reward: 3.416766\n",
      "return standard deviation: 0.609595\n",
      "min return: 2.112856; max return: 5.464122\n",
      "\n",
      "max ever return: 7.524780\n",
      "loss comparison -0.43583626 0.027121484 0.08547801\n",
      "episode 881 in 1.59 sec\n",
      "mean reward: 3.420357\n",
      "return standard deviation: 0.586275\n",
      "min return: 2.143756; max return: 5.445217\n",
      "\n",
      "max ever return: 7.524780\n",
      "loss comparison -0.47644722 0.029796157 0.085567676\n",
      "episode 882 in 1.55 sec\n",
      "mean reward: 3.292898\n",
      "return standard deviation: 0.573027\n",
      "min return: 1.745261; max return: 5.947112\n",
      "\n",
      "max ever return: 7.524780\n",
      "loss comparison -0.5203025 0.027932618 0.0856801\n",
      "episode 883 in 1.48 sec\n",
      "mean reward: 3.272593\n",
      "return standard deviation: 0.503374\n",
      "min return: 2.077289; max return: 5.742077\n",
      "\n",
      "max ever return: 7.524780\n",
      "loss comparison -0.5878127 0.028242476 0.085793845\n",
      "episode 884 in 1.48 sec\n",
      "mean reward: 3.356763\n",
      "return standard deviation: 0.558968\n",
      "min return: 1.923840; max return: 4.986253\n",
      "\n",
      "max ever return: 7.524780\n",
      "loss comparison -0.5617438 0.02642948 0.0859212\n",
      "episode 885 in 1.51 sec\n",
      "mean reward: 3.387908\n",
      "return standard deviation: 0.570908\n",
      "min return: 2.320471; max return: 5.838280\n",
      "\n",
      "max ever return: 7.524780\n",
      "loss comparison -0.5945071 0.02383763 0.08605123\n",
      "episode 886 in 1.49 sec\n",
      "mean reward: 3.442775\n",
      "return standard deviation: 0.587684\n",
      "min return: 2.096580; max return: 5.374446\n",
      "\n",
      "max ever return: 7.524780\n",
      "loss comparison -0.58296746 0.025447078 0.0861714\n",
      "episode 887 in 1.56 sec\n",
      "mean reward: 3.389178\n",
      "return standard deviation: 0.685399\n",
      "min return: 2.039100; max return: 5.947112\n",
      "\n",
      "max ever return: 7.524780\n",
      "loss comparison -0.6805651 0.027920105 0.08627264\n",
      "episode 888 in 1.51 sec\n",
      "mean reward: 3.358280\n",
      "return standard deviation: 0.601684\n",
      "min return: 1.964339; max return: 5.392497\n",
      "\n",
      "max ever return: 7.524780\n",
      "loss comparison -0.8045486 0.028423993 0.08637481\n",
      "episode 889 in 1.47 sec\n",
      "mean reward: 3.345484\n",
      "return standard deviation: 0.617650\n",
      "min return: 1.638849; max return: 5.947112\n",
      "\n",
      "max ever return: 7.524780\n",
      "loss comparison -0.64402735 0.02762819 0.08650063\n",
      "episode 890 in 1.48 sec\n",
      "mean reward: 3.365614\n",
      "return standard deviation: 0.572052\n",
      "min return: 2.069518; max return: 5.742077\n",
      "\n",
      "max ever return: 7.524780\n",
      "loss comparison -0.69674015 0.026512265 0.086621575\n",
      "episode 891 in 1.58 sec\n",
      "mean reward: 3.418771\n",
      "return standard deviation: 0.578083\n",
      "min return: 1.950066; max return: 4.817372\n",
      "\n",
      "max ever return: 7.524780\n",
      "loss comparison -0.7501428 0.028523007 0.08674427\n",
      "episode 892 in 1.53 sec\n",
      "mean reward: 3.343195\n",
      "return standard deviation: 0.554439\n",
      "min return: 1.656923; max return: 5.742077\n",
      "\n",
      "max ever return: 7.524780\n",
      "loss comparison -0.4292794 0.02446102 0.08688457\n",
      "episode 893 in 1.57 sec\n",
      "mean reward: 3.370987\n",
      "return standard deviation: 0.541059\n",
      "min return: 1.923773; max return: 5.336863\n",
      "\n",
      "max ever return: 7.524780\n",
      "loss comparison -0.3330294 0.02244515 0.08703337\n",
      "episode 894 in 1.55 sec\n",
      "mean reward: 3.398363\n",
      "return standard deviation: 0.537244\n",
      "min return: 2.094448; max return: 5.947112\n",
      "\n",
      "max ever return: 7.524780\n",
      "loss comparison -0.49949303 0.02714698 0.08717619\n",
      "episode 895 in 1.50 sec\n",
      "mean reward: 3.382013\n",
      "return standard deviation: 0.581707\n",
      "min return: 1.710516; max return: 5.374446\n",
      "\n",
      "max ever return: 7.524780\n",
      "loss comparison -0.6344568 0.025205877 0.08732485\n",
      "episode 896 in 1.53 sec\n",
      "mean reward: 3.387854\n",
      "return standard deviation: 0.514890\n",
      "min return: 1.504512; max return: 5.336863\n",
      "\n",
      "max ever return: 7.524780\n",
      "loss comparison -0.36220357 0.022248454 0.08747837\n",
      "episode 897 in 1.48 sec\n",
      "mean reward: 3.428828\n",
      "return standard deviation: 0.580158\n",
      "min return: 2.006792; max return: 6.632848\n",
      "\n",
      "max ever return: 7.524780\n",
      "loss comparison -0.46400234 0.027501248 0.0876243\n",
      "episode 898 in 1.52 sec\n",
      "mean reward: 3.394347\n",
      "return standard deviation: 0.594180\n",
      "min return: 2.305054; max return: 5.921623\n",
      "\n",
      "max ever return: 7.524780\n",
      "loss comparison -0.5364745 0.022339635 0.08777029\n",
      "episode 899 in 1.54 sec\n",
      "mean reward: 3.384388\n",
      "return standard deviation: 0.550274\n",
      "min return: 2.164994; max return: 5.167717\n",
      "\n",
      "max ever return: 7.524780\n",
      "loss comparison -0.79152095 0.024652269 0.08791513\n",
      "episode 900 in 1.50 sec\n",
      "mean reward: 3.354975\n",
      "return standard deviation: 0.568646\n",
      "min return: 2.101955; max return: 5.035675\n",
      "\n",
      "max ever return: 7.524780\n",
      "loss comparison -0.378092 0.022535104 0.0880471\n",
      "episode 901 in 1.58 sec\n",
      "mean reward: 3.445028\n",
      "return standard deviation: 0.713276\n",
      "min return: 2.185056; max return: 7.162629\n",
      "\n",
      "max ever return: 7.524780\n",
      "loss comparison -0.8803446 0.02615017 0.08815994\n",
      "episode 902 in 1.53 sec\n",
      "mean reward: 3.429714\n",
      "return standard deviation: 0.683605\n",
      "min return: 2.233023; max return: 6.668736\n",
      "\n",
      "max ever return: 7.524780\n",
      "loss comparison -0.55046475 0.02374308 0.08827449\n",
      "episode 903 in 1.52 sec\n",
      "mean reward: 3.441270\n",
      "return standard deviation: 0.606009\n",
      "min return: 1.955254; max return: 5.445217\n",
      "\n",
      "max ever return: 7.524780\n",
      "loss comparison -0.4769238 0.02305461 0.08837428\n",
      "episode 904 in 1.57 sec\n",
      "mean reward: 3.380637\n",
      "return standard deviation: 0.589658\n",
      "min return: 2.233023; max return: 5.645542\n",
      "\n",
      "max ever return: 7.524780\n",
      "loss comparison -0.5755786 0.025841948 0.08847492\n",
      "episode 905 in 1.51 sec\n",
      "mean reward: 3.454187\n",
      "return standard deviation: 0.576544\n",
      "min return: 2.163859; max return: 4.954055\n",
      "\n",
      "max ever return: 7.524780\n",
      "loss comparison -0.27849954 0.023833118 0.08857946\n",
      "episode 906 in 1.54 sec\n",
      "mean reward: 3.442657\n",
      "return standard deviation: 0.526013\n",
      "min return: 2.055385; max return: 6.413063\n",
      "\n",
      "max ever return: 7.524780\n",
      "loss comparison -0.65681565 0.028362876 0.08868748\n",
      "episode 907 in 1.53 sec\n",
      "mean reward: 3.365071\n",
      "return standard deviation: 0.538042\n",
      "min return: 2.261829; max return: 5.308731\n",
      "\n",
      "max ever return: 7.524780\n",
      "loss comparison -0.46997157 0.021987246 0.08881063\n",
      "episode 908 in 1.57 sec\n",
      "mean reward: 3.371711\n",
      "return standard deviation: 0.573533\n",
      "min return: 1.873606; max return: 4.824881\n",
      "\n",
      "max ever return: 7.524780\n",
      "loss comparison -0.8048534 0.024632692 0.0889366\n",
      "episode 909 in 1.52 sec\n",
      "mean reward: 3.383408\n",
      "return standard deviation: 0.616130\n",
      "min return: 2.029503; max return: 5.167717\n",
      "\n",
      "max ever return: 7.524780\n",
      "loss comparison -0.24022327 0.021444626 0.08904947\n",
      "episode 910 in 1.60 sec\n",
      "mean reward: 3.467066\n",
      "return standard deviation: 0.598967\n",
      "min return: 2.233023; max return: 5.448997\n",
      "\n",
      "max ever return: 7.524780\n",
      "loss comparison -0.7440134 0.023640651 0.08914234\n",
      "episode 911 in 1.52 sec\n",
      "mean reward: 3.393676\n",
      "return standard deviation: 0.599755\n",
      "min return: 1.938829; max return: 5.336863\n",
      "\n",
      "max ever return: 7.524780\n",
      "loss comparison -0.56575835 0.022220463 0.08923314\n",
      "episode 912 in 1.51 sec\n",
      "mean reward: 3.400180\n",
      "return standard deviation: 0.591941\n",
      "min return: 2.205518; max return: 4.860636\n",
      "\n",
      "max ever return: 7.524780\n",
      "loss comparison -0.790188 0.026567506 0.0893256\n",
      "episode 913 in 1.53 sec\n",
      "mean reward: 3.387762\n",
      "return standard deviation: 0.582749\n",
      "min return: 2.046313; max return: 5.167717\n",
      "\n",
      "max ever return: 7.524780\n",
      "loss comparison -0.8671831 0.024302661 0.089435555\n",
      "episode 914 in 1.59 sec\n",
      "mean reward: 3.439531\n",
      "return standard deviation: 0.649497\n",
      "min return: 2.212948; max return: 5.742077\n",
      "\n",
      "max ever return: 7.524780\n",
      "loss comparison -0.59464383 0.02518637 0.0895619\n",
      "episode 915 in 1.47 sec\n",
      "mean reward: 3.376876\n",
      "return standard deviation: 0.568065\n",
      "min return: 2.215743; max return: 5.336863\n",
      "\n",
      "max ever return: 7.524780\n",
      "loss comparison -0.78647596 0.02441136 0.08968497\n",
      "episode 916 in 1.56 sec\n",
      "mean reward: 3.369987\n",
      "return standard deviation: 0.606452\n",
      "min return: 1.923773; max return: 5.167717\n",
      "\n",
      "max ever return: 7.524780\n",
      "loss comparison -0.5551059 0.021869833 0.08981228\n",
      "episode 917 in 1.51 sec\n",
      "mean reward: 3.412070\n",
      "return standard deviation: 0.658693\n",
      "min return: 1.928661; max return: 6.203456\n",
      "\n",
      "max ever return: 7.524780\n",
      "loss comparison -0.47324818 0.024081914 0.089915074\n",
      "episode 918 in 1.53 sec\n",
      "mean reward: 3.292375\n",
      "return standard deviation: 0.541686\n",
      "min return: 1.914913; max return: 5.167717\n",
      "\n",
      "max ever return: 7.524780\n",
      "loss comparison -0.4080983 0.023743147 0.08999687\n",
      "episode 919 in 1.56 sec\n",
      "mean reward: 3.403969\n",
      "return standard deviation: 0.589659\n",
      "min return: 1.778678; max return: 7.524780\n",
      "\n",
      "max ever return: 7.524780\n",
      "loss comparison -0.48146644 0.021809116 0.09007715\n",
      "episode 920 in 1.56 sec\n",
      "mean reward: 3.412374\n",
      "return standard deviation: 0.542373\n",
      "min return: 2.082787; max return: 4.786421\n",
      "\n",
      "max ever return: 7.524780\n",
      "loss comparison -0.4860166 0.02242538 0.09016227\n",
      "episode 921 in 1.55 sec\n",
      "mean reward: 3.333121\n",
      "return standard deviation: 0.514453\n",
      "min return: 2.271294; max return: 4.777832\n",
      "\n",
      "max ever return: 7.524780\n",
      "loss comparison -0.5115261 0.024094302 0.09026081\n",
      "episode 922 in 1.61 sec\n",
      "mean reward: 3.357002\n",
      "return standard deviation: 0.557234\n",
      "min return: 1.863935; max return: 5.336863\n",
      "\n",
      "max ever return: 7.524780\n",
      "loss comparison -0.43094474 0.021208432 0.090385966\n",
      "episode 923 in 1.57 sec\n",
      "mean reward: 3.451753\n",
      "return standard deviation: 0.605848\n",
      "min return: 1.670070; max return: 6.273467\n",
      "\n",
      "max ever return: 7.524780\n",
      "loss comparison -0.45507166 0.021411847 0.090525635\n",
      "episode 924 in 1.48 sec\n",
      "mean reward: 3.471699\n",
      "return standard deviation: 0.559394\n",
      "min return: 2.076414; max return: 5.947112\n",
      "\n",
      "max ever return: 7.524780\n",
      "loss comparison -0.69657177 0.022312542 0.0906574\n",
      "episode 925 in 1.52 sec\n",
      "mean reward: 3.383180\n",
      "return standard deviation: 0.596679\n",
      "min return: 2.233023; max return: 4.777832\n",
      "\n",
      "max ever return: 7.524780\n",
      "loss comparison -0.5767138 0.022516875 0.09078462\n",
      "episode 926 in 1.53 sec\n",
      "mean reward: 3.420829\n",
      "return standard deviation: 0.581807\n",
      "min return: 1.944300; max return: 4.817372\n",
      "\n",
      "max ever return: 7.524780\n",
      "loss comparison -0.87285656 0.022628473 0.09090132\n",
      "episode 927 in 1.52 sec\n",
      "mean reward: 3.416270\n",
      "return standard deviation: 0.641408\n",
      "min return: 2.034108; max return: 5.336863\n",
      "\n",
      "max ever return: 7.524780\n",
      "loss comparison -1.1146059 0.025402268 0.09101267\n",
      "episode 928 in 1.46 sec\n",
      "mean reward: 3.377821\n",
      "return standard deviation: 0.676215\n",
      "min return: 1.792790; max return: 4.930135\n",
      "\n",
      "max ever return: 7.524780\n",
      "loss comparison -0.72166014 0.022883013 0.09113227\n",
      "episode 929 in 1.52 sec\n",
      "mean reward: 3.366912\n",
      "return standard deviation: 0.629858\n",
      "min return: 2.157240; max return: 5.645542\n",
      "\n",
      "max ever return: 7.524780\n",
      "loss comparison -0.77462804 0.022197751 0.09124739\n",
      "episode 930 in 1.46 sec\n",
      "mean reward: 3.423806\n",
      "return standard deviation: 0.580043\n",
      "min return: 2.082056; max return: 4.824881\n",
      "\n",
      "max ever return: 7.524780\n",
      "loss comparison -0.7140792 0.024716485 0.09137078\n",
      "episode 931 in 1.46 sec\n",
      "mean reward: 3.439172\n",
      "return standard deviation: 0.628833\n",
      "min return: 1.896677; max return: 5.336863\n",
      "\n",
      "max ever return: 7.524780\n",
      "loss comparison -0.5553969 0.020246966 0.09149556\n",
      "episode 932 in 1.46 sec\n",
      "mean reward: 3.414223\n",
      "return standard deviation: 0.594244\n",
      "min return: 2.070399; max return: 6.203456\n",
      "\n",
      "max ever return: 7.524780\n",
      "loss comparison -0.4869197 0.02390433 0.09161224\n",
      "episode 933 in 1.48 sec\n",
      "mean reward: 3.409442\n",
      "return standard deviation: 0.568075\n",
      "min return: 1.975212; max return: 5.336863\n",
      "\n",
      "max ever return: 7.524780\n",
      "loss comparison -0.6531514 0.021775449 0.091725454\n",
      "episode 934 in 1.58 sec\n",
      "mean reward: 3.401225\n",
      "return standard deviation: 0.557626\n",
      "min return: 1.905359; max return: 5.167717\n",
      "\n",
      "max ever return: 7.524780\n",
      "loss comparison -0.6062956 0.021437854 0.091839686\n",
      "episode 935 in 1.58 sec\n",
      "mean reward: 3.456454\n",
      "return standard deviation: 0.571965\n",
      "min return: 2.347895; max return: 4.900959\n",
      "\n",
      "max ever return: 7.524780\n",
      "loss comparison -0.62311727 0.020785881 0.091959685\n",
      "episode 936 in 1.53 sec\n",
      "mean reward: 3.440066\n",
      "return standard deviation: 0.592841\n",
      "min return: 1.863935; max return: 5.742077\n",
      "\n",
      "max ever return: 7.524780\n",
      "loss comparison -0.5685757 0.022523532 0.09209325\n",
      "episode 937 in 1.57 sec\n",
      "mean reward: 3.491976\n",
      "return standard deviation: 0.583776\n",
      "min return: 2.320471; max return: 5.167717\n",
      "\n",
      "max ever return: 7.524780\n",
      "loss comparison -0.6417744 0.02100977 0.092232056\n",
      "episode 938 in 1.49 sec\n",
      "mean reward: 3.396988\n",
      "return standard deviation: 0.580740\n",
      "min return: 2.074563; max return: 4.824881\n",
      "\n",
      "max ever return: 7.524780\n",
      "loss comparison -0.670778 0.020827284 0.09236925\n",
      "episode 939 in 1.55 sec\n",
      "mean reward: 3.481060\n",
      "return standard deviation: 0.639073\n",
      "min return: 2.093652; max return: 5.167717\n",
      "\n",
      "max ever return: 7.524780\n",
      "loss comparison -0.82374126 0.021935547 0.09250013\n",
      "episode 940 in 1.50 sec\n",
      "mean reward: 3.410761\n",
      "return standard deviation: 0.670216\n",
      "min return: 1.924891; max return: 5.308731\n",
      "\n",
      "max ever return: 7.524780\n",
      "loss comparison -1.0890512 0.022374472 0.092616655\n",
      "episode 941 in 1.55 sec\n",
      "mean reward: 3.389218\n",
      "return standard deviation: 0.666415\n",
      "min return: 1.298760; max return: 4.954055\n",
      "\n",
      "max ever return: 7.524780\n",
      "loss comparison -0.6635643 0.019588968 0.09275344\n",
      "episode 942 in 1.55 sec\n",
      "mean reward: 3.448606\n",
      "return standard deviation: 0.587861\n",
      "min return: 2.233023; max return: 4.817372\n",
      "\n",
      "max ever return: 7.524780\n",
      "loss comparison -0.75031704 0.020328056 0.092890315\n",
      "episode 943 in 1.59 sec\n",
      "mean reward: 3.448476\n",
      "return standard deviation: 0.604161\n",
      "min return: 2.163859; max return: 4.929935\n",
      "\n",
      "max ever return: 7.524780\n",
      "loss comparison -0.8136349 0.021553423 0.093036175\n",
      "episode 944 in 1.61 sec\n",
      "mean reward: 3.366271\n",
      "return standard deviation: 0.574555\n",
      "min return: 1.907821; max return: 4.777832\n",
      "\n",
      "max ever return: 7.524780\n",
      "loss comparison -0.6849977 0.019316515 0.09318845\n",
      "episode 945 in 1.54 sec\n",
      "mean reward: 3.513361\n",
      "return standard deviation: 0.644784\n",
      "min return: 2.233023; max return: 5.838280\n",
      "\n",
      "max ever return: 7.524780\n",
      "loss comparison -0.78982496 0.02050132 0.09334229\n",
      "episode 946 in 1.56 sec\n",
      "mean reward: 3.478903\n",
      "return standard deviation: 0.628531\n",
      "min return: 1.788461; max return: 5.580830\n",
      "\n",
      "max ever return: 7.524780\n",
      "loss comparison -0.32419285 0.017461006 0.093502745\n",
      "episode 947 in 1.54 sec\n",
      "mean reward: 3.465996\n",
      "return standard deviation: 0.601658\n",
      "min return: 2.233023; max return: 5.947112\n",
      "\n",
      "max ever return: 7.524780\n",
      "loss comparison -0.64094055 0.020651516 0.09364274\n",
      "episode 948 in 1.60 sec\n",
      "mean reward: 3.472861\n",
      "return standard deviation: 0.594541\n",
      "min return: 2.089510; max return: 5.336863\n",
      "\n",
      "max ever return: 7.524780\n",
      "loss comparison -0.408537 0.018611109 0.093771026\n",
      "episode 949 in 1.52 sec\n",
      "mean reward: 3.449104\n",
      "return standard deviation: 0.539118\n",
      "min return: 2.038645; max return: 5.035675\n",
      "\n",
      "max ever return: 7.524780\n",
      "loss comparison -0.70191586 0.023968784 0.09388557\n",
      "episode 950 in 1.60 sec\n",
      "mean reward: 3.428032\n",
      "return standard deviation: 0.610789\n",
      "min return: 1.710516; max return: 5.742077\n",
      "\n",
      "max ever return: 7.524780\n",
      "loss comparison -0.4149217 0.018774746 0.09402169\n",
      "episode 951 in 1.66 sec\n",
      "mean reward: 3.453840\n",
      "return standard deviation: 0.563110\n",
      "min return: 2.233023; max return: 4.824881\n",
      "\n",
      "max ever return: 7.524780\n",
      "loss comparison -0.5320939 0.02024568 0.09415426\n",
      "episode 952 in 1.57 sec\n",
      "mean reward: 3.442770\n",
      "return standard deviation: 0.531835\n",
      "min return: 2.287168; max return: 4.900959\n",
      "\n",
      "max ever return: 7.524780\n",
      "loss comparison -0.6960562 0.020132715 0.09429469\n",
      "episode 953 in 1.68 sec\n",
      "mean reward: 3.459411\n",
      "return standard deviation: 0.575066\n",
      "min return: 2.216436; max return: 5.445217\n",
      "\n",
      "max ever return: 7.524780\n",
      "loss comparison -0.6642184 0.020939874 0.094426565\n",
      "episode 954 in 1.60 sec\n",
      "mean reward: 3.447156\n",
      "return standard deviation: 0.593514\n",
      "min return: 2.089329; max return: 5.445217\n",
      "\n",
      "max ever return: 7.524780\n",
      "loss comparison -0.5840101 0.01854131 0.09455517\n",
      "episode 955 in 1.63 sec\n",
      "mean reward: 3.436893\n",
      "return standard deviation: 0.577448\n",
      "min return: 2.271479; max return: 4.817372\n",
      "\n",
      "max ever return: 7.524780\n",
      "loss comparison -0.50971264 0.016660774 0.094682544\n",
      "episode 956 in 1.50 sec\n",
      "mean reward: 3.483685\n",
      "return standard deviation: 0.583842\n",
      "min return: 2.227596; max return: 5.448997\n",
      "\n",
      "max ever return: 7.524780\n",
      "loss comparison -0.6556463 0.018416211 0.0948085\n",
      "episode 957 in 1.54 sec\n",
      "mean reward: 3.478416\n",
      "return standard deviation: 0.594922\n",
      "min return: 2.265388; max return: 5.167717\n",
      "\n",
      "max ever return: 7.524780\n",
      "loss comparison -0.7886585 0.017824944 0.09493158\n",
      "episode 958 in 1.51 sec\n",
      "mean reward: 3.524306\n",
      "return standard deviation: 0.716469\n",
      "min return: 1.751416; max return: 7.524780\n",
      "\n",
      "max ever return: 7.524780\n",
      "loss comparison -0.8368644 0.020751236 0.09506761\n",
      "episode 959 in 1.66 sec\n",
      "mean reward: 3.447827\n",
      "return standard deviation: 0.631293\n",
      "min return: 1.701868; max return: 5.035675\n",
      "\n",
      "max ever return: 7.524780\n",
      "loss comparison -0.5476178 0.017986033 0.09521626\n",
      "episode 960 in 1.58 sec\n",
      "mean reward: 3.459034\n",
      "return standard deviation: 0.595969\n",
      "min return: 1.920558; max return: 4.819751\n",
      "\n",
      "max ever return: 7.524780\n",
      "loss comparison -0.6505202 0.019374842 0.09535418\n",
      "episode 961 in 1.59 sec\n",
      "mean reward: 3.506432\n",
      "return standard deviation: 0.614092\n",
      "min return: 2.289524; max return: 4.824881\n",
      "\n",
      "max ever return: 7.524780\n",
      "loss comparison -0.80558574 0.01976724 0.095490195\n",
      "episode 962 in 1.51 sec\n",
      "mean reward: 3.461667\n",
      "return standard deviation: 0.607787\n",
      "min return: 2.157240; max return: 4.824881\n",
      "\n",
      "max ever return: 7.524780\n",
      "loss comparison -0.7420959 0.017962845 0.09563478\n",
      "episode 963 in 1.48 sec\n",
      "mean reward: 3.461098\n",
      "return standard deviation: 0.606616\n",
      "min return: 2.070399; max return: 4.777832\n",
      "\n",
      "max ever return: 7.524780\n",
      "loss comparison -0.7704573 0.019357415 0.09578539\n",
      "episode 964 in 1.47 sec\n",
      "mean reward: 3.493203\n",
      "return standard deviation: 0.643368\n",
      "min return: 1.932272; max return: 5.992360\n",
      "\n",
      "max ever return: 7.524780\n",
      "loss comparison -0.73977983 0.017131075 0.09593538\n",
      "episode 965 in 1.53 sec\n",
      "mean reward: 3.528977\n",
      "return standard deviation: 0.662079\n",
      "min return: 1.868779; max return: 5.947112\n",
      "\n",
      "max ever return: 7.524780\n",
      "loss comparison -0.7194991 0.017621027 0.09609718\n",
      "episode 966 in 1.51 sec\n",
      "mean reward: 3.507904\n",
      "return standard deviation: 0.659397\n",
      "min return: 2.012066; max return: 5.947112\n",
      "\n",
      "max ever return: 7.524780\n",
      "loss comparison -0.5861273 0.017548729 0.096260116\n",
      "episode 967 in 1.47 sec\n",
      "mean reward: 3.453726\n",
      "return standard deviation: 0.599572\n",
      "min return: 1.988190; max return: 4.777832\n",
      "\n",
      "max ever return: 7.524780\n",
      "loss comparison -0.70614046 0.018236801 0.09643081\n",
      "episode 968 in 1.53 sec\n",
      "mean reward: 3.517405\n",
      "return standard deviation: 0.604777\n",
      "min return: 2.361270; max return: 4.824881\n",
      "\n",
      "max ever return: 7.524780\n",
      "loss comparison -0.83826816 0.017654058 0.09659157\n",
      "episode 969 in 1.61 sec\n",
      "mean reward: 3.494944\n",
      "return standard deviation: 0.662930\n",
      "min return: 1.503183; max return: 5.838280\n",
      "\n",
      "max ever return: 7.524780\n",
      "loss comparison -0.80317855 0.015931038 0.09675745\n",
      "episode 970 in 1.53 sec\n",
      "mean reward: 3.475748\n",
      "return standard deviation: 0.662596\n",
      "min return: 2.076414; max return: 5.167717\n",
      "\n",
      "max ever return: 7.524780\n",
      "loss comparison -0.7235004 0.019813005 0.09691954\n",
      "episode 971 in 1.55 sec\n",
      "mean reward: 3.463159\n",
      "return standard deviation: 0.628031\n",
      "min return: 2.296489; max return: 5.044232\n",
      "\n",
      "max ever return: 7.524780\n",
      "loss comparison -0.7748691 0.020194562 0.09708436\n",
      "episode 972 in 1.46 sec\n",
      "mean reward: 3.565986\n",
      "return standard deviation: 0.709217\n",
      "min return: 2.070399; max return: 7.524780\n",
      "\n",
      "max ever return: 7.524780\n",
      "loss comparison -0.54931426 0.017185777 0.09725831\n",
      "episode 973 in 1.50 sec\n",
      "mean reward: 3.453655\n",
      "return standard deviation: 0.553001\n",
      "min return: 2.233023; max return: 4.817372\n",
      "\n",
      "max ever return: 7.524780\n",
      "loss comparison -0.37163734 0.018313728 0.097422116\n",
      "episode 974 in 1.50 sec\n",
      "mean reward: 3.523427\n",
      "return standard deviation: 0.594394\n",
      "min return: 2.406013; max return: 5.640087\n",
      "\n",
      "max ever return: 7.524780\n",
      "loss comparison -0.59655094 0.016585052 0.097575724\n",
      "episode 975 in 1.49 sec\n",
      "mean reward: 3.567004\n",
      "return standard deviation: 0.650980\n",
      "min return: 2.233023; max return: 5.336863\n",
      "\n",
      "max ever return: 7.524780\n",
      "loss comparison -0.52935904 0.016147345 0.09771093\n",
      "episode 976 in 1.57 sec\n",
      "mean reward: 3.535798\n",
      "return standard deviation: 0.607997\n",
      "min return: 2.157240; max return: 5.445217\n",
      "\n",
      "max ever return: 7.524780\n",
      "loss comparison -0.77471846 0.017734036 0.09782968\n",
      "episode 977 in 1.50 sec\n",
      "mean reward: 3.482599\n",
      "return standard deviation: 0.641762\n",
      "min return: 2.233023; max return: 5.167717\n",
      "\n",
      "max ever return: 7.524780\n",
      "loss comparison -0.71632814 0.01752609 0.09794654\n",
      "episode 978 in 1.53 sec\n",
      "mean reward: 3.527417\n",
      "return standard deviation: 0.641253\n",
      "min return: 2.058305; max return: 5.035675\n",
      "\n",
      "max ever return: 7.524780\n",
      "loss comparison -0.66025454 0.017426647 0.09808788\n",
      "episode 979 in 1.57 sec\n",
      "mean reward: 3.496640\n",
      "return standard deviation: 0.581762\n",
      "min return: 1.937453; max return: 4.817372\n",
      "\n",
      "max ever return: 7.524780\n",
      "loss comparison -0.60162884 0.017323008 0.09822806\n",
      "episode 980 in 1.53 sec\n",
      "mean reward: 3.498482\n",
      "return standard deviation: 0.635552\n",
      "min return: 1.746222; max return: 5.035675\n",
      "\n",
      "max ever return: 7.524780\n",
      "loss comparison -0.7625129 0.015876258 0.09836964\n",
      "episode 981 in 1.52 sec\n",
      "mean reward: 3.526792\n",
      "return standard deviation: 0.647827\n",
      "min return: 2.233023; max return: 5.742077\n",
      "\n",
      "max ever return: 7.524780\n",
      "loss comparison -0.604997 0.016517453 0.09850789\n",
      "episode 982 in 1.48 sec\n",
      "mean reward: 3.516160\n",
      "return standard deviation: 0.678977\n",
      "min return: 1.986238; max return: 6.015109\n",
      "\n",
      "max ever return: 7.524780\n",
      "loss comparison -0.64694405 0.015359504 0.09865292\n",
      "episode 983 in 1.47 sec\n",
      "mean reward: 3.466688\n",
      "return standard deviation: 0.616747\n",
      "min return: 1.978186; max return: 4.824881\n",
      "\n",
      "max ever return: 7.524780\n",
      "loss comparison -0.70296794 0.017592322 0.09879799\n",
      "episode 984 in 1.50 sec\n",
      "mean reward: 3.534255\n",
      "return standard deviation: 0.629702\n",
      "min return: 2.233023; max return: 4.824881\n",
      "\n",
      "max ever return: 7.524780\n",
      "loss comparison -0.7688265 0.017331917 0.09894079\n",
      "episode 985 in 1.49 sec\n",
      "mean reward: 3.476319\n",
      "return standard deviation: 0.653178\n",
      "min return: 2.146549; max return: 5.522038\n",
      "\n",
      "max ever return: 7.524780\n",
      "loss comparison -0.82754827 0.01688943 0.09908847\n",
      "episode 986 in 1.48 sec\n",
      "mean reward: 3.465143\n",
      "return standard deviation: 0.626570\n",
      "min return: 2.191287; max return: 5.167717\n",
      "\n",
      "max ever return: 7.524780\n",
      "loss comparison -0.7248537 0.016271196 0.09923347\n",
      "episode 987 in 1.46 sec\n",
      "mean reward: 3.530684\n",
      "return standard deviation: 0.661943\n",
      "min return: 2.239748; max return: 5.035675\n",
      "\n",
      "max ever return: 7.524780\n",
      "loss comparison -0.92122555 0.016122933 0.09937558\n",
      "episode 988 in 1.49 sec\n",
      "mean reward: 3.557485\n",
      "return standard deviation: 0.690852\n",
      "min return: 2.223612; max return: 5.035675\n",
      "\n",
      "max ever return: 7.524780\n",
      "loss comparison -0.73214996 0.015676996 0.09952341\n",
      "episode 989 in 1.51 sec\n",
      "mean reward: 3.566609\n",
      "return standard deviation: 0.693998\n",
      "min return: 1.923651; max return: 5.308259\n",
      "\n",
      "max ever return: 7.524780\n",
      "loss comparison -0.5145175 0.013470237 0.09967569\n",
      "episode 990 in 1.54 sec\n",
      "mean reward: 3.572997\n",
      "return standard deviation: 0.643181\n",
      "min return: 2.233023; max return: 4.824881\n",
      "\n",
      "max ever return: 7.524780\n",
      "loss comparison -0.6440811 0.015474071 0.09982036\n",
      "episode 991 in 1.50 sec\n",
      "mean reward: 3.519273\n",
      "return standard deviation: 0.643009\n",
      "min return: 2.029955; max return: 5.921623\n",
      "\n",
      "max ever return: 7.524780\n",
      "loss comparison -0.9747693 0.016987402 0.09995703\n",
      "episode 992 in 1.49 sec\n",
      "mean reward: 3.547294\n",
      "return standard deviation: 0.656236\n",
      "min return: 1.745261; max return: 4.824881\n",
      "\n",
      "max ever return: 7.524780\n",
      "loss comparison -0.5393213 0.015439463 0.10009881\n",
      "episode 993 in 1.49 sec\n",
      "mean reward: 3.507803\n",
      "return standard deviation: 0.586884\n",
      "min return: 2.391042; max return: 4.824881\n",
      "\n",
      "max ever return: 7.524780\n",
      "loss comparison -0.5399323 0.014684473 0.100244045\n",
      "episode 994 in 1.49 sec\n",
      "mean reward: 3.539460\n",
      "return standard deviation: 0.604431\n",
      "min return: 1.974420; max return: 4.824881\n",
      "\n",
      "max ever return: 7.524780\n",
      "loss comparison -0.59626055 0.015257848 0.10039751\n",
      "episode 995 in 1.52 sec\n",
      "mean reward: 3.447461\n",
      "return standard deviation: 0.595039\n",
      "min return: 2.233023; max return: 4.824881\n",
      "\n",
      "max ever return: 7.524780\n",
      "loss comparison -0.70050454 0.017825011 0.10054254\n",
      "episode 996 in 1.59 sec\n",
      "mean reward: 3.518317\n",
      "return standard deviation: 0.664195\n",
      "min return: 2.149918; max return: 5.947112\n",
      "\n",
      "max ever return: 7.524780\n",
      "loss comparison -0.6591236 0.01507416 0.10068543\n",
      "episode 997 in 1.59 sec\n",
      "mean reward: 3.556302\n",
      "return standard deviation: 0.673903\n",
      "min return: 2.381402; max return: 7.465399\n",
      "\n",
      "max ever return: 7.524780\n",
      "loss comparison -0.60863733 0.015438922 0.100823574\n",
      "episode 998 in 1.53 sec\n",
      "mean reward: 3.594171\n",
      "return standard deviation: 0.633117\n",
      "min return: 2.227885; max return: 5.167717\n",
      "\n",
      "max ever return: 7.524780\n",
      "loss comparison -0.62566996 0.015248308 0.10095308\n",
      "episode 999 in 1.54 sec\n",
      "mean reward: 3.541575\n",
      "return standard deviation: 0.626054\n",
      "min return: 1.929368; max return: 4.777832\n",
      "\n",
      "max ever return: 7.524780\n",
      "loss comparison -0.89462674 0.015655205 0.1010635\n",
      "episode 1000 in 1.53 sec\n",
      "mean reward: 3.631301\n",
      "return standard deviation: 0.653396\n",
      "min return: 2.072668; max return: 4.777832\n",
      "\n",
      "max ever return: 7.524780\n"
     ]
    }
   ],
   "source": [
    "### Train model\n",
    "import time\n",
    "\n",
    "# define number of training episodes\n",
    "N_episodes = 1001 #10001 # total number of training episodes\n",
    "N_MC = 256 # number of trajectories in the batch\n",
    "\n",
    "\n",
    "# preallocate data using arrays initialized with zeros\n",
    "state=np.zeros((2,), dtype=np.float32)\n",
    "    \n",
    "states = np.zeros((N_MC, env.n_time_steps,2), dtype=np.float32)\n",
    "actions = np.zeros((N_MC, env.n_time_steps), dtype=np.int64)\n",
    "returns = np.zeros((N_MC, env.n_time_steps), dtype=np.float32)\n",
    "    \n",
    "# mean reward at the end of the episode\n",
    "mean_final_reward = np.zeros(N_episodes, dtype=np.float32)\n",
    "# standard deviation of the reward at the end of the episode\n",
    "std_final_reward = np.zeros_like(mean_final_reward)\n",
    "# batch minimum at the end of the episode\n",
    "min_final_reward = np.zeros_like(mean_final_reward)\n",
    "# batch maximum at the end of the episode\n",
    "max_final_reward = np.zeros_like(mean_final_reward)\n",
    "# best-seen trajectory\n",
    "RL_best_seen_actions = np.zeros(env.n_time_steps, dtype=int)\n",
    "max_return_ever=-100.0\n",
    "\n",
    "print(\"\\nStarting training...\\n\")\n",
    "\n",
    "# set the initial model parameters in the optimizer\n",
    "opt_state = opt_init(inital_params)\n",
    "\n",
    "# loop over the number of training episodes\n",
    "for episode in range(N_episodes): \n",
    "    \n",
    "    ### record time\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # get current policy  network params\n",
    "    current_params = get_params(opt_state)\n",
    "    \n",
    "    # MC sample\n",
    "    for j in range(N_MC):\n",
    "        \n",
    "        # reset environment to a random initial state\n",
    "        #env.reset(random=False) # fixed initial state\n",
    "        env.reset() # Haar-random initial state (i.e. uniformly sampled on the sphere)\n",
    "    \n",
    "        # zero rewards array (auxiliary array to store the rewards, and help compute the returns)\n",
    "        rewards = np.zeros((env.n_time_steps, ), dtype=np.float32)\n",
    "    \n",
    "        # loop over steps in an episode\n",
    "        for time_step in range(env.n_time_steps):\n",
    "\n",
    "            # select state\n",
    "            state[:] = env.state[:]\n",
    "            states[j,time_step,:] = state\n",
    "\n",
    "            # select an action according to current policy\n",
    "            pi_s = np.exp( predict(current_params, state) )\n",
    "            #print('policy:', pi_s )\n",
    "            action = np.random.choice(env.actions, p = pi_s)\n",
    "            actions[j,time_step] = action\n",
    "\n",
    "            # take an environment step\n",
    "            state[:], reward, _ = env.step(action)\n",
    "\n",
    "            # store reward\n",
    "            rewards[time_step] = reward\n",
    "            \n",
    "            \n",
    "        # compute reward-to-go \n",
    "        returns[j,:] = jnp.cumsum(rewards[::-1])[::-1]\n",
    "        \n",
    "        \n",
    "            \n",
    "    # define batch of data\n",
    "    trajectory_batch = (states, actions, returns)\n",
    "\n",
    "    # check size of losses\n",
    "    preds = predict(current_params, states)\n",
    "    # combute the baseline\n",
    "    baseline = jnp.mean(returns, axis=0)\n",
    "    # select those values of the policy along the action trajectory\n",
    "    preds_select = jnp.take_along_axis(preds, jnp.expand_dims(actions, axis=2), axis=2).squeeze()\n",
    "    # return negative pseudo loss function (want to maximize reward with gradient DEscent)\n",
    "    print('loss comparison', -jnp.mean(policy_pseudo_loss(preds_select,returns,baseline)), -jnp.mean(policy_entropy_pseudo_loss(preds_select)),  l2_regularizer(current_params) )\n",
    "\n",
    "    \n",
    "    # update model\n",
    "    opt_state = update(episode, opt_state, trajectory_batch)\n",
    "            \n",
    "    ### record time needed for a single epoch\n",
    "    episode_time = time.time() - start_time\n",
    "    \n",
    "    # check performance\n",
    "    mean_final_reward[episode]=jnp.mean(returns[:,-1])\n",
    "    std_final_reward[episode] =jnp.std(returns[:,-1])\n",
    "    min_final_reward[episode], max_final_reward[episode] = np.min(returns[:,-1]), np.max(returns[:,-1])\n",
    "    ind_max = np.argmax(returns[:,-1])\n",
    "    if max_final_reward[episode] > max_return_ever:\n",
    "        RL_best_seen_actions[:] = actions[ind_max,:]\n",
    "        max_return_ever = max_final_reward[episode]\n",
    "        print(\"new optimal trajectory encountered:\")\n",
    "\n",
    "    \n",
    "    # print results every 10 epochs\n",
    "    #if episode % 5 == 0:\n",
    "    print(\"episode {} in {:0.2f} sec\".format(episode, episode_time))\n",
    "    print(\"mean reward: {:0.6f}\".format(mean_final_reward[episode]) )\n",
    "    print(\"return standard deviation: {:0.6f}\".format(std_final_reward[episode]) )\n",
    "    print(\"min return: {:0.6f}; max return: {:0.6f}\\n\".format(min_final_reward[episode], max_final_reward[episode]) )\n",
    "    print(\"max ever return: {0:0.6f}\".format(max_return_ever) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Kww9Njff2tlV"
   },
   "source": [
    "## Plot the training curves\n",
    "\n",
    "Plot the mean final reward at each episode, and its variance. What do you observe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "id": "VVL-xZlg2tlV",
    "outputId": "1570c4d0-d309-4d00-879b-473b77edef36"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjoAAAG9CAYAAAAcFdw9AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8fJSN1AAAACXBIWXMAAA9hAAAPYQGoP6dpAADZMUlEQVR4nO2dB9wcVbn/z5tQIlJSkBKBkALYaAmoKFeQFLigXklFQC9eSNGLjZKCgihXUoj1+pcUUC4ihIQmCkISAqKCAgkdpSQklCAtBRBCINn/53s2z77nPe/M7MzuzO7s7vP7fPYzu7MzZ86cmTnPb57aVigUCkahUCgUCoWiCdGl3h1QKBQKhUKhyApbZdXwa6+9ZtasWWPWrVtnf3fv3t3svffeWR1OoVAoFAqFIjuis2TJErNgwQJz3333mWXLlkVuO3DgQDNkyBAzbNgw8+lPfzqtLigUCoVCoVB0QFs1PjpobaZOnWrmzJlj1q5dWyIxhxxyiNXg9OrVyy4Bmp1XX33VLiFDK1assN979Ohhxo8fbyZPnmx23HHHSruiUCgUCoVCkZ5GZ+7cuWbSpEmmX79+Ztq0aVZD07dv30RtPP3002bRokXmmmuusYRnxowZ5swzz6y0SwqFQqFQKBTVaXTQ4hx11FGmf//+luAkJTdhQMODVgfyA/Hp06dPKu0qFAqFQqFoXSQiOpCQUaNGWW3OwQcfnEmH8O/BlKVkR6FQKBQKRU2JzoQJE8z06dPNTjvtZLIEvjtod2bNmmWyxubNm83q1avNDjvsYNra2jI/nkKhUCgUiuoBfXn99ddN7969TZcuXbJxRm4GPPfcc2bPPfesdzcUCoVCoVBUgGeffdbssccetc+j0yhAkyMDlWbU1zvvvGMWLlxoQ+i33nrr1NpVdIaOdW2g41wb6DjXBjrOjT/O+AyjqBA5HoaWJzpiroLkpE10tttuO9umPkTZQse6NtBxrg10nGsDHefmGedybicVlYC47rrrzKGHHmrz5BxzzDFm1apVpf9uu+0261/z1a9+tZKmFQqFQqFQKFJDYqJDxNVpp51mBg0aZMaOHWteeeUVmyTw9ttvt/8PHjzYjB492syePTu9XioUCoVCoVBUgMSmK8o8EGbuRl6RAwdyQ8I/cuxo9JJCoVAoFIqG1OgMHTq0U3g52ZEp64DDETWvpOyDQqFQKBQKRT1RkY+OeDs/8MADHdaRKXn58uU22Z9CoVAoFApFw5muxo0bZxMHosHBhEWhThf47SxevNgm8lEoFAqFQqFoKKKD2YqMxevXrw/dhgKfUs1coVAoFAqFol6oOI9OuTIQWZeJUCgUCoVCocjMR0ehUCgUCoWiaTU6+OfMmTMn3d4YYyuX77333qm3q1AoFAqFovVQMdHp2bOnOeSQQ9LtzZZ2FQqFQqFQKOruozNixIhUOqFQKBQKhUKRBdRHR6FQKBQKRdNCiY5CoVAoFGD1amO+973iMmpdnpFGf1dHtNFo46FER6FQKBSKLZg715jf/a64jFqXZ6TR37kRbTTaeFTjo5O0XMSOO+5Yi0MpFAqFQlEZxo7tuAxbl2ek0d+xEW002nhkrdGZO3eujcwaOHCgOfTQQ80ll1yS5eEUCoVCoagcvXsb893vFpdR6+KgXiaeSvsbt40k7a9ebbpccIHptmaNaSqiQ6HP0aNHm3322cesWLHCLFiwwDz11FNm/vz5djlgwAAzZsyYTgVBFQqFQqFoGjSgiSd1zJ1r2m66yfRZuNA0vOkK09Ts2bPtp3///rbwJ8TGRd++fW11cz633XabmThxok06SIJAtlfTlkKhUCiaBg1o4kkdY8eawqZNZlXfvqa/aVCNznXXXWeGDRtmBg0aZNra2szSpUvNrbfeWja/zuDBg83ChQttBXSqnGPaOvroo217CoVCoVA0PNIwITU6evc2m88912yocyLgionO/fffb+bNm2emT59unnzySXPWWWclLuTJ9meffbY1aU2dOtW2pyYthaIKNGDop0KhUOTSdHXwwQd3Mk9VA7Q6abanULS0XwDgbVKhUChaHDUJL1coFDWC+gUoFApF7YgOTspr1qwx69atM/369VOHY4WiVn4BCoVCoUif6EBs5syZYxYtWmQWL15s1+FsLMBhuXv37ja3zqhRo8xpp52W5uEVCoVCoVAo0s+js3LlSps7hxDye+65x4wcOdJGVKHN2bx5c+nDbwiQ/C85ddhfoVAoFAqFIncaHbIfkz/nnHPOKetMTJQVTsx8xm7xIbjmmmtsHh3C1IncUigUCoVCociFRmfy5Mlm/fr1VjszfPjwitpAu0NOHUjQlClTqumOQqFQKBQKRToaHfLoYHZCO5MG0PDQJnl0DjrooFTaVCgUCoVC0dqoKo9O2siiTYVCoVAoFK2Lqp2R0cAQbaVQKBQKhSJBtvJKMplr9vPEqNoZGR+btWvXmiFDhthcOb169VKnYoVCoVAoymUrrySTuWY/r08enRUrViSuc6VQKBQKRUtnK68kk7lmP6890UGLoyRHoVAoFIqE2coryWSu2c9r76NDpmOFQqFQKBSKpiQ6lHVQKBQKhUKhaEqis3z5cvPggw+m0xuFQqFQKBSKPBEdKpMPHDjQdO3a1RxzzDFm5syZNuS8HNhOoVAoFIqqoSHXiiydkfHROfvss23Fcko58BFz1tChQ23YOR8/2/G9995b7aEVCoVCodCQa0X2UVfTpk2zH0B1ckgPS5f4QIgOOeQQW7xz8ODBNiRdoVAoFIqqoSHXiiyJju+MLBocgRCf2267zS75qAOzQpEyUNnzVstET/ipQtFK0JBrRZZEp5xmxic+EJ758+ebSy65pNpDKxQKgaruFQqFIhuigzPy66+/bnbYYYdY22O24vP0009Xe2iFQtGsqnvVUCkUirxEXW3evNnWu0oKTTSoUGSgum8WUiAaKpYKhUJRT40OeXTmzp1rJkyYYAYMGGDGjRtndtxxx7L7EZGlUCgULaGhUigUjavRAWPHjjWzZs2yS5yP4+6jUCgULaGhAprrRaFoXKIjoLjn8OHD02xSoVAomgNqjlMoGovo4Ew8ZcqUVDtDe3GyKiuaAPp2q2g1oMX+7GfVHKdQNArR6du3rxk9erQ5+uijzapVq6rqxMqVK207+O34GZQVTQp9u1W0GprRHKdQNLsz8sEHH2yuvvpqS3hIAjhp0iRz1FFHxd5/yZIl1rdn/fr1dgl5UrQI1NlUoVAoFI1S64oyDyQChKwQat6/f3+bJLBXr172/549e5o1a9bYnDuvvvqqdVhetmyZLQY6efJkM2LEiHTORtE40EymCoVCoWgEouMnAgTXXnutLdp5zz33WHJD9mQID3WxID2EoEOEVIOjUCgUCoWiIYiOCzQ0qqVRKBQKRcNk246bjbuarN1pZPzWrOH1DS9XKBQKhaIhAyDiBkhUE0iRRhCGBnLkQ6OjUCgUCkVDBUDEDZCoJpCimn1Fk0OKgkrbaFFkQnSoTL5o0SLrkyOOyXvvvXcWh1I0M1RFq1AoahUAETdAoppAimr2FU0O0ECO+puupk2bZokOJGfQoEFm6dKlmgxQkRyqolUoFIoiNOFkvjQ6Tz31VKd8OzgnE4I+c+ZMc9ZZZ2VxWEWzQXPtKBQKRRGakqN+Gp3rrrvOvPbaa7G2JfwcwgPZUSjKQjPJKhQKhaLeGh3IC2YqcuWQHRm/HHxydtxxx8DtyZ2DhgczlpZ7UCgUCoVCkWuiQ8VyN2cOxT4pC0GiwDDiAzlCq6NER6FQVA11WlcoFLX00UFjM9bxqfCJD2UfqIdFpmSFQqGoGhqNolAo6plHxyc+999/v7noootsvSvID8TnkEMOCTV1KRQKRSTUaV2hUNSD6OCgHERe8M/hQ3FPoq98jY9GZCkUikTQaBSFQlHrPDpUJMc01bVrV3P00Ueb66+/vsP/S5YsMevXr++g8Tn77LOV5CgUCoVCEdc37XvfKy4V9dHorF271kZjzZkzxzori38Omps1a9bYJIIKhUKhUCgqgPqm1Zfo9OrVy0ZjjRw50n7Q3mCeWrZsmc2WzDotCaFQKBQKRYVQ37T6Eh3MUDgc9+jRw5x22mmW9IwbNy6LQykUCoVC0XpQ37T6+ugI2SFfjta3UigUigZEo/uANHr/FY0RXo6jsUKhUCgaEI3uA9Lo/Vc0Th4dhUKhUDQgGt0HpNH6n3aGb80YXj3RIf8NEVVpY/z48eqorFAoFPVGo/uANFr/09ZAqUareqLTs2dPm9E4bdCuQqFQKBQtpb1IWwPVaBqtPBIdv5inQpFbNMMkqFAostNeVDtHlNs/TvtpaKD847jtrW7deVB9dBTND1XhKhTNjWq1F9XOEWH7C7l4/XVj7rij8var7UeLz4NKdBTND1XhhqOF3/IUTYRqtSHVzhFh+wu5OOIIYz772eznoKjzGNu682BmeXTCcMkll5S+z5w5s9aHV7TyJKiCvDNkImapULQqqp0jwvaHVEBwzjyzNnNQ1Hn0bt15sOYaHbIlQ3ZwOsbPR6FQ1BEt/JanUGSORov8alLUlOiQJZnCntOnT7eEh1By1h100EEVt0mI+/Lly0u/qaWl5SaaGGpqSRc6ESv0mVI0OWpmuqKw57x588xtt91mq5evWLHCLF682K5buXJl4vaogj506FD7HeLEZ8yYMXZJ8VBFk0JNLQpFutBnKrpkRKWlJLQERetpdDBTTZs2zdx///3mqaeeshXOycND0c9KMHbsWNOvX78O2hsIFJ/u3bun2HNFrqCmFoUiXegzFR2VVGm0UgtHOZlW99GZPXu2mTFjhikUCmbSpElm1qxZidtAY3PNNdd0MFmBIUOGmLVr16bYW0XuoKYWhSJd6DMVTfgqJYJKIFs36gpis+OOO1oNTyUkB0ydOtVqbdDoKBQKhUJRNcKikpJGK4nJCsTdr5HNXKvz3/dMNDpEVS1atMgSEZyD0bSkWb8K/x7axk9H6m29+uqrsRyR3377bfsRvPbaa3b5zjvv2E9akLbSbFOR4livXm26XHqp2XzqqflwwMxbfwKg93RtoOPc2OPcZdYs03bTTaawaZPZfO65me2Tl7mpS5m+Z3k/x22zrYANKWUMGDDA+spgoho0aJAlJvfdd591Fq4mwkrQ1tZmyRPOyBMnTiytHzVqlA1bxzwWhvPPP998T9i2gyuvvNJst912VfdN0RjYb948s+u995oXDz3UPH7CCfXuTu76o1C0ArqtWWP6LFxoVg0bZjakVGexkjaz6Eet5qZudez7m2++aU488UQb7ISlqKZEJwxEXOGMfNZZZ1XcBlocQtMBPjqu+QpChVYHbRJEKK5GZ8899zSvvPJK5EBVwjTpB2Rs6623Ni2BOmklKhrrvGlQ8tafALTkPV0H6Dhn/Jz95Cf268bTTzervvMds8/jjxvzmc901EbEfR7d7dBuBH2P2v/++03Xr3/dFA44wGz+9rfb9/vMZ0yXq66yvzd/4Qumy+9/n3xuqOQcevcu38cEJjza3fif/2kWPvJIJvcz8nvnnXcuS3SqNl1dd911llTEIQmDBw+2xISMyJWSHYmooh3fR0d+o9EJIzrbbrut/fjgAmQxqWTVbi5x2WXG3Hyz6dq1a12cGxONdZ8+xnz/+6aryQny1p8ItNQ9XUfoOGeQJ4g56uqr7eptdtjBaiH22Wcf03XCBNPVHWu2u+EG0/VPfzLmN78JF+7unAeCvjMXhuUqmjSJ6BpjHn3UdH3/+9v347gQMGNM1wcesLWyuv7rX8YgZ+PmO4o7H19WZrs//MGYZ56xH9vHcnO7V99rG9YNGpTJ/Ry3vaqJDuSFtw+0KZiUIBtRxKdv377m4IMPrjpRYFgIOevpi6IOyEuUgSZAUygUQWHezAn4Zba1WQ3GhgceMJtPPrkjyZHtKML56qvF/cOEe9CcF/Q9LNT8hz805vTTjTnggI77UTYCgtXWZsyJJxb3hTgkCVePOx+PLbOdM2ax5navvtfmU04hW7CpJ6omOkRPjRgxovT76aefNldffbU1MYURH8gRWp1KiY44IgchbL2ihcJUNX+FQqEIEuTMUZALgCNrmABmO4iGvDDFnfPCvoeRiYEDjbnrro7rZD/+c7fjBW6HHeK/SMadj3uX2c4ds0rGO2qcGzXqCo0NyfzCiA8lII466qiqkvpBnObPnx/6P4kIFS2MvGiWFApF/VFOkEMgMN/4GuA4RCGu9jiNl8C8vEg2YD8zz6MjxOfss8+2fjk4El900UVmwYIFVquzZMmSUoh3XJBoEOLkm6ik9AM1tBQtjBau0qtQKJIBh9nQEhh+jhj3N5+TTjJm3rziMiiPjL99nHwztcxLszrBsRogX07NMyNDXoL8dPDP4UPeG4iPr/GJ46SM6YqwcggN/kECCBXr0Ropcoigtx/1p1EoFHUEvjrWETdIA+ybwd3fAB+eDRvCfXn87eOY1Gtpep+b4FgN7BKQCdGZPHmyzaEj+W4mTJhgjj/++NL/aHEIBwsydcUFxTtJFii5c8jbM2XKFDNy5MhUz0WRIoIelCweHiVPtUejjHmj9FORD1OLbwYPMovjOMwcFiTHyjkrxzlmlhib4FgN7BKQmUaHmlNoWyAjOCuLfw6aG0jJ0qVLqz4GWZDLZUJW5AhRD32aD4+QJ0yiScIxFZWjUd72GqWfinySoDDn4zArQpSzctxjZoneCY6VQ9+buhIdKpMTjYV2hQ/aG8xT+NCQ0I91aZaEUDQIgh6ULB4eIU1JwzEVlaNR3vYapZ8KhSLfRAfHYxyOcTw+7bTTLOlRzYuiZhDylDQcU1E5GuVtr1H6qcjWREnW3lmzTLe+fdNvu1q47QNCu8lhc8YZ4ceL26fVEdtVel4NYA7OLOoKskO+HBIDKhSZgQnrggtsvZXMo6/iRB00cGSCQtE0EBNlUCTVlv8pREmNptTbrhZu+3woBXHlldHHi9unuRHbVXpeWY9Hnn10xNFYocgUMmHtu68xJ5+c7ZtHHP8O9QFRKOqPGNl+qba9qm9f0z/ttquF336crMRpZEEeW+F5NYA5uGKig98NoeFpVCMXrFy50kZQpVlcU9HkSDJhVUtC4jzQDfDQKxQtZb5GwxqQDJAinhtuvrnytrOC336crMRpZEHuXeF5NYA5uGLTFZFT+N9QEO2SSy5JnPTPxdy5c202Y0LFaVfRYqjG3CMTVs+e5bdlsiMUtFISEscUpskKFYr8zCW1MKvUw1xd70R/qxvLRN+lGrPUfffdZxYuXGieeuopGzo+ZswYmyMnDthu9OjRliiR4ZhMyffee69GY7UiamXjVRKiUDQ3mEOuvbY9U3G1Lzd59VFJcsy5GfSvAfxyUnVGhvBMmzbNkh0iq2bNmmXJC+UdfC0Pv4nGGjBggE34R2bjJ5980kydOlX9eVoZtZiMsn6DabA3HIWiLvdtJcdLsg9zSK9e7ZmKa/FyU4/5K8kxx2bQv0aYs7OKuiLKimKbaHoKhYLV8hx99NHWtDVs2DAzaNAgmziQZIG33nqr3V6haAhNS4wojkZ6w1Eo6nLfVnK8JPtI1fERI2onhOsxfyU5Zu8y21ZCPhthzs466oq8OYSX87n//vttskA0ONS4UrQ4GiDnQqVRHJH/KxR5RK3v20qOl3SfBnCOzRXmNn+kaKbh5W4RT4WioR+qcpOnTq6KRnm58H/X8r6t5Hhp9dFLxBeZMLBRX8gqwdjmf0nLLGGgQhGoHsWu20C2XYWi4Z+5H/2oo+knL2bWSv2DgvaL0xZh2rNnF5flEgZWOkaN6KvXOyUzVI7PPXONjkKRqiZH3rTcisHve19q3VQomu6ZO+KIji8XeXmDr3ROCNovTlsk3ZNlufxblY5Ro2qs00COz12JjqI2qGTiCFIfy8N0xx3Fop3gnHMy6LBC0UTPnJcsLxeCKM1MvHHaolaU1L4rlzCw0jGK6keM+lsNbS4bmxMCnSbRISvynDlz0u2NMTbkXHPpNCGSTBzywENkIDRA9pWHyNXorF5t9ps3zxiydPfpk9EJKBQNhrwQmjCkmYk3Tlth2zDfXHZZuA9TEMK2CTqGP59J2hW/UKfkAGIbIsfiFueUfdMgSKu3mJ8eftiYn//cmIED459/ju+3iokOpRrIZpw2aFfRYEj7oQtTufsP05aHsMt555ld773XdLn0UmO+//2qT0ehaEg0ukagTrDzhmh2mFvSrmnnz2cQHop0AjRM7kscJEdyAEW16x4fpGUymju32LcNG4w580xjbr+9/PFzSm5SITqEkI8gV4FCkfZDF6ZyD8HmU081Lz75pNn+1FNN18qOqFA013PIs9PKpAfSh9OxrzUJmT+6/utfRQIi2ZSB+4Llk8gkZhp/PqOtQqFzoU7JAeS+NMZp019XDcYWNeRWoxNVYyvHZqogqI+Oonqk/dDJRBJ3ou7d2zx+wgmmfytO6IrWRZTwbbA37tTB+V91VWetSRAYOwpJM16yrV8QlMg1NB2QoZkzO5tpgoIkwkw6/A4jEW4xUjQqQtTknKRdv820rnHv3sXItDjbNdB9pURHUT2iHrpK1emtPlErFEmfEfc5bLA37tTBeeML42tNorZ3l/74ooFxlz6CgiSqmbd8ogZ0Psw30Vm5cqU6GLcqkhAWlxS1+kStUJRD1DPSYG/cqSNKaxK2va/FCRpfTFxnndXZHBYUJJEWUaNNtCzbbFP87iNImwTcdZ/9bNEsFmbKS/pC2mD+YDUhOkOHDrXFOxUtiCSERUgRDziq5AZ5iJplMlA0GFqdzNTixcwdX+akMHNYQJBEakQN4iV9Yint+9FcrjZJtpV1d9xhzOOPt/fddw1IqkFvMI17TYjOq3iRK1oT7gRQTvALGeLBbKCHqFkmA4Wi5RH1YpbUHJZmn4KO60dzBWmTgjQ6YwN8uJJq0MO2z+nLXU2IDhXLFS0I/6YvJ/hd9bG8dUS1V+v+J4Wa3xR5QE6FTy7PKUpLltQclhbCjhsUnepqk3wN08CB4XNTUu1g2PY5fbnTWleK7ODXi+GhilPnKqz2Sq1r9IQdL25Nl7DzyHFNGEUTotr7OI/IS72uRq1R1Tul+lY+4s7xNYZGXSmyQ9RbQyVvZLXWkIQdr9q3lpy+9dQVzah1yAuyuo/rCdWW5hO98+k3pkRHUZ+bPkm68zjtZSFMw45X7SSrk3RnNLLQzTuyuo/riUrnAncO0GLALQM1XSnqAyaaXr3a0503krq7WrVvVmrjRkZOVd65RFompzj3YSObt4KgJq+WhBIdRe0hb1U42FFGRNKOZzGhuu3WQ5g2m6DICkr+8imsm40YpDUHSOZicuoEPdtJn/u42/vbye9ly4r9mTAhvE9uv+NsF9Qfd31YX9x9Vq82XS64wHRbs8bUE2q6UuTDTOHmikjTdBGVF6MWUJOM+t+kjTRMTnGvSaOZt8LOy10vz+E772RXYiKrvDT+dm5GZvLkkJqD/oSVvZi7pd9xtgvqT1Rdw6B95s41bTfdZPrsu68xJ59s6gUlOoraoFzW47AJVd5U0P5UkogryUSdpkB2s5XGPX6zQsle/hw+416TvDmXlntG4wjoNM6nXE6dtPLSlNvOzciMryOZm7ffPrydsVv6HWe7oP7Embu9/wqbNplVffua/qaOKNQAPXv2LOQV69evp3iJXaaJjRs3Fm644Qa7VBQKhfPPLxQGDSouk+DIIwuF7bYrLrMe60r7CJ5/vrgfy2rbqgf8/qc5zjHaVtR47qjHNan2mOzHPLD//u3Pld9m2DEC1uscXRtkOc5x5bdqdBS1QaUqcDQ5otHJGtWo6avNNNrMWpc4WgE1b9UGQSacWiGNtAwELxDE4NZzCitsmmfNlKKmqAnR6dGjRy0Oo8gzKp1oMFfdfrupCaqZDKvNNFpvuCpwKWpYS8Kh5q3mH+c00zLIvdloLxSK5o26euqpp2pxGIWifmikqKGg6AjpP0KwHlE2UdEwGrlWOfyxq2cYfxZpGappc/Vqs9+8edH3VbnoqjLtd4pKqrStsDbTwurgiKnIdf75pHF+GUFNV4r8oJHMF2n0tV7nG/VWX6835HLJJVXbUxmCTDt+5eoWRZdLLzW73nuvXZrvf7+y6KooBEVIVdpWWJtpYW5wxFTkOuCej/87R8+qEh1FdkgqyPMo0MLOIY2+1ut8o8hMHk1utSJfjUK0k/QzyCSZx+esDtds86mnmheffNJsf+qppmul0VVRCIpGitNW1Dll9SyMjRkJ66/zz6ce1d3joNDi0KirDJE08qhcVEbI/xtXriz8/YQT7LJm55BG1EqDRSM1/T2dk0i5suNcST/dfWp131VynLj7yHZnnlnxNcvt/ZyT+7CZoq7qlhn5K1/5Sr0OrcgaYsflLTKJP0A5e3tIltYOKuhq++zblsN8GtLwyWkkv56kaES/mkYpQ1FJP9190rzvoq5zJVmV4+4j2xUK9fHtyrLtONc3jeOvbsBntNFMV2vqnBJakSGCVONpmAVC1LaxVNBx+4zqdccd2/uZR1NOIyCueSRP5qJGudaV9DOrc0vb3ytJ4jzXTJIkeaBg9Wrz4V/9ynQhq/DZZye7/6o1/3HfkzKD/p94YrGtJHNOkuOvjjC/Jy2s3KpE57rrrquI5CxevLjaQyvyiqDJKg2/gIgcGY+fcILpz/+VCk7p6wsvFB3qmERrkbunWRFXYKVxX+SJLDU7/LGu1N8r7JrFJWRsxwsJ906Y42uZexAN8PvvvNN0ueceY7p3L7ZRq9IYrmPy0qXFkgxJnoEkx5/rPGOuIzofSI4UVk5y/q1GdObNm2euvfZafH0S7dcGk1U0J4Imq4wdSika12XiRGP+9jdj3nij+MA+8UR76YhyD7D0mdBIEPf+bNKJoWrEFVhp3BfN5FxbD7j3MEhSYqESTRHHO+mkooCVdipBuXunTN/QBD//0EOmb9++pmtYAsKsNGSuRsrV6MRFkuOPdcbJPz80Of61b8JnqWqiM3fuXNOzZ08zadKk2PusXbvWjB49utpDKxoJYQ9mSkShz8KFpu2PfzRm0yZjPvQhYx5+2Jj77y9WR//LX4qEJ46m5owzim+IcSedJp0YaoY0TCpBAk8JaPkabCJcowo1pk1MheT885/G7LZb8nb861rNvdO7t3n0y182fY491nTdeuvaRvjRd3ceqqSOn4uo+723M07lEps2aQLGqonOTjvtZLUzsOK4YNuB1V5YRb4RV9CkRBRWDRtm9mHifOutYrG6oUONmTDBmPe8p3gM0dCU09QknTybdGJoKARdszQJaDORJrfatZhLosKIq31h8ddLGQee1Ur8QrJ+sWgUPy0faWmiejfo+ZdBKlFXr4oKMgH69euXxqEVeUXc6ImUIgw29OxpNs+YYczuuxcn8b/+tajJGTOm2DaamvHji8skKJftM60IlkaNEGmFCKpKoofyet1kXNAmBEVhVXo/h42Ru57zQKM6bFg0yYk673pGxpW7Hllcr7jHDItwlf+XLeuY0dhfF7QtS+bMT3yi+D2qrVtvNebTn27fjv0OOMCYQw4patabIepq/vz5ifeZNm1aGodW5BVxNR0ysboPrBuBkDQ6wD2u/3biv6nEeVOvJJtpJRqASt9U455Dq5nX0nwzrZPWzqZLuPnm4o+0zsUdlzS16mFj5PuHYF7mGa9Uy1vPzM7lnqMsnrNKjunOCUEaPOCvk8zN7nqW991nzIYNxZe9I48Mb+uyy4x56aX27a680ph//ctq0LsS0Zb0BTNlaGZkRT4ETdAD6dqV/eiAJMetJruxH8YaBz/6UfFB5zxmzsxWmMY9h0rabgYkIZ3VRgKlDJxlu3bt2hjXLU7V8CSh47IMuiZJCYUbyi0ClzZOOaUYxHDBBUUzt7Qfdh9E9V+0VQj5coVxg/ykwu7NcmMWFuHKiyFaFrQqRx4Z7PDM8XlxZJ6iT/Kf9Ivl7NnFqLA99ihGpIa19fGPo70ojjNmSdq7+25jttnGbDr1VPOJ73ynqG3/6EdNXVBocWhm5CqRVpZVaWfp0uD2go6zZR0ZkWNnkmWfM84oZlT1j1Xpufj70f7uuxeXWSPrLLdO+7m7p+Oce5Iss5VmpE35GpQd5wbLqF0VgjI6h80RUW3wPPLh+5Y23z33XJtRfdPAgR2vebWZp8vtL/8feWQ2GZAZF9reZZf2cw5DnHP1xy8hNn3qU4V3ttnGLuslvxNpdKZMmWKmTp1qaoGZM2easyTUV5FfhKlO3TeoOOrlcir1CIfTLps2mW59+3Z+MwtTn4eZoipVPfv7ob6VpINZIM3IkyTnds45+XLiTVublVTzJecnav6ofqSJvJoi07zertYjLDQ67nFDtLKbTznFrFqyxOyzzz7BjthJnt8kDt2+5iTteYIxQFMjc/DYiPbjnGslWm0Hmy66yKw79VTT/aKL0nEKrgRJ2NPSpUsLhxxySGFlFjWFtuDpp58uDBs2rHD//fcXagHV6FSJoLfLKt8Akh5bal11ejML6p+r0YmjNUrQjyBtUypv3X5b1dbCSdK3ajQ6WdfsqbdmQ86P+ykvGp1KtR5Jj1PN9Y7T//HjO2tFw/ar8D5rmTm6zshDravEpivITv/+/QtTpkxJnRxMmjSpMGDAgMKyZcsKtYISnQwmvygykcHxGeNbfvlLq4pOaxIMBQIEtTDLiD7Z3/vv375tEoFRjtiE9cEdc7eNqPYSCLNS8dS//S3ePTBuXKFw2GEd+xl3/BoB/hindM9XNXekaRZJuyhvnHblP+4biA7jmdZxW2WOzhk25oDoJHZGJv/NU089ZcaPH2969OhhRo4caSZMmGA+TWhZBViyZIlZsGCBjdwiieCTTz5ZUTuKGiGO2txPhlUOSZzzQo5vw8tPPrk98VdWjriYpUgZz/L228P7xLkQifDuu8Vto1K8B+Uacdvzz4H/cMymXYlC801ysp0grL0EZhApnmqjKIioiNrHbZelmCPjjl8jwDUb4nyaNDqvGoSZa7jvMKNNnlxMsVDNfR/32XH7EqfkQ1i7rkNvkmzBTZr7RZGDqKvZs2dbskOY+ODBg23SQEjQIYccYvr372+6d+9uMyazBOvWrbM1rlguX77c3HfffWbZsmW2dMTQoUNt7auDDz44xVNTZIIsIniiIq6qPb4fvl4uEkL+DxMkEDiEtEvkgvokNXh69Spu60/aQSGgct5xspf6UWhhdvSg75VEwrjFU7/1LdPlD3+ozK4fd/waLUlflX4MiRFGDlnHMwTJSZJOIexlIw6BCCuIG9XfoL5JWQiymUOMXV+9OH1vlHtFUXukoT5au3ZtYfr06YVRo0YVevToUWhrayt9unTpUvrIOrYZOnRoYc6cOYV169YV6gk1XeUAQX4FSUwqcca6nD+Fr07P2g+mQvNR7PYzQKdxzrIPWfv35Bix7uewsY+6JnFMRpWYvMQciV9N2L5xngcx9Zbre0o+azpH1wYNaboKAlqbiRRU3IL169ebFStWlDQ47nZofCgboWgyVPNWFRRxhfalUnNGUF/kLZu33aB2/dwdcXJihOXniHobdt+c+U6uC75Xkogw7cSCSZEkkWPcwpHu+HANJMcHtZFEExQUlVdOI5dGPp1yZtZaahbi5K3xEaW9cyOB3NwqccaK64Im5r3vDc/O649LUBV00YgFHUOexzgaUIWiFgkDITJqhmoxpO1nUc3kFdQX14QVVLTT97eQDK60EybMo/xi4viuUF39wQc7+qskPa+4BCIJKfEhxzjllPbf+B+JP4iY0EQI+cd3Czmy/aBB4eHY7jliBuF7oWDMddcZ8+KL7X5J/jn7Id7+WCW5P6PGKsrMWs0Y1wJRJMj9j/MT02s5nzKpXYWJlmsTp+J50Dr2k+sdlPbBzajskjJ5CUkSbq5oOWhmZEX1SJIVNC6qcTCMIklx2vX3D8vKHMcvJqptxsr3VwmD/1YrcAUGCBPmQX49QceIyCBNviJISofSBC7pCCMTIgxJJc8S4hJWryjo2kEounUzZtddi2MVdM5HHNGxzXLLqHOPGquoHChxxjgrxNGaxEW5sXLH3902SXbfsHWuFk/aE0ItOXXkGfa1vvXKa6TIPwotDvXRSQHlsoJW68vh749PAOGn+AS4+V3I71RNGHe122W1f5QfQlQYedJ+lDlGKQN12DiX8xupNLdLUC6kCny5IuGfe5o5lZL8X+ncEXTtkviBJc2tlGb6CPfY5c4jqs9BfngR59VSc3SL++go0VGiUz3KCZ5qHUv9/XFY3HrrQmH77YsCeMtY2zw6SY5TK4fXSo+ThUCPe7xmvKfjJKoLIlM1vhcqGueg/pYjEAn7FXv7pKSJ5xlH5DBCVs0LSUQ/G/5+bhBsVKJTfyjRqQGy1ugkSWSXZr/iotLj5CzyqOHv6STjmcbYVyi0E41zXO1Kub5EaeOC2k8a3RW2Pe1Sk4nnOYvnUDU6dUceiI766CiyRxJ/myC/An9/om7uuqv0s8t559lEdl1+/3tjvv/9ZMeohQ0/7vkHRaI0WjRJXhxBoyLv4oxnGmMf5RSfFqJqt8WsFVfqX5BDL/4uQe2Xi+7yfW3CHOnlOT7ssGDfIulnpfeTJhNUqDOyIncCrYLorVIiu1NPNV0zOkZNEJR4LSrpm+wTNwliLa5lXsa2WpKRhoAMig5KOr4VFqxM1L+g/WT8cPL+wheStS8RVESgQWQ+8YlipmP/WBzjjTeM+dCHik75/rEF5ZIRKhR5JTqvvfaa2ZEbV9GY8AVJJcKy2rduJ+z58RNOMP3jHjevmpJyuX6SRFn520ZFWaUZpZKXsc1DP8Kig5LgRz8y5sori9do5szqy60E9S/O+HGfJIFEoD32mDErVwZrm8IitsIi7/JAoBUNiZpVTaem1bBhw0zXrl3thzpZ8v3oo48215EnQ9E4kPBodyJkIio3IUopBkm2N3t2x4laJt+gRG2ynx/2TLhzEohZiP3d9sodL2ybZcs6LqP2iTqO9Ivwaz+MPGjc/Wvgt8l//v/0kbp0LOWaueHebn/883PPK+zcQdD1Czpv3uLPOiu43SRjGHTubj/8vpKkkTGAQLDkt/RF/mPbNPoDoq6TOwZBx+LauMss4d+LMn5xnm2/7+xH6oGTTy5qc6JSPfj3irtevpOQMywlQVgfFIpaanTmzp1rli5damtjTZo0qVQDy61/tXDhQvv9tNNOq0WXFNUiqP6SuwyDm1Rtv/2K64KyoQbt57/RbTnWZhLZPfBAsv6X03bEMcH4yeOCksi5Wqug7L5Bie3c5Gi+1ssf96R9d4tqIoj8N2rRPnBccuWQ+wbhv3FjKY9OrHMvp+FjDObMMWa77YpCXMwS1Zi+3HpJ7v7SJueBduGSS4xZs6Z4z2zcaMyECca8/XZxW+7Nl15qT+JYSX/KXbOohJPXXmu6LlliuklyRvohY5M1ws41zrMdtm9a5qY4psS8mE0VrWu6mjVrVuT/I0aMsIRI0SCIO5n727pJ1UgZP3585c6hcsx33klOdILai1NhOagNSR4XlETOnXw5b79yd7nEdpVM3lG+IVJUk+rWQURE9oUUQMy6dDHmgAOM2X33joTSPQaEiWrm228f3W93fCG3kJz+/YvfgxLQJYWbpTcoOd0LLxSJDtqy555rJ1aMxcKFxX4MHWrMtGntWka/P37Zj7iZgIMQ5F/DPfLKK6YP/UEb4j9X1ZS2KIewsS/Xh7B9k9y7aZxHHsyVinyiUANce+21sbabO3duodbQ8PI6hOqmHNad2ljHPaekeUIkWd64ccUwWr7HQVTocJwEcG5+Eh+0u/vuxWUQvBD+yHGOG07sJ7CTc4tKJFguCWHckOe0ktzRPuPGJ+w+qeb+fv55mw/qll/+Mvh+9se6HikIyh0zaYLIsHs14/QPTT9H5wQbcxBeXhMfneXLl1sfnSjgo8N2igZBmN9BnNIFYbb5WsP3kfDPKczmH9cfyT1XtB7ss//+7aahoD74x8GMhWnH9ydy+xDmv4R2Ay2LhPm6EHMhy6D9JYQfTWxYRJfsE3QvBF1jdzuJzEGDwXm4dcZcn6AgPy5x0mU9yyC/HB8ylpiIykWguWPh+/fQf6KQwvxO3HOX80niM9K7t9l87rlmQ8+ewf/7Yx33OUwDvu+XaAzDng+5ruWe8zBNXJLnTKGot+nq7LPPNhMmTDBDhgwxbW1t1j/HBT4648aNMxdffHEtuqNIA3HDb32fkzwhKAeJX6PJNakkMWv5EGLx8MPG3H13e+HHqDwobhSWXyzS7UOE/1LJf8ZvG7OLFDetpBhlVA6WuPeMX8MoqGCmS8hcuE66cUwkSXzIgoqBun2KG+WURmRiuTGsZZ4Y/3zCosmSPh9Joq8Uirz76PC5//77zYoVK6zjsTglDx48uFbdUFSLpJN1nicr8ZHAv8QvJCj/y7ISwe4CDcDSpUV/EHxA3IrfYXlQ3Irr7OsWi3QFXJT/klRr9/113Mgzvwp5nHOL8nFyfZXcJHDi28JY8D9jLmHDaJCkrY9/vDhGtLPbbh2rzcsxcDr2nXT9bdzjxyUEYb5SQf5XSduKQ8hWrzZdZs0y3fr2zU+SRve6Ro1RpeQrbHtN9qdIC4UWh/roJEQcn4BalVaI49MQY/9IX5Y06u1E+afEbQ9/hyT+Ov469sOvhGVUn/DJCekX48s425piUan/Gc+gwozi2yL/u8UXw8Yq7BhRdZHiXM9KUG09rDjbn39+YdPAgcWSJnHv56z9dKptv9L5QH10mgIbc+Cjk6vMyA888IA56KCD6t0NhY+k0UhphnmWe1udO9e03XST6bPvvsUolaQI8w/wESfyRNorp84X/xS2c01KQW267QXt42/DvmhOMI+RdVb6EZSPJahPYWa0LZqG/g89ZNqefdaYrl3DE8AFaT9czZVodMKuadQ9Vs5kF/d6VoIws5Z7/DD4Ga3DMiWPHWsKmzaZf3bvbva54IJi6Hs5LU1UlF1YH4LKLYQdp1qtbKXzgYaLK1JCrojO4sWLlejkEUnNNmmaq8pNdlsEw6q+fU3/Stp3BXA5uEIhac6ROHmHXF8ZyIqErPvb+SYadxvx+SHnDan1ZdugfCxBffJNedKv1183bYTE77mnKRx3XHHbIFOVmMvKZfCVPEJBcPsVlMbANbkFjY1cT8Ljw0LBcS72cxrFrT3GcdmXccLJXn67JM4337n3C/274ori70MOKa6jLYIxfv5z64y825e+ZNoeecSYP/2pPd+Rfy7+C0hQDiEXYcSwnB8RS86H9mW8kpjLKp0P8mz2VjQUakJ0pkyZEmu7a665xpxF9IkiX0g64aRpWy93bIlSIbldJQjTrgTB15wE9SvuuQdtR1viK3P66cWcL37q/zBNjuuvI4IegQjkLb9cv4SMiJOpJLHbUvMIgrO8b1/T5+STTdett27fThLxSV/TfBN320LYMi5oql58sXieQp5cwSvXE7+mxx8v/u9fWzdxouQ0ijq26xfFeYvmizxQbANxefPNYqQaSQhlTKSP7v1CpBjn8NBDxvzjH0UtGwkLuWb057LLzLYkNFy3rkhYJepICCznJY7sbjkQ0WSFaXZ852/pj7sMu3b+eJW7xj4RquQ+UB8dRSMRnUKhYB2QcT5WNCDiTjhZOEXWYrKLS+R8U0/a/ZK0+YyhJLcLSv3va3J8weZqTtzIGNGEyHZh18sXiHw/6SSzef/9i4SS/S67rP1/v6/uOCW5J8olokOjcN99xd/bbttRC+drw8SpmfMnKaGvocIpnP/22KNoHiIM39eUsD+E5amnitsAtiOpIOtJpCjHwGkaDRLrSIS5eHGR5DAuFLVk/bhxxb6hvfngB4v/7b13sd0VK4zp1s32p+vw4WaPRx81bRxrwABj9tmnmH6AdtkXkifnKGkbOLacO6Utfv3rYh9//vN2zZI4gIvzd5D2jD6jZfKd82kXkkk2c7RhfsqIOPXTsnaaVijqSXQo/bBs2TKb/TgKF110US26o8gKjWpTj+t/UwvS5UZL7b57MPmKG+Zbzqcl7Hq5AhHId3IAUSCP2mKiQQvqq59HJu6bfzkzighbiMuuuxaJiUv6RBsm+Vs4NtoVsiD//e8dNVTg6KON+cUvipoTUl6I1scNKYeMkBJAwDZoVGiXcyY67MEHjTnwQGO++tX284B4QMTQgkBMaAPtkmiYyMVDZXA/Cu3KK00bJIIXxH32MW0Q309+skgm8YtCY8O5s5+QUTGNyXWCcKJdwhSGBkbC4qMi5aTfkmuIcRTNEe1DjBgv2uccaJP+h/mU8Z+f36dR5wdFw6MmRKdv375Wo1MO5NmpBoMGDbI1tRR1QrPY1PMwIUeRqrDw3qBxjwpDD9svaP0W7cyHf/UrY973vuAEkFF+LWH3hG8ORMiLNsG/DpLE0IVLpEQb5h8zzDkaoPV44okieQraT8pbCNCyuM7U4p/j+vq45kO0P/RRNDq0J2ZFOT8hWJxzoWA2v/aaWfXyy6bPT39qujCGJG2kBuBHP8pk2m6SdMPug8Y5yPHbv6eCzLFyTn66AdeHi3EAYfmbQhytO/VRoagFCk2CcePG2TCzpNDw8sZH6mNdy/D4BuoLYeVv9uhR2BxV/iBpKLJ/fuXCx8vtn9fxTVCyoqZzR5ISG1HXJ2nZhxxA5+jaoGnDyynngHZmR5wCy+C1116LtV0UMIvdJ7Z7RfZodlt73AKltTj3LLLrVgKO+/rr5p+HHmr2+tCHTNewt3L/rb1cf6Oi0eKYCqs1J9bK4TVIS5gHZ9ukyfrCro9o1vwq9q0+lyhygdRrXT399NNm3rx5ZU1V69evN4ceeqjNjNy1a1fzw7hp1QNw9dVXmzFjxlS8vyIhWrkGTa3PXcwjflRMrceefEV33mne7tnTbJ4xI1wo+TWukvY3L3XQsr6OjYqw6yPnxzye5DxbeS5R1AxbZeGPA+kgHw7aGghPUG6csVsehLVr15qddtrJjB492hb+POqooxIdb8aMGTZ8fc6cOamdg6IMWtnWnuW5xyldUK+xrzRfUSvfKy7yoL2p1flF5UjyofeHogbIxHRFHauvfOUrHcjHpEmTzIUXXtghZw4JAiE5YP78+XafJEQHk1W/fv06FQmNwttvv20/AsgYeOedd+wnLUhbabaZG+CMes45xe85OL+ajnWG507mYbI8QyjIDVTr40fife8z70yebDYsWpRsnHN2rzQCmnruyNH90VLjXEdkOc5x28yE6FCNfPny5baIJ0QErQ1EZubMmTYhIOYtqpgfIllBt4Btk5qspk+fnmifqVOnmu9hT/awcOFCs91225m0sWjRotTbVDTnWFPIkVIWaE0qToBYAzT6ODcKdJxrAx3nxh3nN0mjUC+iA8mBOLgYOXKkmUySLge+EzLkJ6nJKinY5wwJz9yi0dlzzz3NsGHDqnaK9pkmF3bo0KFma7LIKjJDU431ySdXVsqiBmiqcc4xdJxrAx3nxh9nscjUhegMIJtnAITIoPGpBpWYrATbbrut/fjgAmRxs2fVrqIzdKxrAx3n2kDHuTbQca4N/vWvf5n3YapMEXGvW+pRV+Cee+4xt3v1Y3A0FoKDD08QniLVekyTFRoiRZ2B8yxmwKAijgqFQqFoShSCStOU2TaufM8CmWh0pk2bZv1vCCFH80LkFdoXIqvIsYNT8uDBg0s+O4DvqLbKASdmNDqUlXAheXRkPb47lWh8FAlAKCmFBt3iigqFQqFoWjz66KPmpZdeMp/+9Kc7/bd582ZLaHbeeedSbctnn33WLrfZZhvTVEQHcoPD8ezZsy3JmThxoiU5RFjddtttZsGCBTYMfcKECTaXDmBQbiUdexmgyQnS5kg9LY6pqBHEpyqBb5VCoVAoGsPUtO2225qttupIE15++WXrd/Pwww+bD3zgAx3MRxCgv/3tb+b973+/jaCmDbbDbaXpiA6A1EBwfKDJERCVBfHx1ytyCj/PC07dbr0dhUKhUDQF/va3v9kAHawzkpJF/FshOmhqUFBAatDkdOnSxbqnYMl573vfa+68806r0Hj11VethqeeflA1KeoZhbQITpjfjyLDNPZupW18dTSNu0KhUDQU3n33XatxoUKB61ezYcMGS17AXXfdZTZt2mRLO7Hk88Ybb5gnn3zSvP7662blypXmPe95j22rW7duNhoKYgMZkhDwemp0MnFGFuCPs88++9gB5MP3Sy+9NNVjkJRw1KhR1ndHKpj7/juKlACROeKI9urSAk3jrlAoFA2Jv/zlL5bIuICwQHQgPGhvIDXkw8M9hP8gOmhuWP/888+b5557zn5/6623zA477GA1O+zPNpIUWEhTU2l08Mkh8zEMULQ2aF0o/YCPzi233JLKccaNG2c/ihoAbQ25hiA1mKwk5bumcVcoFIqaAPKAlmT33XevuI0NGzZYedy7d2+zcePGThmGZR2EBhMUvjZ8x9+GIB++Y8564YUXrPmK7SE3aHXQ3Oy3335WmwO5qacmJ1OiM3fuXOuQHGZOwgn5kksuMaeddloWh1dkiSBS0+x1fBQKhSIngGxgLtpll106mJvi4o033rBRypCTXXfd1frXsA55LZFSr7zyitXcQHbQ0vABLFkHoeEDAeI3bdEGS3Ll4MsDGaPaQFDeulqjS1aZkQkxDwNOyBIOrmgwNGt1aYVCoWgAQDAgJTj5AiKb//jHP5q///3v5oknnihtB/EgQkrA9mhi8KuBhPA/WhjW8R/Ox3yH4DzzzDPWVAWhQoOE9gYSwwdyw280Nfvvv7/Za6+9LOmCMEn/0ORQcYDjJKl40FAanV69epXdpn//vCa6VygUCoWifoBIYPqBLPgaEbQ4EJ1HHnnE7L333paUCPngP8gLaVvIZwMJ+uAHP2jNTQ899JA1VUFqcBbGfEVyXzQyEBMIDb/ZH80NmhmICs7FEJl//vOfZrfddrM+N6SP2X777e3xWPKhbRc4I3OMPGSdzoToxGFwGiWlUCgUilYDxIJ8M4Rlu0Cbcu+995o99tjDylCsHiwhHDj4ooGBYEBC2BayApmBbIiZCK0KmhhxJmabJ554wmpZOCakCcdhnIxFUwNxwWQFwfnHP/5h+0J7uJ9g2vKVE7SNZqdHjx6R50loOvvQr7g1qRrKdMUgEnEVBvxzkqSQVuQYWgZCoVAoYuPxxx+3ZiYIA1i1apV58cUXLfHA7eOxxx6zRAPCgkIA8gM54YOGhu0A5EH8YsS0RJvse/fdd1tCxPpXX33Vkhg+oskRnxvMT2xDUkCxxECWiJCGHAWBbQ866CBLvsqBfDp5QCYanbPPPtsmGSJLMaHf4uDERaJOFQOOnVDRhLl1FAqFQtEBaFPQnKBRgWRgaoJ0QDQgMpCMPn36WOKCFoUlBASyA3GBCLGOJRof9pNcNSgNcB4WB2U0RpiZ0KQIAXrzzTctMYEsYaZiH6K2+A6Z4j/ktMjqZkNm4eWo3chn44d+U76BqCxFg2VD/uxni4RGoq0kQ7KGlisUiiYGGhZMRTjeVgJIBf4xkIgDDzywlG/mgQceMB/+8Iftb/xgID9oWyAlkBNIDNobtkUrA8nhO4SGtiApbMs+9A2yA8HBH4ftIFWQpp133tn2n/YkjFxCviFSkvU4K6DwwI/ojDPOsD5FTZcZmRPkc//991vWiJZHkgcpGkxjc8cdxUSBAleLo5ochULRhMCMgyUCkpCU6GCSYn+cdCExmHGQg+SekczDruaGY0BexPyEhgfCwn/44bAtzsBEUuHfA9kREsb/kBr8YiA8EgYOgeq6JWEv8HPaSE6ccv421YAkg1hw6umnU5MSEAcffHCndUuWLLFFvxQ5h2hqfI2O+59CoVA0CaRkgZh+IA0QEz44B6NtgRyIDwt+NZAMtCmQFQiK+OIAtDHiQIwJC40M+0J0ICXsw3H4TfQS23EMSAq/+Q+S8KEPfci2h4ZGiAvHcskL38VZmPOAGEWB86G9NCHjBG6++eaSm0q5vjRlrSs0PUp0GgBuMsCBA9vXqxZHoVA0KBDGmI5cEMG0evXqUrj1pz/96VK5A8kUzPo77rjD7j9s2DBLQAjzRnsDmYG0oFURcgMhoUSCJNSTvDWSh4YQcvxj0NrQlhAdjitkBp8cF241cd/Zl304FsDsRY6bNEGblHHiPAhb/8IXvtDh/z/96U/mxz/+sTn66KOt68pFF11U+q+aTM51JzrE6ycFg4Q6UKFQKBSKWgOigTYFEFL9gQ98wBamRKsCWZDcL0J0IDZoaFiPvwmEhCR9kAo0NLSHmQotDLloIDWYq9zjIfPQdFDRG1KFDw1+N5jEIEWQCELJ0fpAqipNtCdEJ4tcdRdffLG59dZbS6Tm8MMPt7l+IGlots477zz737x588yjjz7ayUzWsESHk8P3hpj7uOCm0Tw6CoVCoagVIB58MOmgCeG7VNiGaKB5wYcUYgPJWLp0qTUxiYYFwc3/aGIk/BvNDcSCdbQl2YHRDEGGJLIKokP9JzF5YerC14Z+oCUSnxuIEmRLQs8rASYijh0WHu6C43D+OAm7xIpzx+z0rW99yzz44IPmhz/8ofnUpz5lFi1a1GH/L33pS6WxDCpV4aKeGZKrJjoQnIULFybej5tEoVAoFIpagEhgtC+QE7QqCGe0DGhS0KBARhD8kBW0Omh4CPuGnPCBgLA/5iBe8NG84N+C6QltD9vQDoQH4iB5ZrBgoL1xiQdh4Gwn20iGYSBVwysFWqEorFy50p43n+uvv9784he/MKeeeqo5+eSTS9ucddZZJV9awW9/+9vA9oJIjgscnc8991zT0AkDqUReCaZPn17toRW1hCYGVCgUOQckRpyJRQgTmQRxQGuDkJfMwZAW2QbtCtFRklEY0xOaDnFClqR8JNKTkgxsCxFCYyOERcK9XQdhCEWQdgUC4PrbCDjGvvvuG/uc0RoFESP8hjCzueCcvvzlL5vjjz/eamcgOQC/G5ypxSRVDdACuaB4dxKLTy41OjDjWu6nqBM0MaBCocg5MLlAMjCzYIqC2OCLQ6I8CAjaDggLWhw0MIDffHcjlsTPRfLOQGjcSuGYoVxIfhiOiVuGX94hCcqZnCBmkLTbbrvNDBgwwEyZMsUMHz7cnH766aVt8P055ZRTLAG75pprSsTLJSEXXnhhh3ZxLBbTWTU44ogjbH4gCA6oZiwaPupK0WDQxIAKhaLGgIAQHUWED+HeAC0Ffiiu1gSthhS2ZJ/bb7/dEg5Ig5irMA0h+NHsYE6S3DEId3xm0K6gyRFyI9FQ+NC4NZ+AS3pcoBWCTLFPpeA8vvrVr1oHaUiM6/OC78+0adM67XPttddaH6JvfvObloSJLw3n/vLLL5vf/e535q9//Wup4nkYkpCc//3f/7UOz5jwIFCM1Sc+8YlOufLqGW0lUKKjSB5mrlAoGhqQBbQUealF5AKCAlGQDL/itIvgR9NClBTEhnVsA2HB/0aS5EFi0NignYHosE4yA4tPDRoe8tJgaiJqSEiTmFgQ+JLgL4lGAodbPymfD5x78dHxCcD//d//WZ8ZtDRcHz6MA+YmQrW//vWvR7bLuEyYMMEMHTq0g9PwyY7vTRg4JpFgAs6delZkcv7Yxz5mx+4vf/mLOe644yzhgkB95CMfKeXyobalmz8HskP5J8Yd4lfvop5KdBQKhaKFQDVrqmBDdIiYhSAgVPENqUQTIaHVYSYXNBT4taAxcYWhAKGJIEWzAsikTz8++tGP2nbZH60BpAaNBr8xRyFwIQsQIPrAf2h9IC+4RiCsITkQHpyF0dZI8UrIkfRDQsmBkBRZlnPsjQP6Q/8xb9EPtC6cH0E8fGdMJk6caC677LKS+U1wyy232GU5kuPCj4yKg6997WtWC4ZGBuKHxso/d8o3Aa5LEPzrilYK5KGAtxIdhUKhaBFAakhwh/BHkInTLdW0IQZ+crpy4I2dyByIweDBgwO3wWSC4ESI/u1vf7PHhZwAiMif//xnSz4gWmTRRWsDwaHYpeSYgQyhsaC/EAdJygf5QUMiBIj9iIoS0gWJ4cPxXLOMFLasBSAxmJVw/OWcAP0kiolrAS655JLM+7HTTjvZcWM8/Dx2aJi+8Y1vmGZF1VFXcYBDmKKBoBFWCkUgEJY4ekq+lLxDooYEmGIw7aBhYAnxgCTwHRLh71sunwsRTdImjrgs2UfaQnuE2QKyAuFhG8xGmEEgNJAcCAtt0CfaY3/2EadhfiOY2Z5tIVdopCRyilBvtEFocThOkOmI/ytJWAeJQkNSDSmSxHnkpWEMXB8XQZxIJ4igQLRfghNPPDFwH4iN4JxzzjGXX365JVX47LiOye52zYiaaHSwGUq9C0XOAbk56STiNIu/1S9H0UJAoCFwecMNSnBGyC5v4USWuDWCID4IcTQiUYnRCOFFUIvza1ReEtqEMCDgSSbng//RbuBkyzaYfNCM4Gcila0RrByLDyQB8iAEhr6gxeENX3LESLucA2SCD6UQXJMW50nbEAcICCQFkxHjQls45LIep1jmfcgPwNeF84GIsA6SA6FBq8OxIUD8xoeGMaAPkAT6ylgLGUPIS3FL+kG74gCLX0ma+N73vmedbDnHMWPG2LGhEjnnJo7OEEX6IHlwBPTtBz/4Qek354fmLC7cRHyY2ubMmWOmTp1qTXZ8h3Dfeeed5j/+4z/s/UH/+O5i/vz5tn8QSKliwLjS18997nNWu8b9KI7ezYqaEJ1ynt6KnIWRc7169dIIqwYDVZGZsPyoh0YFAk4EbJTvCNshkHmjl0KJjIMQDyZzhCT/SfQMAotU/ThUSg4U2uA4+FFQiFh8FNgW8gOJQHgh9CTLLgIDIcQbOSRCUvvzGTRoUKmytCSTo5Iz/0EA8I+Roo0IIwgI/RYNAP2ljxyf2kEAQoPAlAR2XPN/+7d/s4QGEgARwxQlVbARxOzPduwHQYAoQEgYJz6MEX1jG+ZqTET0g/YhEwhJSA3ny72F468QHTQuCH3GB8ELIeE4fIRssQ3CVX4DSIIUuOS8IRMibGmHvrOPRD1BCqU0AtszbvQNDU7cqB62p39BRJQ2GUPOCb+Yk046yV5XSWyLkzBE4ic/+YnVhkASDjjgABsBJVqvT37yk3Y/osQgIj782loC8StygT/Pd77zHUtqGD+cgIEbhcUYuGUefK0Mjsnca3379g1N53LYYYeZVkBNiE49Uz8rqggjJ9JKURXk7TjtZwCBhrBA8wAQlvJGfeSRR9p1TNJM1kzECAjxW5CU9e4kj0Al8gJhXg8guBH+CF2JBOJtFSHHh4mf/gv5QCAj/DhHNBOQGj6ucyzCA+H98Y9/3JogRJvBuaN1oA32hegwPgh4jgEpQriTtI1jMK4QAoQ8pAUCANnheGyPFoFjQTT4zTHQTNDOXXfdZf1D2B6BxQfBRh8gVJAhhBn94D+uJ4QLQoZg57gQExxF2QeywXH40B+Oe/fdd9t9JdqIc+GcGDd5yYRIMcaMLe1xX0AQ6KsklcPFgP6zD0ITIcnx6aeQEe4RzoV7SkgA/aLfjBnjQx+4xyAsgJwqrGdMIBoQMf6XRHw8GxAw+sF1pn+sR5BzbK4b9yXr+fAboMVgrFxn4jBQiBPtDMnyKFvAtRPyx7miaSHfjODGG2+0REHAufz7v/97yc+H//m4wBzHJwkgqRAkP2ScaweJqbReFcQIYqYoQp2RFS0XRo4QRIgyAUdFVTCZ8/Ht4QJ5Ww8DkzUTn0SGuGCSZ7Jlgpf8Hbzdxn075a2ffqF5QOAgpHi7Fc0HAgrhjhBmMuc3zqIIGfwmML2I6QQBiSCUZGH0yT8vhIuvVRG/DAS3ZJVFeCAMAYKadsLIk2So5RrQR6JN2J9+IPAQ4lKNGSHJ8dkWwQoxYMl6roOrEWAsEcby9s92bEN/ZT/aRCAzBvzHPrQl5Akhj+DmXmE958J2rKdPaG7EtISQhBy4zq4cWxLWsb2QFNZznWgTUoF2BCFKX6RukowXviesg9CI3wv/S6g0/9EHrh3/ca6EA0OcOJ448TKOECf2oU+MrRBIwJhKCDUEWkC/hSQD9kcrwhjRBn2R+4Tjca/xP+HG/IY4ugUyxUdGCmjK9YPoQFpc85wQce4lzpe+iuZN2mNcypmqcJTmfpZM/L/61a/MZz7zmVgh17Nmzerwu9pEevjRCKmiICjP7re//W17PowDxJooLCA5fpKC/dE4kSwwL3j11VftOYaZamsBJTqKpgTaASZQEbouJPspQjWK6Mib/FFHHWXbQ6DwhkX4JWQBocEbKipsFwgYhDbkgOMgXH2ig9BDICGg+I9jIfB4w0foBGmA6AuTBkRAiBFkRsJmxRGT44qGgeMwiYqGgXNAkPOfmCMgBZIvhH5jipDcIrSL8MIvgb7J+TFxoYoXZ1FxJuV8iXphX/5H+DJ+CAmOz0TPmzsmI46FoMaHDwLGcSArnB9jQ98QcKKBYnyE8HBMBCPH5VwQqJwXx2Nc2AbnTc4Xocq2tC/nxVgKgYFQiN8K58aHayY+OJwjBJR2+Y92IQQi6LlW9EMcVkUwc3+wDVoHhL8UaxTyRJsQJsaFNlgvpiX+5z/uN74LQeN+dkkox+Vai4aEdhCYHJu+QgTckG7a9sPAXVMn7bM9JA9SxzHpE+AY9BVSS3tSCsGF+zxF5Z+RTMJognxHX1fjiPmGc8GBlnW8ODCemIj8Z4RnlJDt//zP/7Tbcg4XXHBB6bwFI0aMMJXCzxzMs8t1ROPmgmgxnlXuWbbhPGQcuc7cS+64k3NGyBXnOm7cuIr6h4+O76dTa8hzJMSUZ40xCnthrAWU6Cg6OiLjo+OarYLWNQAQRGFEB0EkgiEK4o8BCUHQ8ADzlsr+CE+pf8Okig1cJn6EKxoX3swReAgWhDATG9uLGp+JkMkA7RLCGuIFoUDYsw1qewQCKnyOi5BhAkEAcwzOj+/ieyCZYXHy5Nxok/3YjokV8xTgnCAZCCzaAaLR4Dw5PmSENjElcf4cA2dXgC8Dwp5tJUEb+0AaGAP6zUTP+NAnhADbcQwEG2PBxMfxOE/eulkHGZFCifRZ/mdflmTH5XwgWbTNMREaHItj0ga/uT5o69iO/nMtaINrJA6jQkzon5hsaJNxggAyKTNBiw8NfWOspEq1VHsWR1qOhwBEM8Vv+gtJRLixP+MHRMskZiHGkH4xNlwPMX0BSBm/+ciY+Fo10YSIEAW0LaYP4BKCOBWt5blhTF2/DzFRxUWQA7UPxohxEIJ06623mhkzZpjzzjvPHH744aUoJQg9zrQQBgB5wMdJAKEQcoDGhN+0m5Y2xo2UGrvFvM8YX3zxxfb68rIDYf79739v//vxj38cqu1lvzA/Ol4yLrroIpN3vPnmm/blhHtWCI0AR3TmSu4VeU6BEh1FfutZNVCNKx4qJjQEEQIlzC9GNDou0RG/B1T88gbMRIUglDczHlRRySO4mLBYx5skkyrbI2j5iCMngoLjMWEjrNiO/aRaMkJRzD9MGBLqy0SCgGZ7+gJxQygwQbIOwcY58J1j0R59dU01/Eb40y6kQRw8OT7kxS0GyJJz5LjsI3WAEMT0keOIhgOyhUZLTCNiJpExZwKkv/RLtD/iP4N2hN845fIdQA5EEyECCoIhkTdMpoDxRTMidYjYXyKF2Jft+Y/zFfMGS7RH9MWNiqEd9mdShhhIX9iOaybmO9bLeYvPDpAl28gEjv8L2yCUAfcBJgiEOBoqSIaQbIgEfYek0UaQ4HNJRpSJ1O0PYMzCnE+5JzGXDRs2LLJNxgQyUc7cwLXjeuMHFfS8MRYQXfxd0FCRFO+///u/S/2bO3euueqqq8z3v/99668ivirnn3++ueGGG0rtoOlwicvZZ59t61mxHetPOOGE0n/izJ0EmJDcCKkgDBkyxF63H/3oRzb6iT7IWH3+85+3zwREh/ul3PVqRGzYsKH0IsK5klmauY9nSV7MuK5y3/PsMMcJiS2XMTpLtBVqkDWJN9u8Rl4x2TPJcFHSzCXApE/ehGOPPTaWs1wu0KAaHRlrESQIHCZ0JiCEJOp71kMi0CQgEHlzhNRgjuG6oxJHwEvaed5GuWdRk0u4LOtoU5ww5SGmPdpFIwOZQNuBRoR7CuGK0IQw8BwgGGiDSQPCwVsP/eI7Apm3UcKDmTggVNyb3KNoMzguQpLzFCLGxCNaHsYBLQDtCYkRsxjt8IFEsQ3HQ/CIDwz9kVwjED7alPT5/M9/nAsfcbqVsF+WEBTRZEhEDEKS40ipAdF4SXiyhOcyXuLHAsSkJOn4wyKuuDacUxzNQTmIPxb95npV88yKGQyyhxCQtjDlcd24zlGCUJyZuS/TdmLHd0P8cOSZ4Z5jDP16TuVAP7/4xS/a60mJApdsCAhN94GA/H//7//Ze0b2gUDwDLn5ZIhwEp+VMFA2AcLB/RKntMGVV15pTj31VHtdeL6EbKH9wsQK8J2h7IH46GD+4r7AxOqHkPvAXMYz7aYeyBJRfoIy5/Xu3buTuZP5SUi2mE45N541McWyZB7gO88Z8yH3C+sgMowh8yL3gVRsZ4l2i23kJVD87bKQhXHlt2p0FNGOyKyD5OSM7PBwQTR4mISr8zDxcPOA8lAy2UhEieTCQJCL6QNiwhsnIZY8KAhOJkYJe+XNRJKU8abOm6tEfDApILx5sCWsF9LDfpADHnqEB+0iCBB8fJf6OpAA+sODii8D2zLJYGphYmZCoS+8raLOltT1TCwcjzcnjsHDjQDl/CBDnDvtiSaINjmm+JK4SdPEeZn2OQ/aoD0xp3B+jIHrzCtjyW+J7OF/OW+uh5ihIAy85XG+TIwyyTFB0m7YBE0f4rx0hGktKgHjywcSWC0YZ87VN5tyHbIEwpj7JkwYc/+5zsYIHq6FrPvNb35T0p4Brjf3vhv5w/OCWekrX/mK3Vc0dbNnzzZXXHGFmTx5sjXFop3heQkjAxAdN8qJe94lJKAcyQH44wSBZ4FMxICMv5iEAWTq6quvtvcs1b+ZAzg/l1DiL8PzTv0miBomtLjI+hq7gMRwfXghEPOqfz+4EXqAeYg5UV5YWM914lmUlx60yxKEIYRbfOIkIo5xlJcY7jnuLZ5pMZkydzC/SMCFn4m51lCi04pIqqXJofmKhxWbOKGZ8haIQJVcHeJfI/Zwcc5EiPMgSqQNAgkHRklUxoTBennLkcgTHmbIAA8zAoyJAoLFBIpw4BhoLDgGbYh/BuuYKBD4aH5oT2zaTBysh9yI0KcdKZbH8XHsFXAuQT5HEBUheL5TKQgzPwjhkDT50q+gSBb6R38ZJ0gL4+OaW8SBmnMVjQ/7iA+R+yYn41pP0CfImWiN4oJ8KpDI0047rTTejCFZZ7kn8CHh/JnoJXTarZ8EGUCr8LOf/cxeI+4p9uXtmtBn+kVEDvWEGENyuiC0IdF+Zl/ub9GU/frXvza//OUv7dsz5h/Gm0gjBNCZZ55p/vCHP5TCvV24xAeC8tnPfta2yfNF/SPGiLDsBQsW2HuRcHnuAYlicsH9fe6558aqt+SSnCyAKcklH0J0gNznhIu7xSYhX7zkSG4ZCFG9IOH5bgJK7jPmInnx4IWC5wutCc+4S3REK8s9U3CMNuIryL3FNRafM0kyyTHFAoNmimPyW+YQthFHep55XrLQfuG/J7mAGF+OwXHZt5wWrBZQ01Urmq4o7wBx+exng4mLT4RyaL7CHIMGBoGAYGCyx6mUe41JAPIhobc81BAciAfXW0xHkm2VyZyHUXKXcL1cgiFwBbjAL1LIcZhgfJMK6+hXHh76SiEmFc6B5xnhW860wj6cd61CSyVzLhM2E7WE7kIuSLonWiAxqSDM2A4/ERy0eW4RDvh+yLnhxM11577BRCPmDiGd+HYsXrzYfsdUiEmEEGby23AP4LDKGCBUXFMOGgPIBSYawPwjghfyysfN1YJmgvsLcsL9ee2115Z8qdIE552HQowCnI4Z63nz5tnfXFOeVczAAC0cJjnGET+agQMH2hcguX48e5i4GHvGtBYmwiRwo8wgItyD4lMHcUXjItmkubcZC7RiaF64V/mf+UZemNgP8sO9wf4rVqywpESycnOPMia0xz3N9pjt2I7jQlwg0ZKcEv8rnnnmTP7n2YI8us7FtMsLAO3yAiVRhPSNa4WrQD1NV0p0WpHolCMu5YhQHSEPMQ8bDy72YN4mxJTEg4Ww4w1ZHkAmBYQyRAfiwwPJNeFN2SUqPJi0yYNZqcZBnIDF3t1MyFowiF8QwG8EMksocNg4ov3grZQ095ARrjkkQ/K+APqKhgpCAS688EJ7HAk7xqmUidz3JWGy557h/mIfQFFKNBqAfDXHH3+8/X/48OGR54UZhHtWfKRcuKajWgG/NLdCdjWAEKKVhCiGAWdkxpznFKdfHwhMnmvRTHIN0YxBQMl7gykJLQv/kSMGIoNz98yZMzv4GiVFLYkO5y/RcJwH8gYSzEsWL2yiWeRFSyLEIDG8IEhmac7RzSElPoNiNhfTpSQJhTRxf724JU8T9yHtQFIYY8gM8xx9wjzHsYTEAMmsXWlOn1rIwlwRHd8hLE9oSaJTDjnR4IgZSFT2PHhob1jyUOL5zxsLD7hU5kVFDVFxw215M+EayJsqv4NygDQK6D+RJVLeQIQ9CclcH4u4ENt6UsGAOVByw7hvynEB4ZRJFJMOETkIMUwvRAUJICVMxBIOjtmHfkBqJTy+UuBMSx9os9lBkkgIOMnyMGdh3hE/lihQ7sDVLKEJRRj+13/9lxWkAqKkmPMgPzynlEE4/fTTS3lrEPCYwXiu0TBgouUZhjDyPNI3eU7LASFNLh3uO9GI5ZXocBxIO+eHRhHNMy9jaKIYC4kU5Tlk7pLUGGIiFrnEPMhzyj3P9hAdicgUDbRk02ZcxPT1zjvv2HEmYSjXjTbQ1FDQVaIGIe5xk5UmRcsQnTxDiU5+QRgsJAZ1NGMo0VLyFoIjoXznoa+3CrpWEEECyB3i1tVBcKGpgjgwNl/4whdK//Go8+bN2yNaDBEY+Jvgt0TpCMYYwePes+IcDYkSwcBbPA6pAkKGuV4IHzQrtEvafa4H2gMEK/shMJns+R8C89WvftW2K/lRwiD1opodOPNiZuHeRihB8OT6UroAswMaKnwjeDbI1yJAO4VPj9wbXBP82PCXQSuFmdcH29M+5JL7g2uBSQ3SKaUEzjrrLCuEf/rTn9rjopVBOxAF0Y4iPLN6JqWcRtz5Ve4f0dbGJTpS5yxMy0s7kA3OVV6gJKO1pCjgONzzPBto9+i3JPoUMxzzGM8uGh5IEVobvpOjiWOgUYSUkHcKEsTLHEueO+4LNGDMj4w7xIdzIqLx2WeftRowiI7r44fflpArNJNZhX8r0ckBlOjkF5gjEKiMIRMNEwTrmCCkXhCTPQ8/mo28ER0mSDRMmEX8SZLJCG2V+0bs35f4fTC5udopJsuozK6QCBKOjRw5smSCYSIk54ibvfWmm26yqm1MOn4BQt406a8ULMT/gQkZvwcmcH6HRcTgiEhCNXKNhMEtlig+GPQxLXB8fGiCgCCSyLm4QEAQoQMQRggI7j1Im0s0KgXkAsEEyWEuQrhBTiTDr6RFCNK6kY8Irab4g3G9uKa8zY8ePbqUONJ3ZI6CZLMGEOVKs/SmBdH8VevAjgmbeRntRTmiw3aS7wqyKCQEiP8MYw55kugi7i2pSo8GBVO6FC9lPdoZCVRgvpLoT66N1ClDo4n2h7a59jzvvJhwbHGiRgPEscKyp3P9OR7PK1ixYoW9T/jtam0gQJimso4UywPR0agrRW7BAyKJ9ZiUUPmKsygTOW+VvPkmzXqK2Ye2pCJwJeDNFj8StCC+yhenSdT4EuWCoHGjQHiLwqmVhxQNC5MmkWMQDoQKE5KEzeKTwJs8YwAZQOMSBYSkkByAehr4KeoxX7hkw4WEBbt5UeijCPuosF8mziiSA/zjVkNyyHlCsjnS5gO0UwgYxh4BRCSI1BvDxCGVzBlrtBkAJ2WIBdfFBRor2kKrgsCC4BBtJG++xxxzjBViCCfIBn4Pvg/K5ZdfbvelLYQQ+6KxkaKV9957rw3FluyxgLYoyMi2ki4gDBzbBUJUSIogCckBHBMtDtGItSgMyVhIhXKAKZY+QLilMCv3H4Sfa8TLAxpIPyNvENhPIoikVlkUJLO2ZEDnxQEByn0N6ZB6X8xD/M8Li0QkysuLRFpyXLaRiEzIh4R0c75cc+YwrjP+S5wP58zLHfcGvlTMU7wMuecalWGYF0IpyCrYfffdbVvuCxNII5VCoyBTjQ4qUNdRz/+dB6hGJwLLlhlz+unGUMvpvPNq7q+D8OFthMmACYe3EiYP1LHiV8LEIkQorkZHHE8RyAjKsAkScsAEyfHEf4S37//5n/+x2iXAmyb3tYBJyq16DNgf3wTaov9sQy6SMECK3KywrQAxxwQBcoIWC2IKSWEy57kSHxt8RZKC64tWC2FDIjghlQhRiaByySHbM1eUS06IWQFyKX4WP//5z0tJ2ciaC6mKqq+Wp2igtAA5lzBmNB9irgFSV4t14ueFmYX1mFMgBhAIyCKEj2edOQFh7+dRYk5gvNwxgyQxllLuhGuB+UbqlEkBWIgExwH0lfaldAoEAcLCd84F7QrnQV9ol+05tmhuMPVCTqSGHM8/7bGtVGLnZQKiIWSD+wtwHDQyjEVQ5GccuGkH8oB3cqDRyZTocIFFIABqlfAGkyco0QkBTp6oPgnh5A3irLNqkjgQ7Qxv+EwMTCa83SFcmCSYiHhT9/O8JBUMQnTIE+ITb3kcIFn4PMQBhMvXBuQVqMGZrINyqoSBsGa0EH7EEOSD60SiuSTAHMd1Qtjwxo7PEQ6ukEmimmTOQGPC8yMRdC7YBg0TZrS0a+hARJkT/DfgWiFroiMpFioVhGjKEMyQA4lqlKSXQZBaY9x7+KJw3XmGJdeVJM+UKEjGnyUmFe45qcOGlkNqn4n5UYqcsj3HEZMS66S6O4QITac48/JyAtEQwsX5oGVEk8acI1nEAeeG9kjmBfbn5QgtIeNHNBjzO+fCtYKE0TZaFCn3wQsO5+Zq7aLA+TWkzGhV05XPoVrcHaixoqtYjwBhssfEIyQn48SBqPfFXi2JsSRnCw8MjnnlwIRH7hIcXX37sxt6LM6JTIa8+SHYyE3CvkmQBslhAsCEgUZAIFFimCIwk9FHAcnhML9I0UPABMxkjYkFwkjyNnwFcAZGIGCGkKrRbrbYqCrNOBejYcJEh5bCNVuhYUGI+ESHSR2SSAI2SRyH4zHqc84zLKcOpIUP1w+hFGWy4SWKTxaoJIIsCWQeFBLDfSiJGKtFOSHJsSVTdxCBdEsKsC3+KbxkcM3QWHBNuKc4htQjY52YcyTDLtvzP1oUBBAaBkiOaD8AhEASVUoCO+45uT/oC23yH/szJ0j5AckpI8kZRSuE0JMM3xAUtqN9KYrKh766KSQgIlLIVaKQcNymP5KvRsxrmJU5Hh+2lSKncu1om7bwjZNw8qRoJpKTF2RKdPy3kWZQwzYVfOLiEp8tFXo7kCB3XUZgYpDU5UweRBNAdJiwmFTDhCSTJ9uhFiakFUyZMsX89re/LW1Dm7yJuRFKOOlCbIhU4Y2zFqnKIQiQAckDgukEEwwTI0nmmMwR4hAF3lwRGAgmnEuZxPkP1TjmMIghZq7/+I//sAKJZ+zrX/966Vi+v4YAv5ZLL73UtsUYEFGD0y3mG4QE2XqlMjtg8vbfmETjQT+I6qFNN7KH/kJ0IDhJ0ujHIbN5A0KZ+xbBJ8KNe5LrxT3pgjIKaB3ENAHxQIgjkLm/pVCpAOGPzwikPSgyBm0CwhmtCGQYohYWQQPZ4Ng8TwhyhLhUgWcfCDXmFK43fReywz0o1egR8mzL/cF9KXWQ6Df3LucBQZG8SGg3aE+K3bIPGhYhCiwhS/ijQJzFsRfNDu1A0kX7Iv9JhnG3hp1ofaSMAaZmyBTjTzvy8kRfMItxbpjDuQ7iP8P2tME2MlaS64jrKgk/w5JliplKTF+KfECdkVsZPnHxiU9Q3asMEwgyYTMhSTZdeVsEQmLCJg80HPhAuHlkmPiYpNFekE+CidOH63CbhOSUyx6LBoTwahfkhsEJGEEiuTUARQlFOKLiZcIVnwZ5u2Oih5ggTERAsg3ni+YqKRBOZ5xxRum3+AxJpAbwTRucM5FY+CShfZIkbRAlPj4QUGh70ii6mTYQtow/glXMFNwv8qYeBSEl7ts69yfEgOuEkJW6a6yXHDEiiBk3SImQIiGzkhVZHFZ5FrjeCF/6BQkRzQRL2gAQLI4JsZACshwTgc82QoB5nqSECX2gbxJVJHXNOC+OSR84T/ZlSVuiSWFfyRAOIeA7x4csQFZ41iA0EkwA8YIAQMLQkKAZggiwZD8pHUL/XYddCIZkNueFh77g/8T/aCbpL2PGMcRRmXGkHZ4NxlcCBSAqrvaIPopjP/MK63km2Y+xAJwD9y5zEMTGvS9wwwgC55O1RlCRHEp0FO2ogcYmDEyk+GcgKJj4UDszifFdBEKUE6eYSPwEckThgCCSExccl+RmOKfiTIrGhAkRLRDREoTgMsFjCiJxH0A7wgRKZA+aJd4u3bc8lpMmTQo8XliZCARNGuaNaoDAgezEfVutJIFhNX4tIoBFKImDKj5JCDYpUIkQQygh1BGqkBLxH0HoIUgljT0fNAkQTEgJ27EvwlVqoCHEEaqSD0XMKNwDEBHWS90g9pXIHskPhDBF8EvuE/rFMRHiUkyR/SAnjCn3M78hCGJCgkDzHWde+iXmG45Nf7hn6TPh/Ny79JvzZMk9DuGhHxxXSAFCXzQ09AGiwnlybNrE14b19AvSA1HheUU7SnvsJyZG9pNIOL5zDEgB2zPujA1toKUkBBwyx/PMeiHdmITkpQStEFopzoGP1KQTjYpLTLgmrIOQy70rWi953ugP5ysvF5Ah0Ur5mZdVW9NYUKLT6Kgmi7GvwaljpXImWyZLeSNjcpWQSiaeqKydvLUmzY3iAvIwY8YMS1IQPrxBM+Fj0kJLRPE/+oJmyC1kCZnhA9ieyVaIDtthQhMzmqI8EFxu+Q6EH8I0ys8BcsP/7MtS/DAgD1LoFKKA8ERYQUghLNxv3Gv8j0CW6Bo0FghbtCeSgZvtELTcZxAqBDDEgvsEIc06tkH4s2QfhCx9Q3sC0RFCIj4c9EmKIEpOKO4f1kGqMWFCXKRILf/TppAVqbbOvlK4lu3pG9oLMb9wfBkjCBJti58U+2IOY0wk/Jn7nPEXbRTb4nCLVodrA2GkD3KNuO8hMxwPUgXBoV3JtutD/HUwT4qDrlR7F00KZk4hNmFEmeNwf8j9IposNC1oUv0XAsYGwhfl/8J/3CMSjk+b9XJIV6QLJTqNjmochIM0ODVwOGbilTdCAW9mkBX+YwKLC3xuwrLqRmXTpX4OJRMI5SS6h8kbvxTpC5Mdk76bWdglOUFg0idfCs6aWSfh8sHYuZWya4kgU44LtAAIUd9XxXfKlWry8h9kg314s3YhBVIRSmhS2F9yl3DvQIppC0GNoIIE8T/XFKGMszP7QwLYH6EszqhcYyEekBgxsUCOIEQiZMXUwv3Kh23F/wOCJFoWzkeq23NMjidaJ8gOfUTAS4ZfTGkipBHgjBs+PTwr3FNoOCAzkB/WodmQcURryDHpC8dH28J1wUTHGEEg5BpxHO5zji2lFyA09Il9aJ88OpyT+PGI1ozjuo7i7OvXCgsDfcfsGUU44kaDcQ70T4pIivkUsuPn2IGEiTYvDJwXGiMhXIrmgRKdVjY3Bfnc1MB8RYoBJjx542NylmSAInTCgCBDcCK8mOiCQsBRh8+aNatEhHjDo13IDWp93u5wRpQ6Pj4qzV8hDri1AMIUQsU4ItgwZWAa8UPv45IktBUIYwRcnCy0Er0jSfDYl3UIKYQl1xNhyG+EGtoP1kMa6Dv/QRy4nghwyWXCf2gkxLQkFZG51rQPURCnUrYRAkW/xRRFe9wfrEOIi+OoEAjJucT2Yr6Rew9hR59FmHMv4HsDWaHvHJf7i30JcecYEAlxJBYCJBoVSBfXCA2GhD+LCZMyHJAJIQqijZLIQPFtcjUjQjCEDKCh4RwkxB4hTf8geCLsMVVBcFwiCjmQrNyMF+cjEURA/G5cEw3fcSyvFmlFFTEGUgzTBeNdKcLMxorGhhKdRkfaDsIZOxwjjBEOkpMFoYWfC2pnBES5ty4IzPXXXx/ojCyJ46iNJcC51nWwrYbE1BqMjfgzuEAQImQhI7zhI+gQwG7oPMLcDcFF2JPIDK0CQtDN0QJhgXCgXUBIoOKnLYgBJEKKd7KPhPxDTCAACAY+9BVBzxu/hOhiBuS4CCT2gRCI7wfER4oZQrTQLkAGuA8kJwlCm/3oEyYT+sR38RuhXxwbwc65ovlhO0gJQh2SJISBfem7XH/e3DlPTEkkpOS+ZD/8xCTHDOvpP8SY/6VwrGiYaAPyI86tkkEXQgMYPzcfD+dHW2I2korU5cxzUWCsfQ2EH3Zfzk9KUg64oG9ovKohDQpFXqBEJ8+oVRXxGlYrl2RfvNkiKBEsCFlITrlCgQsWLAgkOSLMIEFoewi1bnQgMNGKQBhcogOBgZAgWMXMJ2HgEoWCwIV40AbaEf5jfMTnBJIiESUIeoQa2gcx9aAdQvBCRiBJbMu1QYAjqCEwCFe0KfSH7xANycYKweBNW4gXwpj1aAy45mxH2xyL645mClLg+kjQf0gCfYPMsJ84tkqBRfaFMEBehMC4EV78Rz8YQ/oO0UBwc1wxT4nWRYgGmhW2ZR9X88D/hM77pIJzcjUhjD3XQ7Jgu/9xLr75Ew1JpSQnawRpSxSKRoQSnTyjBv4yNT3OFqKDwEUYkOwOYcDvoDo0CHGEjYRyk/cmCBLOiTDOW2gn/Q6K0BCNi9S9kfMV8w+aCcwUaDfQXEgkD0RGHFYZN8x+Yrrhf4gNQp99EFRsg0AXh1MENcIYjRDHhxyJYIbUSDV4tqM/7Mv2HEMIl5AqSAMkSMwckAPW0yc0LmgSICOSBE40K5ALITASccR+7C/J4fgtod74XPAfbUHwhGxgpgvLhiqaGEl25xIOyVArZQV80DcxY7nwfYzKEYQ4ZpC4bSoUisqhRCfPyNJfJiw5YMbAPwfhhvBDIEoNGVcQARwwv/Wtb9nilnzcDMACEupRBoD8NLWE1KWRMgZ+6Cn/i3O11LbxC+hhouH8ITZCFjCDIFzFXMB+CHy0G5JNFmEv+YQQpIyd63gJicBBVZIKComEvEg2W7fau+QhEZIhTthiduH86Dth5RyX8hy0I/lY+C5hz5LXR6JqODbbsxQSyzHxOUFDI7lJ2F/uBbaX8Gu2Y2zoEw6sbtZeEFb5HTCOUm06KaTWUbXVshUKRT6gJSDyjCz9ZcolB0wZCEauP4JaNBcIQD5BYaiEabMN9Y9w8JWIKMHxxx9vnSj5SDRIEiBYEezlzAZBKfWJBpJoLoShhNpKGC+aEcgKxAVAAhDeCGyID8dGA4N2AlKCpkNC2tkOXxrahWAg6PlOX9mP8YMsoF3hP4lUom3GFQENIYFo4HsBscHpV/xrIECQDjQ/nJtoiiTTrPjc0DfxEcKZFQgZFbMPfZLcRpItl2vJ2Ig2RLLXinOvVHP2w39FS4P2huML+XNRK+KB47MkllMoFI2PTInOyJEjO/x2nUQVdUY5LU7Kfjv33HNPKf27ZP6VhGxBcNPgUx7BhVtVuhIgbBH+EIIg0wX9ZBtICSYgyWcCkUGwI6QhAWKawCzEObENJACTEOQHYsB2tIPfCmRGCAL7QoaEhADICwKW/cV/hHbEtMQYSgIzcRTGx4Y+QWok0y/tis+K+K8I0RSyIJFtkhyOc+Y8aJdzoD0IkWivXEg4tGuawZRG21xT1+QD8aGPkDk/iicIop2qJ8ngPKS6tkKhaHxkSnTIoBr1W5FjpOy3A3FB2CI4xfEVYe5r+RD8hNwSBi5gWwHmrGohphRIg4CwZUlnLxFNkusEM5QIdUwu7EvfISY49nJu/GY96yAqEqIt/ki0I061CFHWoV2BXLCegpzsQ58gBpAYv+QFVb8x4bGfaFdwZpXQZska65sBQZjmyiV6Qo6OOOKIEiEKqi0mdYRcMuKb5gRomML+UygUioYnOqTLxzGPyRj1dyU5PhR1IjIp++0g2KWGlWRxpWSCS3QgCFKyIQjkHQnKe5MEYjJDSKOFETMaJhocgHFoFlKDkJa8KNzHEBCIDVE7kBqIiJipxAwkNarElMO+/E+baDc4Z54HKYbIOXEc8cvhe1ghTvrsJ2bLoiREORNRuYRvCoVC0TJEh4mcNPqKHMInMsuWGXPmmcb88IekWE3VPwgSICHkEo4M/Iy3fp0qH//93/8d+5hu1l0pBwDxQFMEIUGrgimKUGrIDFoQNDokmoN0sL+EKkMwSDC4dOnSUvE/TEQ4w0IKMPvIh7YkNJnvkCO+Qw4gRxT7dImEPwYKhUKhaCCio3kYcgyXyEAwRoww5sUXi2SnSh8YH2g9IDn4q0AyRHvh5jxBU0J+lqDq4g888IB1Ui1HCjAhQSYgHBAWCAfRQjj3SgZeqRIN+UCrRN/YDi0LTsZSaZq+ErWDaYl+QtohK/STtiTJmpwLGiFJkMf+nCdmLMgTTsQSdaSRPAqFQtFEREezajYAIDknnYQENgYHTDQ6KQMCAtER7UeQ2QPfG3xhfIwfPz72cXCsxSSExghiwrEwR0ntIRLTQUQwo+F7QgI4SBREhrBoyAgkhn1YSnkBfIvEZycsy6z4rUCcpKYSCKp8rFAoFIomITpkquUNmGgrfHTCknshbNR/p4ZwI6pY4uyLwygkB78dUtanEGmFg68UPUTDQd6VIECCXJKDdgXSkTQ/jtQQkgy9kA40LWgWJdMuWhb+J0oIcxU+L+KoK8nbJGEdhCxpkUwIFZogrXqsUCgULUB0eLMlgoZoKwQQAgfSgwAbPHhwifgsXrxYiU69HJFdX50UIq3wX8FURAQPSf/QnoRF7wgwM7nA1DNz5szEx5aQdcmuC+nApwaTF/41aGSo0CylEECQdon7Eu1MpWikeloKhULR7MiU6IwZM8acffbZJTJD8cZFixaZESNGdCA+ZEM966yzsuyKQrQ4n/0sme2MOfLI9hw5QmpSiLSSfCwUTITk4GAs1aqL3VhtHYBxyuUeQNPiOxn7RQnLQZIFQmwkosqPTiLiScxJUaRLoVAoFM2FTGd8zFYCCA0fIT7Lli2z6fshPnxXVIGg5H7+OtHW3HorGe6MOfHEzuapCiOt0OJwrTH9QDQkugo/F6l5JOYhwsf5X8onXHrppR3yxEByyHocB5IEj2R8+IORR4aoqqD6QZrLRaFQKFoTmRKdKAKDaYAPxGfy5MlZdqP5EWRy8teJluaFF4pEJ6VyHBANnHepGo7/CzWcIDJ80OgQhu0mq5MkfTfddJPV5Anwmfnud78byycGp2LalLw8UmwSgiMlBBQKhUKhyJzoIOQwX02fPr0UjhsEreBbJYJMTv460dag6YEYpJQIEA0KmYshNRAe/Gskp0z//v07+MC45R5ckiMOyHEdf6UsgdR8wvmXYqFuaQOFQqFQKGoSdQUwUZH1NszheNy4cXo1qkGQySnMDJVyoVBMVpIQEKJCpBO/JWrJj8IKAvfF5z//+bLHQoOD/w/RVURQYRajXIEWi1UoFIraYXW6pRAzR3Tp5iqwZMmSkpMoEVZRUVUILUVjQnxxJPMxmhxJzufjwgsv7LQOE9SPf/zjWJoYqeQNwSH3DT456lisUCgUtcXcLZ4RLMOI0Pe+V1zmAZlIiYsuushMmjTJjBo1ylx99dVZHEKRExou5RUgN5iUyFvjJ9UjsurKK6+0fjw+wqqXy384LUuVc4pt4lSMmYtluUrYCoVCoUgf5QJ0hQih63jve7uYvn27mXois9dh8pYocqYX9PPnpHAMITr46EBG8JfxCci3v/1t8+ijj5Z+T5w40cyYMaOspghiA3mifbIUE6KONkfz1CgUCkVtRctqb98oDwghQK+/TuBJm9l33z7m5JNNc5mucE49+OCD7UeRgV6wHIL0hnx38+dUe4wAooM2J0jL4pIcQJbscoDgUFYBExVZjonmoogmPjkKhULRrMjS7DN3rjHXXlus+pO0/SQiQ4jQGWcYc9xxBTNs2CpTT2RCdKZMmWK+8pWv2BpHigoAESGxX6WRUXI3jxxpDIkYhYr/8Y/G7LBD8S6s8hhU5b799tstySHSCqITpGmRcHIXkJf/+Z//sWHgLH3QHo7L+N9AdtiOGlW0H5TJWKFQKJoFYYQiDQI0dixRzsWqP0nfcSsRGYiac8/dbHr23GCaznTFWz2mBxxM8dUZOnRop0y1iggkjYxysx7zhLC84w5j8IkhZw7kJizcvEJARHAOJsIKHxzSBwQ5FPvlHUglgEPxJz/5SXPjjTd20gCtXbvWPPvss5YMQXTQ5uCwTLZjalMpFNUCbaGkKMgjeKa493m+eJFQtNY4f/nL+LUYM3o0ARjt66+80ph77in+d/rplbXds6cx//d/xsyf37l98NJL7f8x3fq/6Rv9kN9pjTNzPC+xWfldZkJ0Ro4cacs7UOph/vz5pVpXJAiUWldKfDJ4BYDciBbtN78pFunkxoljVE0Iblw0L2jtiLAK07Q89NBDpe+f+9znzIQJE0q/g25qBBBReJAaQtUhOoStkwhQoagGmFbJos19m2fwkkhRWAi/Oty35jgfdxyabV4U29cdc4wxn/xk8b2V9XAGpnt+d+3acf+o/8LaB+vWGYPHyfLlxjz3XHEdZf+ef764Pf+7v9McZ2QIPphkuedlOPdEBw2OlHoAvPFT6gHSM3v2bJtAkGRyOJsqKoTrGSZaGtHoCLGB6GQEbkRyI8HSg0gOyQMp9wBZAd/61rcs0Yl6GHgQ0OhAkiE3kBzKQgC+KxSVgqhA7i/uVZJMcj/lTbgJcOrnucFk62YVVzTGOG/cWCQEKLijcqDG3S5oP0xPb75Jfb+ihgde4LaDJob0Yqx///uD25d2CHzl9Mny0q1bsV3+4/Fgndu2uw+Q/dav79gO0z59Y9m9+2azYUP4OEuGe64FMgV3B6Jq0yQ7mWl0CDHv0aOHGT16tH1DZx0fMWesWLEii0O3DvwSD6KtCaq6HeVqX6EbPupIbswPf/jDHdYTRg6pfeaZZ0qh41x/yG8UIExoiTBRkfGYEHUKgyrBUaSBl156yU6cOLSn/baYNnhuIGYkxmxFooMwfeUVY3beORkByMs4U+IRAU+KL6bUsPPxt0vSPnElEJn3vKe4P7/RsEAudt3VmN12wz8SDXnxGEHtSztof3gk6CfbQ3CYdiFQJNF3+wwRor2XX+64HyYwfjOMaJJYL8d/882C2Xnnd8qOM0QIWYHsQPNKpG2uiQ6lH9DooMkhNT8JA/3/+SgSAlIi5iiKcoJynmHsg4s9NBz45qugOlkxAOvGj4Y3ZBi5+GXNDfBwQ5NXrrwDzsw8CMLuBwwYYD8KRbXgnsJsxYtX3kmOokgK0HSARsi66wNC4y6DzgdyADHAtCTbJWlfXF2EC0A+IBZvv10kGRwHESsEK6od0cTgv4O5inYQMSjqg6btoP0gTe+8U+wH+0K+9tij2B5k57XXtrHblYO86OISgftCWlrXTF8XYGc+yVFUAUjEVVcZ8+tfG3PmmeW1MJActGgPP1yk+pi2fLf9ClzpSR+AaQrywlvR1772NUtsJRO2i1NOOaUsyUEzRGkHbnKEkSQJzKtpQRGOemVEjTou2kfIM/dXFkBocVyW5f4vt63g3XfbzAsvtNnteFN//PHiMs7+cY+RVyBIMZUkJQD1gj/eTHdMyzLtBZ0PBETcKfme9FpBZiA5HIMP0zukA02MHMfvhw/W77mnMX36FJdocCBHRGVBSsLGP2g/lmh76Bf/0460x7nvuGP8E8RPh2eWT1rQ/PmNBMgIT9TNN+MEUyQ+QVoYMUfxJOFVBkXnScJVf4vPTGm/hE7KvB1Tlf7555+3Ghfy20ienOHDh3fYdubMmTaLcTnNEPWy8Mv5wAc+YN773vdqWYcGRoUKwqqTmUUdV0yoos1J2zTivrHTpt+2+z+Io63gDRhzAFyfxxiSw9sxGoCg/d1zanSNiAjoWpuy3OMxvQIhE1Hb4tArQXxB4y3nI4SI8xASgWaEayVmoHLnKMeDA3BfQCTYnn6G7b8xYvz8/4TElNs3aD2+OfQJTY748xS3KZi33opfj1Ce06is+UmhEqWRwNPCp0ePIu0WDY0vGWTWJ7ke6SjvvrtIeAA1qKqoXI72BY3OHnvsYe2tTzzxROk/98akUGsYyVm1apUNM4c0iS8PEXlqzmz+1PBZkaQ4xxUNYRgRqFSguqaKoLZ9U4b/PQi8AW+7bTe7HQLkmWeKb8xSFtDfn+OuXdsuaOIcI4nA5w0fh9NKyUYYeYgz5rUmbhwPUww+MDjmMp5h5862kBzezdBgoHlje76XOw8hP8j1uIRHjsdUy5LforUJG5tXIsav3NiG/R+0njGi/yw5f9mmUGgLHI8wZKHJb0iig2f21KlT7RKnZjQCJCkUZ+emhjuj46+DKQuTkURYuRmQSUvJXej69si6CiFFO3ESpir9D37wg07b7L///uYLX/hC4P6YEGgDh3Q863E4oy2Ij6LxUU0Wg2pIUpLjBhEPnyzIm3IcuEImqG1fCMV5/LbaqmB69iyYLl3a7P4QHIQGfhNB+3M8BAzKW4Q0b+WuBqESciICHyDwxS+kXP+DyIvblviQxCUxYdcrK4gPCspvyASatLBzd/uGpkU0b/vt13kcou4NMV1xTHlfDBoPV2vCseKMyc4R41dubMP+jyLv/rJXLzQ6pq5oOKIDuSEJISHqkqAOUwraA4jOggULTFPDndGF+boMWDIgo+2RJyXFUHOchsl1g3npV7/6Vaf/yZcwefLk0P0hSXjXQ07xy0GLc9xxx7VkdImiI1JO9RSKsLdfJmaEiPumXGnb1ZIMgHmCGALX1BHlN4GfhuvrUa0mxHV6dTU65RCm1ZK2pI24DrlR2oogJNXMuePsmm+kHQmf5v+otsX5VjRq/jgEnYfbHgQQkoN2iGPK/SNtCZllzCA5YWMSZI7a2TOputv496t7vLCxD1rvr5PfnJMSnYRAk+OSHIDZg3UQoMWLF9ukhE2DIMcFWUfklZv1uNrX4hhAGyMIsqFehYYpRnQV/j34+WCPVZJTGfyE2GnXgG0WkFMEgcNkjvkHBAkscaKMilSJgzh+G2F9YN3LL7eZbbdtM6+80mYFm7RR7tq6fhpJNCG8JPKyiCnZhe+vEdf8EHTc555bYaM0t9uuewdfIoilm//FHxPRkCxYMMOce+4k+yIbprmXfSVZHogaMwjOmjXbmq23bgvc3hXccu48c2j9uC4QS+DuiyYnbByCTIFuX2U7SI5EK/E/2jS5l+JcUyFYrhnsFc+0Ke1Lv6P8yNxrApKaM2WciQWoV7aQhpMw11xzTaDvh5Cb3Gp04oSjBG0TVPhE1ol043eNwlxwHsaG+uc//9k6Irv44he/WHZ/NDlMeAcccIANH9Rw38ohtwEBeCnUZ21akMKeN0p3IpeJnaWLcpEqceD6bcQRSNIHIUiswxkZJ84k0Ud+36s5F3nDh2gkjeDyj4sWngSxo0aNKglczhOBLucnx3vhhWKOFhGmCGT6IIQvCq6w9sctKBINIvmvf20de3tAnyEQhHGLKS7sGvnjIOY7PpyX21fa5ZxpW0K1JYTbvZfcNsOi+STKqzj27SSFNsQU59+fkhiQpR8l5t6nQefgP0Odr0txnFnWCw2n0SE657777uu0XjQ8CNLcoVwumyhvzCANjbvO30cKelIOgjIQKb3iQ3BWr15tk/jhTPw9CJkDim5+6UtfKpt+H5K033772YSAlIfQCKvKEZQQW9EZ1OUhZb1bii3Om3EazslR+wXlW0EAIXBwRt56622renyriVYSQsJSksAl8VsKg+9LhBYKAS++KVjhRcAD0T6IE3YYXDNYUKRUsDmtYN5++x2zyy5drAYtaHvfOZi+8xtfKUnOJ9vHud7uuTGu0ldEhIguNCW0z73ANsSehDlCi5Zmu+06apZcv59NW0yGoq10TXHSputI7GsP/fu0nDmzs29ScZx33hm9Sn3ITsNJGbLuBgHVKyhXEwnTCR+B5H5JO25f2mLZZdYs08aV79nTbDrllCJdD8Ipp5gumzaZze4273ufMeecI412Xufvc8oppuuSJfZOK8yaZTafe24qJAenbyKsqBME4fExY8YMq53x1d8yBhQBBeTJwXTFOiniVu24u2PdSnBvg/33Ly6zHIK448ztcemlXcypp27OzJSW5Bg9epDFu2C22mpzydwKvyZ7LGA64G2TCdmtZoIJiYmcW3r33eOHx7pti1BjyPxj+Nvhj0+ECs6bGzYU7LNUTYht0v67x6Ivr71GEtB2rQKaFtoJOpcgyHaMO+B8+L799sX8QMU+tkc4YVbkw378hpxyjH32QeAX+//OO+3X0D9XBD1CHEdud5OidqTNkiDGVq53MV/M22arrYr5wFzItWB1MXKo2Bfa2XFH9iuYdeuKSVLFxBg1zvThpZeKQl6Io9tXjkfbYJddim34Y+zfp3KNxARFe5yfnAr3F87s69cXj0nf5H6TlFKyrXvv+cNLO/zPGHNsSkoI/HbkWrjjUXSsDx7nILAN48o8U07jH3fObysESaaYqCZShiips846y6QFSgyg6SGaJ6iKtuD888/vpI2Q0gXbQYszQLc1a0yfhQvNqmHD7G/5vmFLqkj3f9b5v6s5XiX7l8Nvf/vbkiMyGplf//rXmSVjUzQe5s3bz9x7767m0ENfNCec8HhNj7FmTTezcGEfM2zYKtOz54bSPYqTPFF+Qckr8R9Atf7e975jJ2TBhg1dzauvdjO9em0w3bpt6pDMD9MSWhcm8TgIO0al7ZUDba5bt63ZvLnNkoTtt3/HvPnmVqVjuMccMuQI8+CDD9o6cz/96U/NHXfcYT977723+fjHj7Jz5tZb71zaV87lxhtnmcWLrzX333+/zYLfp8/e5uijh5uJE79uevXayW530kmfNX/9620d+valL51ivvvdX5SSyM2adYX5wx+uM48+utS+CH3wgweb8ePPNv36HVoar6lT/5+ZMeM75uc//435yEfeb3784x/bPhPQcOCBB5pzz/2eOfjgYZ3GkPN88cXtLIlgDGhL+v/b3842t9xynXnkkaW2/5wv9fjOOOMMm+wWfOMb3zKXX36ZOe+875n//M+zS9cQ8P2KK6bbfo0de4aZOPEHpnv3t82jjz7QqX/Dho0yY8ZMsYRjhx022mvyf/93kfn+979rFi++w7Z17rlfNQ89VNxHjg8uu+wyO+cuW/aAee21dWavvfqaz3/+s7af731v9073Dtfw+uuvt8c/4IADzTHHjDJnn326OfPMb5pu3XqaH/zgvA5jxHZ+f48//njzjW98o7TNK690M6+/vo3t+847bwi81wDnD+jTdtu92+GeS1qXDtcIAl+igKXgxBNPtNePjMqhKFSB7t27F3r06NHp09bWFvrp0qVLYdiwYYVrrrmmkBYWLVrEKBYWLFhQdtsNGzYU1q9fX/o8++yzdt9XXnmlsHHjxtQ+//rXvwo33HCDXbrr3z333MKmgQPtsrTum98sbNp9d7sM3GblyuL3lSvDjxlnmwo+b7/9duG3v/2t/Vx11VWFJUuWFEaOHGnHjM+Pf/xjuy7qM2vWrMKNN95YWLx4cWHNmjWp9i9qrPVTn3FeuXJj4dxz37XLSo9Vro2w/1k3cOAmu5R1r732WuHRRx+1/d60aVOnz4YNmwrPPbfZLt31rHv00c12GbU+bH93fdg2Qe29++67hbVr19pl1H5RH2nz739vXz7ySHEpbcoxBw4caJ/lESNG2CXzuqyT308++WSH89p///b/P/ShgYUPfrD9d58+/UrbzZo1v3DiiWNL688+++zC1VdfXfr/uOPa5xKO2a9fv9Lvn/xkfuGNN4rH/MEPptl1xx5b3L5v3352X5ay/b333hs4Du55h/X/oIPaf9MH2f/WW28t9S3oesrxb7rpvsIDD2wu/OAHs0rt7LVXv8JHPtLeLmP02GPt/Zg2rXhOU6cW99lxx+6FwYMHF1599dVSP939Dz54YId+M57+fSHXUPrMtTNbru1OO3W35+rezxdffHGH83avO99lu2ee2WzPj2XQGPMfH7ft9ntsU+l+jnPv8pzyvPLclpsnkNv0FVkehaqIThCGDh1qCc2MGTMK69atK63n+/Tp0+1/AwYMSPWYXMzZs2dXtC8DFGegkoKLgFCAeBTOP79QeP754h9LlxYKRx5ZXArOPLNQ2H334hKwLfuwDUvWDxpU/B6GM84oFHbZpVA47LD2Y6UAiCEE8oorrrDnc/vttxc+/vGP2zEbP368/R31+cMf/lC4/PLLCw8//LC90bNAaaw3bsykfUXncZZbtNyt5m4Xtk/Qen6Xu+XLHU/w1ltvFR577DG7DMLmzZsLb7zxRqfPmjVvFJ58sriMWs/3e+8tLt3twtaXOw4T/HPPPWeX5dqg7+Dtt4vnzBK88Uah8I9/MO8W1/P7sccKhfvvLxSeeabj9q5wc+dRhNOQIUPsepayz1VXLbDrELq09cgjhcKDDxYKDz9cKHziE8Xtb755kf2Pz8qVa+26I48c0qGPs2e3t/Pii2tL/7Gv9Oexx9babZEdsu600ybadh99tNifU08dZ9ez9CF95vylfeYzIQ6PPLLREiHGivb+7d+K/eflWfaHIEhfpO8s//Sn5SXSRX9+//vi7x126F644oqldvpmvO+5Z23h058utvvlL48r9UPOCYJzyinFc3Ih4wNB8p8Z6edVVy0qneP/+3+zO4yn9HP2lnbkPzmH5cuL/UV+LnXkkXvdx40bZ7eXayn7uuNbvMad/28f+02F5cvftKQsDso9r5XI71SjrsifQhI5QrypfeSq3/g+ceJEs3DhQrN8+XJzjjgXVAk8+TGDkYk3j+hy6aUdQ2L4joFWHIgBSfzGjy8u3YQiElmFdVHqUYVFb+HFRxwiGZBTDL/BPwefJnyZSOyHOnHp0qX2v0MOOaTs/vjmYOL84Ac/qBFWTVR7KigYsNx2YfsEra+gBFuHRyeJbxDqb3I7+Z+ePbc3++xTXEat5/uhhxaX7nZh68sdBxU8mcdZlmtj+fI3S86fbgQMfi9kgsAFkbEgPBrnWUm5FRSRxRzqzqO4AOATyZI5fenSFVsiwow57riR5hvfmG63w1m2f/+ic+oJJ4yy6x58kESuxX4Q3g/op9vHadMm2eX8+QvMu+92L/134IFDzLBhxRDylSs7Bp7suWc/881vTrc+IRIldOqpxXaeeGJFaTuJQpJ7Ap8R99iEqE+bNtXsuuub1kkdp2eW0n98EgHbDxs22n6/+ur5pf1ZXnrpbPv9xBPHW6fiiy8u9mPWrAXm8MMHWr8WxnfrrbubqVMX2HH81a/mdIpU6tULc9L0kmOz9B1PimOPHWm+/e3p1gHYjQCTfq5Zs6J07adMKR7/wgsXmLffLrpv8N/hh480J500ruRvwzoi2b7+9eL2F1+8wHzkIwM7XHeil1nOmTPHOotLRfIgh2j+w2dIUhFI9JfcY/gyNVXUFQ8Dg3PUUUeFbkMYOJFTPEAXXnhhVccjbw7OxxCovGLzqacWBbwfPeXO4GGZ0vywGsK5iSUOit6CJEGImMlSDL/BXorDF/5LEB2cjvlN5BQho2H7cM6QHJyNP/KRjyjJqRP8oLxK6knJPvi7J03XFBU0GLVN1skD/dwgjQoEHALRDRPmegX5fPp5dnyM52UrAKNHj7YCb9WqZeZTn+pnTjllpP34kUbvvLPOzJ1bFP4A4oBAFS/Qon9KcR9Czp9+eoXNgfaBD/QrCXHp269+tcBstdU6s8suHf0tIVjiiiGh0nvtVfRDdB2j/SgriXji87nPjbREB6dXXuAkAzX9F/IiYL/hw0eZBQvmmCVLFphzzhlXWr9kyTX2+9e/Ps6OwV/+stj+PvHE9jxuzz5bdLjedtvuZv/9DzF/+tNi8+yzy8yAAe3EYtSokYHlFY46aqQ5+eSR9nryWzJKM3bSTwkRX7VqhfXf+eAHB5revft16L8Qo9/8Zo51iqYtyAl9AQccMKRTgkzkuPT34YeXmYMOGhgrs3JUdFvTRF0R+RQm/FwwiBIlVSl48NAU+CSH9bnS7vgztvzm7oW0xCnLcOWVxXBxPpAcXhVcqSCSiPZSDnN5/fXX7YQAOeUBw/EQnHfeeYE1SSBBjz/+uI2oIk8OjqCEnivqA59ERNWTCiNBss+mTV2MpLCKS0T87YL2yZLUcE48Pscc03G9OyHvvvt2toZbEiCY5VGsNuSagET6AjHYfXdTEsBodNxkmnJMSTIHadh+++065FeRhHbshoZFtARxMgzzjAdB5vT777/XDB8+0r7hr1+/ztx553xz++2LrPaDD/ODAA0SxEOKTwIJ1aYfjzyyosMxg8tkdA4q2XXX/iWyJon0tgTO2nMOE8C0z35CGLbbbp2ZN2+eueWWW6zjq99/GW/uk+HDh1iZhdBnG8gXCRCfeWaFfXEXMib7l6vV1LXrmg73jC8z3b7T5g03zDc337zIrF69wpJDt5+SxXvduuJ4HnzwITYak2svmY5794YItV9bzp/oK4gR+PCHo/u7eXN4yhb/ugWlbeA+wAmcdAn1QqpE5+CDDzYPPPCAFY6UWg8C3tFSsqEazREXO0iT49+suYIrSViSRZinH1NQUM4btzgnWp2wFLjVVEOMgNQSk3B8JgRAfSry4LganH/84x+W2ACWTNIHHXSQJT4akVU/+CQiShMTdhuxLcIEgUVUUyOBc7rnHmM++cmO690JGcH03iRVB7cIckw2leSt8bVJZIuFkEhOFYgONeHok0t05JiSLRhzC0LEzY0itZAkHw9wS1H4fZRkc9KvIGy/fVGQ77RTL7vvn/+8zIwfP9i8/vo6S1TQyowYMcb06zfQPPTQMjN16iSbJ0e0KNIPN0Fd0nxnEnyz2249S33n/Cl2KtlC0GL5pQ1cyLHRqBxzzGA7vxFphSwaM2aMPQ9kE5YCnwwfd9xoqxG54YbFZty4kWb27NkdtGAydhAiedGGO2M+JGResigHEUoSqAaRB/oyeHCxnzLOJ5zQsZ8cgz5KQkWOgwlJtECgd2/IVPsxpISE398w9OrVr0NbUUharqMhiQ7sljd+Lg42vj59+nT4n9A1fGqYWCot04Dg5eZif7khhdzIf7mFK0lEelCX6rHHjPnRj4yZObPj9rKNmKO4gwa2qzw7bOcuU8KLL75oyY2E+N1NFXRrJ9+zE3lFcwOpobI5Zq2PfexjnR5gRf0RpT0Ju43YB3PBjTe2mX/+s485+eRklUpcbVKty1RwPAiC/94VVP8nLsIITdzaUn66fb8MQjkg1MRsgxCVxH5CKNwyFn7iO9EGub8lAdx9960omSjcvtx1V9Enb+ed+9n/Jk0aZUnOL36xwHzmM0VfGsk3g8ZBBK6UkJCxh9BJu+LfJ74wPliPMEeoI+TR3gB4n5vkjmshQr6Ytye8fIEI4X/7t1FWZlx99dVm2DBC0nc0777bxW7n+vm4ZPhrXxtvic6tt15tiQ4Z+iEJUo6CfXfcsbs101GOqNqEjQBZST+Dyl7IuDHO3DsHHdSvw3pfs/Lcc8X1EGPJeixpWKS/zWzmTZXoMGBoW8hnw80p/jhyAfiPSC8YNDWrKs2XQ1uYqML6kFu4kkQKbWJuQrMjhmxMeqzjP0gNEgZyxGwRJqEy0P3joEkGZFToaGj+8pe/lOpY8RbkAv8btDbkwIDwUMdKSU5y+Jc+bZTzzylHgjZtKpi+fVehbI+lDXLXAb7D27mla0V4OMbppxdLDviIS0x8gRW0X7kClW4brr+IPCZJhIhbfBQCIP44EAm/EKObzZY+0z8+komYayEE6Te/mW323nt2p/G46ab5dvmpTw20bT/77Aqz007dLckRxYwI8meeWW6X5RKeI2TFhYH53NdyMI8zxyPk+U9SnLmpUmQcxVLEFCrxL1E+IxxPSIokjJXtHn202H85J9nnYx8baPe57rprzN/+Vuzzqae2a0I43oEHFn1apN6ir90QExXBOHHg9tOHtME4FzMZ9+tg7WA/99izt2igGCtZD9lk+7D6kG5/86ilqWutqyVLltiIKwgNDscMMB++sw5zEwNbKRj0LWHxgR/eAHIrxSgD4VYVl7AAinMi4QBLdO3yW8JPPv5xYz796WI7WYbT2OiFJ8wf//hHG2GF2Wru3LnmO9/5Tul/tDUuULNDdHBW/tSnPtVJk9fqiHup/EufdvtxI6WC2uOWPffczaUkfD7kNuUj+7rrkCdHHlmcaOkDZI7tuJ2rvY0rfRT8mj5hNZ7c+kxuLSF3P/xWXGtM57pK7VE/4i8CWZGU+0ne+KX4KGasvfYqZsjGVyioRIMIW8xi9FkckqVKNkRLiMKVV84xv//9nNJ5ITB5sWSJeQOnYYAQxUfnX/+iUGexDfpx661zzKxZM0r7ynhuSYreyVwlL6WiuRBAfuRFVgSwECeWXJvHHy9qcNAYcWzgljCQcQi6VvSf4z3+eEftDef+i18U+//KK+sCnbLBmDHFiKdRo9qtBxzvJz9pPx/fB5V1EJewgqRBkH76Wi/GhqAQ4I6bjOdRRw02f//7utL9N2/eNYGKAXf8b711WYf7tZL+5hqFFCFJ+CRvzrJlywpz5syxyQH5nkdknkdHcruQO2e77YrLoGQhkgDklls659kJ2r/SRCNlQF6O3/3udzZvDh/JvyCfI4880ib+kzw5JBL83//9X5sQ8M9//nOhHqh3Hp1yOWXiXqqgFEtxELf9uLlvwtojOd8JJ/zdLpPsG3SbS2oozrfa27jc+SfJy0H/yKcieVUk5wm/yRfjjp2bi4YcIg88UFxKG2HbBv12QdI0cpmwTBNBOWVYkkSO5HOSO8VPGEgiOfojcHPasA8JRCXRH3lXpA22o/277y7m0eHDtm6uHjmmJKhzj+smgJVjso5rwTPCknMgvw3/kVsmaDx9fPvb0zvMZyTTk/6fdFKx/+TO4ZguyDXjJutzx1EwceLEDuPG+UnSPs7NhXtOQUgyzkHjSc4c2f6//mtiYB/c/so9IP11c+5Ug6T3cxZ5dFIlOiQDPProowuNhJoRnSAp5koelvvvX9wmKLuav39cqZUQ3GDz588v/OQnP7FZjV2Sc/zxx5cIDv8tXLiw8LOf/cxOXCTYqhfRSEp0Kh06fz9faPuC1s/7KMughHnke6Qdtgn6LreE+19QIj7Z5uSTi7kj4c1uG+XGQPYfP779I/uSbbh//zWF0057t3Qrun0KOr5s458/n5NOKubJZFvpB/3de+/istx1cMdVjsl1oM9xEgYGJTvzyYAsSbxHwr3ly9u3Zynkxk2q5u/rkpuwxGsuSLD28MPvFJ5+enNggrYwghQG2UeS7AkZk3O68MLZNtkcQGgK2UDQnXnmxMBj88yLEGWJECYBHZDM6W6SwR/8YHpJgCJcXdCWCFg+fHcT2PmkQJIhyvgKkWK/OGPF76lTZ9vMxSLghw8fWXj44eWWzA4Z0t5/H3IOQuKCCC1J/I46qiPB8UkTYEyKSf8WhPY57jj77UoGZfa56qoFhbvuWh56TiRohCS6/YUM+ucWhKgxlvV5IDpV1bryge8NDsc4pDYKsNGSzLBsrYyEeGfVKrPqG98wffv2NV3PPruzE4DvMIGqc8SIYpW0MWOK26DjR++fZUIRzy+HGjf45mCfJVng5z//+dL/1Lw5gggwQ0qff5qXX37Zjh31g/DjicqflCVwgr755pvNsccea8PaywEzRyVD6+8nvxmSIL+ToO0pLI+ZQYLspLA9/uiYFPbbr6iWRw0vFYmJKiEwgmNsMbXb7fhP2pbbiXWEU/MIYp4gMkWiUr7whfZ+ihkraH+yGODHQT+kICDH//rX3zGTJy83Tzyxr3nooS6G+rlHH93eJ+IA5Dzxqyfi5PDDjbn99uDxwNSyapUxWDrFhyZoXdh1oI8yBoBj4rPCuFFGT67thg0bbA08nkUKygo4Z3KciGMuJqCgx1RCkjkfcdyVMGnU/RLGTX/xm8GkJNdWwsblN8cDQccS/OMfBetDw7jvtltbh+38NuNA9mG8XIdk+soHZ23up6B93ONUcuysERRF5jtiB/W3eC686L9r2tq2Mt27F4uCSig8Y+WPSdSxxFSWZIySjHEcx2YxYwXVely8eLE1Q2KCFH+dqLEEcRypw/rrrt9tt+B0CWEIe16rkd+pOiPjy4GDE1mPq00G2OggI/L777zTdMHpgqvtSlSRbm7iP5m5/Rw5KUdSBYFwViLhsCtDXnhQIC8QHgGRVIcjtbaAvCM4H5NIkBuykZyP/egin3OGOe2G5XyUqH8XtCF+Ke72kgqJ9rnsLPmN398nPlF014IEEeCGX4iECUvgHW1KaCgRF9I2Pi/4itMXCA3ZaPFX5BgLF7b7YbhBf0Bcv5jU77uvYyYD+kFQIFkFxImRApq///0+5oknihXT/cBAaZvzf/jhYr/Cxm/WLGMmTCguBUHrfNA3xnHyZGP++teO15FMDQT0hD02QU7B4swr2WfdiV3CtYt5R9q3lTw1EEERqlwrN4Q6aClEKcr5eM89C+bpp6ny3bXTdkF5SsrB3UcENPcUBIccpJDhqH2qOXYYqo1IErgOv7QpZDOov/615xW/a9cNZtOm7e1vrrVMeUFj4js2B4VSJxkj1yld7ruw/eM4zqNowK+G4qw+2VmwYEHJ9yYMQUkWy12jsP6mea+kgVQ1OuTQuffee23YN8n8cGRCMxAmBIcPH25aUqMT9mpfj/hbwxv37daRmPxHf//7380BBxxgmTcVc3/yk5/YnDm//OUv7TauU/hee+1lc+qwfT2RVKPjI47mpdz+bA/xgKyQ/9HXmAjikipZH5Q6KUgjhQbj178uEqZrrgl+g4V0+PkpITlw8QMPLGpnwvrB+ve9rzjOBx10rLnssq07nIPfdpa3c1KNnPuGSB6gcm+glWhQ0hDc0kavXpvNW28FJwxMgxzkAVlohyRZImQzyDHbP2ZYYsYwZDH+ad5fOCgjewnIQelAWQfKdlx77Wzzwx/OsNFrURFf/jHSukZJxzn3Gh0GGM0A3Ak1Gl7dQVki+Z/1ROs0LXr3No9++cumz7HHmq4ifF3pBVwp4Mf21oj4EFX1r3/9y+bKwVQFeeFm5K0AkgOoqeOSHLl+aHnYvlGQRFPja16i2uRNH5LDHLJyZVExF5WTxk+ULaaksNvBDyQM0kjxugLJweTh5qSUNvmOdsYN+gOS4SAspN3tB1EuQecguS+BZEGoJANzXFSTNirpG2jcN9M0EqXJG3WhQALD8P9B2LGSCuN6kaegca22L0GaK7c9SarIfcx/EKJ3320zL7zQZk2JYceMSkJYLeLcX3HHhYhmFA3k+PET8g4cOLCk1akmy3GjIlWiM23atLLpr1sJ3dasMV3I3oye2H3NB+VeRTPKduzjz3/+s2XQkgJfMlrfdNNNHRi5C7aHaaepAasFyMmI/wqmCDc3YxD5QJPjJrsLgxAITD6HHdYxt6P4vqCBiBLqSUlBENGQPnBJIDO+ZTSMHEBu5FwxzySZyF3eHmS+Cjqea2ZjH9e0FRfVpI1KSkhqmelVBEqvXgWbWTjs/yjBEzc3UKXbp4Wgca22L36bfnuSYJAP755Fc+Q21vfKzS9TyzGKur+E4IhPVZzjQ2YkZ90TTyw3u+zS3+y/fz/z7/+ePEFvXrMc153o5Lm4Zj3QZ+FC04YEAlGv+UFSLaNsxy7QzOCAjFYHDQ6aG0jNFVdcYevACE4n45qzz+rVq60mp9GIjhhp4xhr4yrY/ByQlfDVSsoySJ8gUeKXIqXOWOeXRIsiB37C7jDTml+yjPWY7NB+QZZknUv0giDvQnl6J5JcOQiUILNHLSCChfeKIKITR/AkfQvP01t7Wn0RguAnDwzykdpxx41m2227RR4z7TGKq6ERgoXo8HMBRQETVa7qPTYb0YmLmTNnWsZJQbVmxqphw8w+vDYwawkljyro6Uu1jKOtqFEFycE3B9MVWp2f/vSn5qmnnrL/U2vn8ssvL/lY4QtD0i8IERXJ49hbawGGc968/cxBBxWjdcKICUMuUUdhPjDlCluCoBqtYXAdloM0O+XMOEEkSHxicFh+6KFiVBWToezvOhqj2WFbbsOw47jH8M/T/X3OOcVaVxdc0MU6DPsmPlCO1ImZDadrbv28wM027FdybiTkWWNVq76EaWCkJIWgmDSxUKpennW/yvWvnClOkTOiQ3bksBom+O4QkYXzULNjQ8+eZvOMGaYrEWhuGYcgpwZQAy2O4KWXXjIvvPCCJTcQmA984ANWqyMkB/ziF7/o4EiOIxsaHxzMd6fMck5w6aVdzL337mqX3/9+ODFxSYk4tCKoXQ7q7xfkVhXl3BtEYNxQdLc/Yf10EWQCc+vBfuADxUnQNQHJPuJoDMEj+itMa+OOS5jpSZYLF/YxTzzRZq2x7BNk4ou6fcN8heoNyTZcq5o+rtZBIrfyLMzq4ctT6THzpKUKQi39vhQZEB3IC+HlQSRHHFjle9Oklo6DIKnhOzVU63yQAGhl7rnnHnu90M5Qu4rvJ/KavQX77LNPydEYZ2VqWEFyKOi5G+qBHOHUUzebJ5980Zx6KiWCu8bijH5oeNAlCsoCIAjjqmEEJqw/5TQ+Qe25t08QyQpyNJZLJiTHNTm5+wf5K7nOyMOGrbL3RphJLOj2rbFFtmJBmoZgSWqWkAKboBZCrVLyEFbfK0vyU6lvTNLryH3NM14rEqcEpsGJDoU6eeunPgnx+rNmzbIh5zgpE9ePtuCiiy6yFcYvvvhi0zIIkh6VeGGmAEjmQw89ZMP3yJXz/ve/367HL8fFz372s9J38ulg5iJlwAc/+EEb9pcnSH6X3r37x+aMEu0kWpmg/YJ8XQQ+V/VNYb4GKKofURof93iyjHv74GgsyfrcdoOiysppqATUujr55M1m6623VIKMgaQW2VplWsjCyTSpWcLV6NQCYf0rR1qCtBBJxy8pMaqVZuaVV9pKFdCVgDQnUiU6hLWhtVlIhrItyYkwfRDqJllzMXt85StfMZMnT9bij3UA2pznn3/eXgcKcV577bXmxhtv7FAc7uc//3kpfwEh5+QpwMQFWbV5gaTccYOjnFYmytHYJxthpjD3WHGJTJxIq2oQFFVWbiyqQZQWJ+hcaxRwmIkgrcQsERRKnhUqTUhXbXK8OMcIO6YUWs1K47LzzkVrQ1BiwbyYE/PQp4056EOlSNWbFJOVWz0cwcjHreSKNzjCksRGitoCskJ5DsLDyWhMHiNIzTPPPGMTL4Gvfe1r5sMf/nBpH5yVIUREWBF6ngeS41erFmfkqOrVQRWuEa5kEcZihwYGMw+J96SitgjaOJMybdEG5Icwb8iOfyz+D9PwCJGRnDdBVcbTLFjvHs8fCyFb/hjjhIwzcrXHchF0rlFjleYYiCBNc9KOalMEtlsluhpU0l5Y/6TKNxqmuG0mHb+gSuJx4FZ+zwKEmrvnkfXxKkEe+vRKDvqQC6ITVGODUDeSGLmADC0lJlZRM7z44ovmrrvuMv/4xz+syQpccsklnbb75Cc/2eE3JiuSBVLLKg8aOPGbwcdEhKPrjByVQ4cSLyxdEIWFqQZhi0aDPDsQHlf4usI1SNC6Wgl4Pm2i2XGFty/sowR2mKAPI0BpEAHRUJFfSMgWY8xYy/nddBPa2nTvgaBzTUqM8gyXjCQVFPiORJGONAWPkBZMOH6blRCqoH0qJZaVEqSofrOORIEkDEzreFkiD33aOQd9yIXpChMVEVc+0XE1OgAzSVhUliI9UHgTkoLGhnw5mKwwRe277772/6uvvrrTPu9zkqUQck7OHELJMT3mIRmk1IZy/WaCnJFdMNnddVfR6dPNoRPm4Cv1pkQr427HNn6yuyDHY/6X/YMissKcnKNy+MTx+wky+1Ti8+L78fB706aC6duXYkDtvlDVIqlJLk/OzHHw4ouYi4v3HoU/k5l62n1HguoO1cr0FtfkFFRQ09+nEvNHpc67Uf3mP8a2W7dtbM2yNI6XJfLQp21y0IdcaHTwycHZ9aMf/WiJ8OCYDKm5/vrr7W+cYMmhAwFSZIv777/f3H333bZ+FaHjRFZRm4qwcl/LJnBz4zz33HPWzIjJql4kx9emQCCGDSuSDASwEImiM3JwG2xLeQZKJKCtkTRGL7zQXnTT1Wj4WhlX6xCU7M79381xg6takOYBrRLVyt2inEHn65MXPq6jdFxtUFItiBAjzmPEiPbxOffczdYZuZ6I0vZkZeJKC8lNPYXSG3SQ9iYr05scTzQhcd/k3T6G7ZOV+SNIexPVbyniScJARfMjVY2OlIC/77777BItwJgxY6w/DuHkmLbQ5iA01UcnO5AXB1MV2hv8ciA4EJ0BAwbY6uQTJkywJilJCki1+W9/+9vms1tUBuzD/xTIxMwIOaoVfO2Dq6EAkoNFBL8ksnP3l+ghNDNsQ7VvXIsouCmZg8Xxdvz44AR+oj1h6fYHM5eb5DooUkty3HzoQ8HOxcWqycWSEb7ADspS7GpykmqDZL8gDVPS5Ihh10n2yTpKKgncc2Cq4XpQ0Z0w+2qIQVKNBI8O17oSrYv4jtQ6N0ycKt1xEtwF7ZNFjaugPoOgPrjH2n33gnnttdRqWitaKWEgvjcSfQWI2LntttustgdtDmRnypQp5rTTTkv70C0PtGlPPvmkNVVBdiA6fPCtgdCA8847r0RywNlnn20+8YlPmN/85jclQsP+OCp/7GMfs3lzaokgc5JoXYAIbEn5AwnASbZv324lbcmcOcZst12xNAKEAM2Jm4k3LI1R0PGFVLC9ZFX2E+65CMpx44eOuxmafbh5dYIITVTIexjoA8dzc1ZGERrfPCSk5pRTgscJ1CJKKgn8c5BIOAo5JjWlxDHJZK3ur0fNraSkKk4fk9S4SkKA4vbZPVbO0oEpGoXoQGBOOOGETskA0QpElYdXVAciozBRQWAIH2cJwYHs4F8j+Nvf/mbNUYCkb1/96lfNQdRNsBNMb0uU0OYQkQVBZZu0EZSvJSihnAj6f/6zfUIKEtgIfpxk9923jzn55KK2BJKDmUoS5kEM3BIJUXlo/HIIQirobxzBHtS2L3Sj/FLcvDpBhCYq5D2pb0tYskK/f0JqNm3qYqQoclR7eYB7DhRt5Ppz7yQNq/a3qUazUqnmotx+1WpE8K3Ej5LnPytShfsCqUaCAlbihLxfccUMawWgaGVQstlKtE5xETa+9GfGjBlm0aJF1kWjEqTRhqLGRGf69On2onEzDx061H7Q5DRa8cdGAM7FTzzxhHU2ZoKCSJL7RmpRoZ3hP8D/c+bMKRXq/NznPme+9a1vBU5GkCQcksmWHDQpVYugfC0iSCE8TzxRJAr8RtAjpCA7kB4chIMyGK9bVzBPP71VyfcGYK4igmryZGOmTWs3/0TBN+X4x/JNVkk0Kkk1HWGEptJ8OkH7JU1WeMopm80DDwS3V20SwKyTBGI+2mWX4LBqd1mpSSYKcapQu8IUrVMSMlavCuRxgbsCebsQ5Ah0H0nMXJXAJypyLGpdxUEl49vIOWeaEak6I2MGOfjgg60/yPz5863PTo8ePcyhhx5q/UDIkqyoDuJ3g6Mx2hnexB577DHrREyOHMYbB2J8dH784x/ba4CvlFuN/N///d87tElpB8gQmiHMXGRAPvDAA1N3QBaHYh5+JgzX94TvDz9crM1EsXRxOibEGY2OkB0gzqgiHMEDD+xsvvSlYsQVvPrGG4tEB5KDcBFBHuWkCsEiBF00MkJ25Bhxc+pEnb/k6innJBvX6TYNB9wkOX4qRTmH6GrCxqtxPI7j0Fut068rKMOcY6OcdMs5Azdy2G8U0nK2rtYBOmx8yfCPhomyR5UeM6qNrLEx5bxOLaXREeCXA3vng98OH/kf1SPaHvXTiQcS/JGoDzLyl7/8xRITHIzF0RjtzR577GG3EXIi5Td8kJWaAp4C2nr00UetqQqTFe3sv//+mURZiTCDeKAd4TsRTiJIJWnffvu1Ox3zP5oc8VeBhIh/i7T3b/9GmOgm849/tJur3FBxKcmAMOTYRFMB19cGECnFW7d76kF1oSrJ3CtOxERboV1IO/uwO75J+pV21uUwxK09FvZ/lMaHa+6H/KeFNN7M41ShjtJelNMi1TvsN+/ai2o1Q2HjS+RwWPRw3GNGtZE1Xsm5JjC3Gh0XgwcPtjWuIDgIUwjP2LFjrbDGWZnIH0V5MF533nmn+eMf/2jJ4yuvvGLz45DJGJJDrSoqiRMhRQ2r7373u+aLX/xiJ5KDM/IFF1xgTYkuaA//HEgTpi60QVmFkkM29t7bmM9/vj0Db1BtpvPO66hhkJIFhDqLr4wb9v3Nb242H/jAWtO1a5v93w8VR4hLlBZuCNK2q0Xg88YbxUgpcVoGbIefjOSTiaMBCYL4++A7FHTuaaCSftUK5bRC5f53r5WvwQkK+QeyHdFWcd9g/W3KvZnHaTOJ1giEJbJLetxKgOsBL6HMAZib0Di45WFcYA5n21126WHe/3785PpbnxN3e/5HywxIK0K7tOmex4wZc8zgwcXtOCZzlJ97zQX/sQ3b0h4+RrQdNj7++HOO7Ec7d9xxhxk2bFjp2G7fOBfalrFgPxcck3VuTjhp+5FHlpkNG1aY444rnhefoH5GtUH/+F/GMGn/ZJu2trZOxwWvvbbCfPjDbeZrXxuVybGbOurKBcKYwYLksJSLifAWxzdFMCiAiimKyuGEhGMOFI0NxJFQcclwDF566aVAvxvwjW98w5qvgnylXn/9deuwjDYHvx/x60kL7ps4goqJZ8CA9kKS4gQL3Df2MA0DJEF8ZWQ7Msj+x38sNwcc0NdMmNA1ts9LmEOt7xPj1oWq1Jck6Phx24q7XS00M/WC7yTuaq6CQv6BbEfA4XHHFQkLZDau4zHblHszT/utOCqRXZbHBZAHXkJ33LG7+chHBlphDZnBDYEXVlfzIA7M4OCDB5p338X0vMwKPNqQ4BOEI/vRDku0+bgyCIYPH2VuuumaUtAKJIn9+QQ5HpPklP9oS8oN0Q8EMn2UdXHGhz7NnTvX7oPpCBnFOuQUvo60i18R//Md4Y7fIu4AALnG+fK/r5UhxYqcO22wf1A/o9ogRQv9qbR/5bDNFvHhpE6r2bFrjkKKWL9+feHaa68tTJgwoTBgwIBCly5d7Ketrc1+hg4dWpgxY0Zh2bJlhbyAPjMMLNPExo0bCzfccINdJsE777xTeOmllwpXXnmlHcvf/OY3hblz5xaWLFlSWLx4sV3efvvt9vOHP/zB/v7a175mz8H/HHDAAYVrrrmmtL18br311sIVV1xR+N3vfle4/PLLCy+//HLhtttus7/TxvnnFwqDBhUKZ5xR/Jx5ZqHw/POd/zvssEJhl12K/0e1w5L9ZVnNWCcFxzvyyEJh//2Lx4+zvdvPqHOKAv9zTI4d1lYt4I9zufPLCu5xo/og/61a9VbhscceK6xf/5Zd9/bb4W3z3zPPFD/+dvz29w9a565/+ulkY8R+zz23ufDyy+sKmzZtCj1mWB8rwcCBA0tzxvTpswsPPFCwn8ceW1sYMmSIXc9SsGDBAruO/XzI9osWLSqtW7t2bac23Hb2339g4cUX15bO9eabF5X6w75g+vTppXUTJ07s0M64cePsepbuGIVda7et66+/3o4zWL58eWl99+7d7W9/H/cc6Id/rnH6OXLkyNhtuOuT9i+sfb89tz9pHlvA+HIdZZzL4a23is8ry7Tkd6qmK1RcvBXA/GD0vvmKqubisNyqwOHXB5FO5BhatWqVzSj94IMPWg0O5Rd4w9lrr71K5iRCxNGU4WuDUzGamv/93//t1OaRRx5pfvCDH1jHYv9Yzz77rNXgkC+H//HPgY1TvDMrcwrdx+/GDfPmPwpg4htDtNWbbxZ9aIJqSbn5dPw6TLXKhhtUfqLc9lEOtowL41EuIizIfJYVkoxhWnWnwuqHhdUXc81cUX2Q7Yi2SmJCwoeK+9A3VyXJTizb/vznycaIdkhkt9VWhdBj8p3+0c80fWJ4G//mN8dZTRKf/v27W40Dc4No5NHIUtJi+PCRHXwyBWIaj1PiR5LG3nDDArPLLt1L53rggUNKmhw0Iy7QevjHlXbcY8a51iNGjLDzpNu2aFo4hqthEU1F3NJFcfsZBcbADTlPs395PnbuTVdijhI7LGo6BkvDy9vNUdwMn/70p61PDUn5KMewcuVKW2yT8HDWYULCKRjTFNvhP0O01VVXXRVYnwocdthhNlLq+OOP72DScgHZhIBi9sIhGTLFcTgG+3LstCHCBiEVlFGYWwNzAuW3yFwMfIdahIQ4J0sklFuHSTIjU9Tz5ps77psmkuawKedgK47Z4pQdBt98liWSODSnVXcq6JhxExJmUfsqzFyVxKlVtiGCMMisVk1fssqSzJzN1OHnCB09erR9ecVE0a1bP3P44SPNZz4zstMzwEsZJo84kHqHrsnGPS/MVmzjp7gIyqFDfp5KEJS3Rtry/0uaaiOon0mdjpGfWfUvz8fOPdHhJkd7A/sXG5/LBoX4kKOlVbMWY9+E8JCrBs0NEVX8ptCmZCTm+1ZbbWW1L5dddpm54oorItvGAfmII47o5ETM/pAk8urwnaKe4lhGxmM36zH+P3yyQJSPiU8eXEIUVszSFfxuZmSKe3IOWZGBpD4w5bZPIqSz8L8Jui716FNU8sFyeYuC+lBtTh633pMbSZQkusndtpoxCjpm2lFW4i65xx7Bgpj5AlAf73OfKwrwrbZaZ+bMmW81PhAWPmFOy0GQt39X+PvnFSRApS9Zo1LyVKt+Vtu/Rj12LogOUVV8ABFBPAQ8HBAfGDpOZEASCrq5XZodEiXFkiKbkB4cgXH+hfhhNkLTAsiRg4mvHP7rv/7LnHTSSR0KcbqAQKElwlEZ4kQYOg8gkVW1RFCIdhB8ARWVyM5NdudmRq5EqKSVrC6onai2fSGdddK8OJqUejg0RyUzrGRM/DIe5FPiBTVJratyzqxZZyuuJXAkBmhIxcznQggHZm7O5Z//XGbdEiA28hJLTUPXMZWxk4inIPDCV6mQbaSxzTPWJSCmjY7Moq7w+0B9Jyo8hDwPAFoeTCYQn1YiOhJBhRaFkG40LJioMDNh2oP8vPvuuzaUPCh76DHHHGMJC0SJKKmvf/3rgWHgmKbQ2mCmguRwHdAmfehDH7KTEsSq1pXIfVOTG3GFqQkNjgABhT+OZDd261yFaSA2bSqYvn1X8R5V0/wzcdpJ0nZa/YiLLMw+aYN7BKLCtWdM/IKt5bSEjClJKMnHhsLSr3UVhmqjrRopR4lkYibc2JjONlS09K72BT8chGRQVJRoavC3YwzCzl0S5IX5dbAe0hQUjdRIY5tnrMixT01DhZfjWCuh5W5eBN4QWqmuB+aohx9+2GYqhqRIDiHWU0zzV7/6VeT+aG3iJFeUxIL4/eB3s8MOO9i3MHLoQHTqhSAfE4pvXnZZMUEfE60rbPFbQbj51cXDNBDnnrvZ3HzzhpoK/LhmnyRt15p4NEI4OtmyKQPC0i0fguyVcgpB2iAhOZg2CS8nlUtQraswlDMPlSNCtaw2Xi3kveeXv5xtPvaxzj42hJcDcUZFQDKHB/mhSFg59eaizp39+SAXaM8nMzi88lIMmfL/a6SxzbP2ZlHAC3WzYqusiY04KIt6E4LTalFXaG6uvfZam4GYDw7DEJzfud6Wnnp25syZVtuD306c9OD44uCDs9tuu9kEgmh0SCYIsQozbdWiYGeYUOW2QJNDoBdmLdefgXb4368unhURqETgxzX7hLUdRJQagXjUGkQtkema+wqzk5/xOuxecM2l//d/Re0gFpi0TB5ChCQxnd9mvbMVVwKIBflxJIoG4SjaG9YJ4YCgiDOxS0LYvz1x3LpOY+ybqyAzOEBzDJKhiokM2SH+nUEvxI04tvWC+ArNnj27AzHFjUTGuBWQKtHhpsQsArnhpsVbXxyQMaG0KjBTuWGSVHh3wfgwkVx33XXmgAMOsL46OCsDyIoLTIBogjBPYQJk8uC3VCqn4jj+PvzGJ6eWCCrYGQaEl5RyCPJdkVT+blLBPBGBaklXrc1UjQrJlh1EoqMi1VxzKQpT6qZ169aewgA3tTT8O5rFjCKlCCAeuBjwXV5W/VDpKVOm2G2kUKermWEeQ4BOnTrVbjtx4sROGY2RCWzHB40NL8bMZ24CQMB/jRDRk2cggydNmmTHmOvFGItZkGsqIe/NjlSJDg5qpNOGOdba4TXPwJRE+HgY/vu//9s+0G6Kbd8khVYIsxQaHpZob4imonwDuXkgRoSIY66qBcJMN/LGHeVXA+KSlrwSgmpJVyP4x9QLQfdMEhIt+0OM5N55663iEjMpmbSffjodstMMZhTmHRySP//5ceayy2aYa6+9uuQfA5Hx88FAXpivWI8AFYdktPl85+ULjQG/3W0hP5LVWMA2YqKSl0E5phAfReVg7JcuXWqvMePL+DOurn9VvWpt1RJtZA3MqnHqLXHTM5B5DSnHuRdtE5qSNPP9oFG5+eabzbHHHmsuv/xy62NDzhpuuD//+c82aR/2bBJWTZ48udP+kBccmHEoZgzxtaGPojHbZZddbH8ZV5yYaz2+VODGjwYTAjWlQNBbt0RO4SuRVUSUO9b4JlXbXq2Qp77EQZJxrgZB90yUWTRof8xWJFnEN+zddzeY559/2nz4w33t8wTJQbDjt5PHccfszLzE811Ls/PatUUimJa2K++oxzi3IjYnHGde7Emgi7KE5zUN+Z2JMzJZe137H+qxCy+80JpVUF3yvZXwpz/9yS5xCD788MPtxwWmJ3xsMHEhQBAoL774otl5553tei4kSQYp5kniQAgQZir8ceoFoccuTZa3bhyMcRZFMKHhwcUIcwGTaVLBkkRzQvs4OLs5eYI0A3nREOWpL3mCaLmk4jxLxglzZ9xEjW6UH9p5fHQQ3nwQ5OKrU0/kKUyaPvCMQgCjoqXqjTyNmaJxkDrRoWAbak+EsxQDE6URzE7UnfcQ89kC4NzxvQEf/ehHzWOPPWb222+/UnI+SA7sVaKkIDswWjQ0EEPsqWhxJEohL3B9bNzEfhAbshg/9lgxKywTE6YGJtFyJodq4WdGDiISeTIZ1aMvedEixckvJFrDW29tr9Lt5x0K0vKUyySdF2fWPPn35IkANsqYKVqU6Fx00UXWHoiNtVgFt6OqClMNGh0E/w9/+ENzJtKyyUHlcRIDAqKhGBMp6SC5dCA11LPif9ahsenTp48NC8cPp9Z5b8LgCxYROm5iP/7nsqLZ2X//4mQkb+RZC3Q/M3IQkUjbobka4lAP5+ostUhJxiKoH/7+oi2U+yioOnmY3447toSn5xF58+/JCwFspDFTtCDRoQ4TQllIThBwgiJ8mmSBrUB0cB4GaGtI1oc5Cg0O48NviCBOxJAcgRst5Udd1RO+YHFzlQARREERVVjZstYk+MShFkSi0cxPWWqRqqmTBcmhSCvmJtk/KjIvzPm9kdAIxCIPJiT/WI06ZoomITqYrMjDUM6pF5MWeRNaATgdA8InqRgOqSFSitBwzFaYtvwK43mCq8XB8dgVLGGlHUSLg+BiX4InsiAEogE45RRTN+TJFBYHWZK/IPISt/xFUGX4cn110xA0ix8Ix3755Taz7bb50OLmwYSk5ipFrogO0VVx6mdIZs1WwGpm+y1hfuS3IVrK1d5AdPJimoqjxXEFCwIJ/wn8cVjv/sfbOG5YLMmDkgUhEPK0aVMXM2iQqQvylNun3ggiL5VoeOotzOohWIVc4ciPpbtbt21MPWonxiV5tTQhqblKkSuiQ8Zj/G+oyo3mIggUrIToBJWBb0Y88cQTJY0OH79CeF5Jju9gTNSKHznF8hOfMGblyuL/ktgP7LsvIfLt5CcLQiDHOuWUzeaBB9JtW1E96l2dvZEEq5ArXibIrbrttnhfb1u7Dnj9KEfyamlCUnOVolqkmjyAjJloKEgceDuv8Z4wp0SEZE9ulYyMkuUTcxX+OY0CeRuXsN7HH6dKeNEctUVJZYFT8he+YMxDDxXNWOzHh/Dyo4+Ozl5bLUQ46iRYO6xZ081ccEGXDvdAo1wfKdcgEVzlBGstzVZMDSi5cc/bffeC2WqrzNKbxepHA01VCkVtiQ4ZF2fNmmUT3EFo0F5AaqizgR8KWhx8U8iWedRRR5lWqhCLWQ+zVZ6BEIDUENaLJueII8jqbAwJNP/5z2L0iuQmESAQcMki2RgaH/bjDV6W9ToPtEtxhHErotLxYfsf/Wiguf76tg73QKMATQUftBZ5Q5bkKi7By7ofCkW9kHo6SOqXPPXUU2b48OE2lw4aHsiNaHoIP5c6KM0OnI0JFQdkRSZcPM+CTvxxfv3rIuFBEXfjjaQFKGaRRUODqUpMWNIOpIaoKtTuaIDq/SYv2qhGFMZ5Hh/yFL3++tbWd6RRnK9doKnIk7YiCQFJwxyVJ4JXq3NXKFL30SEds2gvCCNvdaDZIkkimi3MVlQjzwPCnEQl3w2BYg8+WCQ0n/ucMdtvX/yf6CrIDNwN0xQOwKzjsmOiykuYb6NFQjXK+JCn6Mkn/2mmTXuv6d27S8MlK8yLr4fveAyy7FcenXk1kkrRsBodqViuaE8WCMgbRMTVVhSSyQGCTEtitoLk4FjMh+8EiFHLCl8c9sG5GOJDpNUbbxTXQXDIhgwJysOkVW+NUt5R6fiw/QknPF7xuKqmrbOQr4WGKY/mKPUFUjR01NW9996bZpMNDYqaAiqL58VsFRbhInlM+vc35oADiusgNFJvCFIk+xx2WDHSilNiHSRJEgjm6Q1ekS+opq2zhiVP5KMVtWuK1kCqRGfu3Lk2GeA555zTcoU7gyD1vA477DCbGTlrVEMsgvKYBGWrFb8ekgei5YkKDW60rMGK7O9JvQ9UyCsUDW26opwBEVZEXlGQknDzSy65xObWCfo0O3DCBnvuuWdNiI5vGnCjqIhyD4u0kezH4i8Qla2WdXHNVPWOvlLUPzpNzVX5B9nss87nRfRpnGSyYZgxY0apvFArgPQrnC8FsBU50+gQXs7FIcKKm5pK5UEPkGQDJiqpWUFxzvXr15d8lyj/UGvTgJvV+K67iuYmSfjnFtqU7bgcOBlLOYcgLU+jJoFT1EfjpuYqBbKgf//+NuXIokWL6t0dRQsiVaIzbdq03Gb6rTVefPFFuyTiSso/ZA2fWLhFD3Echug8/HCRzFC6gd/8j9aH5d13t+fJEWdVXwAqeWke1IKE6P2iUCTH+PHjzaGHHmpdQRQ5IzokAlR0rHFFgdNu3brZTzbHiS6cCInhf3xqiKASTQ6JAMmPA7kBmK7cthTNDyUhCkU+QYoWPoqcJgxUFPHII4+UIq623Xbb1ImO+Ff86EfRPhBSYRzCA4Eh3w3C7bzzjPnQh4qaHtlXw7IVitYGvjBksEczj7kJzUKYb82cOXPsttTwk+3xLXG3l/8B/iZsR5th7dDGqFGjSqVzgsB/bMO2tIePURJfFvH3oZ077rjDDBs2rHRst2+ci/gv8R/7VToO+CjxH9v448lv/z/Oh+NJZn2/3/zvjlnSfk+K8AGSvjLGWRy7Lii0ONavX09RGbtME2PHjrXtHnXUUYXbb7+97PbPP18onH9+obB0aXHJ7yiwzaBBhcIZZ3TcXtpxfx92WKHQq1dx6a5n3/HjC4Uzzyx/vDxj48aNhRtuuMEuFdmhUcf5rbfeKjz22GN22QjYtGlTYe3atXZZCwwcONDOVSNHjrTL7t27l9bJ7+XLlwfuw4fv7u9+/fqVtluwYEFh3LhxpfUTJ0606wRyTGmHbeS3u9306dM79JHt+O5uv5TJMwakLZmjOe6QIUNK7fBdzsf9zmf27NkVjQNgXzkHF3Js93wZJ9YtWrSoU79lPKvp98SA9gVca7+f1Rz74osvTnQ/J3le48pvJToZEZ3DDjvMtjthwoTCM888E7qdEA5IyP77FwpHHlkkMJCVoG2FxMh+PklxCZD8D5nZfvt2ssNvOR7LXXbpSIIaDY0qgBsNjTrOdSU6/ptHjomOLxDpgwgzlgIEsgg7H7K9K0Bpx2/Db4dtBOwr/ZH1Imj5IKRdiPBlGQduW9dff31pnEXAB5E72aeacXDHWtZLGz75iSI6/vqk/a6G6FRy7MGDB9ed6KjpKiOg3vvJT35iDjzwwFLElZib0MpK2DemJyKe8JchjHvy5GLoNr40fng4OW3mzSsuAcU0KcGA6Um2feqpYp4OMhvT7pVXFhP7jRtnzL77Fo9DVBVLEgKSjp5t+a0hwApF68bXU6eQj4AgCqKkWDKfuWaUkSNH2qhaH2LucLcNA2YOQLkgjiEgOov2wX333ddhH/xW/ONKO3GO6WLEiBHmyCOP7NA2kcOAY7g+MjIu/jGSjoOURuJ/zFRjx461504OurjgmIxRNf2uFJUc++mnnzb1Rj5qEjQhtt56a7P33nubt956y/rouHMe5OTxx4skg2CswYON2XXXYgI+yV0DadlvvyIpYXf8bHDzkQriOA8DnPIhNx/7WPE/PhLJLnWqaBe/G8mXA7GR+lULFxYzIVOsU52QFYrWja/3fWcElPXBDwX/DAQZwk6IiAsEN3nU4oBtEb4IySCnWwgB27gECAQdlxI7lcAV2H5b/n9+P6QvScdBiBrkrG/fvnZbn+iVA/4x1fS7GtTz2NVAiU7GoJCnEB0J937ppfYK4JCW554rVgxHa0PYNxoZ1j/0UJG0dO1a3B6NzxFHdC6ySQLmt94qVhAfMYK3IGOeeKK4Dfm1xLmYpRAk4JZuUAdkhaK1Q9vConxwKgWU9xHBjoCeP3++1fhAWJImBBQNQ1RkUZCglL5kjbjkqZJxIDr56quvtsQxjCxVikpJX6MfuxyU6NSA6KDdkTkPc5Mk59tzT2P23rtorsKkhbYHcoOGBcLihoLfeGORAEFiqBpOPpwPfrBollqzpmh6QoMza5YxEyYU/3/yyfacOA0+BysUijpBCEcv3rS2RD0NHjzYCnQxXYwZM8Yu+U9MSVFYw6TV4MK0mnEQohcVXVYvrKsig3VeoUQnY/hh5aLVIX+NVP/+61/bM9Si/MEcJRmLReMtOXAwZc2fX9T4QICYe9AYDh/evi3kh7mJlx+/QrkW2VQoFEEQU5KPpWQYdbQv4l+CycXXRsT1BZFEeGHbsx4SEGbaygMqHQcJ2XcJUZCfT72wIiV/nqYhOtXWqxqOdG5y7IY9yXT2j/n5z4vkRsgLPnEk9ZN1PDeYnzBlYX4S4sP+mKkgOGhvIEk+ccG/B82Rv16LbCoUijDgVxLkW4JpBggJQhCi5QkyuSxHtRwD7M8HQU97PplB8OMXBInIK9GpZBxw6ua8pByG5JoRTVAetDeLmrBMR1VEhwtcScmHVqh1JdgPj2Kn7hS+NvjF8IFsYLKiSCa+N27tKZ4TtnWjofgf8xWfMWOMOfro4ieuSaqB/CIVCkWNgQAm2ZtEyyAERWvBOiEcCHdxJnZJCPtLgrggAeqbqyAzaDc4xm233VYykUF+aCvMYTgvqGQcJBpLoq8gljj4sj4uSUwD/bf4OnF8l6hRNFXGvplQFdHR2lbxISYr0ej4pANSI9oWd1v5D20PcItxJoX65CgUiqiSAxAPTCl8F/8RP6R7ypQpdhsp1OlqZiBECMqpU6d2KgskGY0R7BLKjsBHy0GWXdFoyHGTRiPVGknHQUxWkAs5Lwmlh2BAjmpVRmn06NG274w9/WfsxVwoUWHNhKqIjta2igfJn4ODMCYrnmdZB2GBfPgRUBIdJU7KogECQRpO9b9RKBTVhJUjnBG2EhGE8EMQ+/4jzPsIatYjKMURF5MH39HcILj57W6L0Ge9q/1gGzFRSc4cOWY9TDlJkGQcWM95snRzFQFy6LA/5ALSUwtTXffu3a3vFdeecaef9M31N8qrybAStJE1sNYHnTlzpr2wt9xyi6k3XnvtNbPTTjuZ9evX2wKcaeGdd94xN998szn22GPNhRdubWbOLOa4OfxwY26/vZ3AoKGJ0rLEJTBx22tGuGMtEW6K9NGo47xhwwabtIy8JVkV100TmzdvtvMS81GXLprTNSvoOOdznJM8r3HldyZRV0uWLAn13EZ1d+GFF9qOtQogKRAWNDqiqYnrLxPX3KT+NwqFQqFQZEx0IC+EDQaRHHFAlu9pJklqBPiVwdP2l1H/G4VCoVAoOiNVfR02WDzHSaI0a9Ysc9BBB5WclnHAOuussyzJwS4oIYutgAYqd6NQKBQKRVMhVY0ODk1obRZSQGlLKB2ZLAlZPOqoo+w6PLy/8pWvmMmTJ5s+ffqYZgcmKyKoyJOjZiWFQqFQKBpYo+Nn1nSTQgnwOMfJqNnC14KwZk0386UvdTXkXyJqSqOhFAqFQqFoYI1OUM4DQtQoBucCMiRpxZtZkzN9+iHmpZfabEkGoqEUCoVCoVA0sEYHE5VfpMxNPCWQbJLNjEsv7WL++c/tbNK/jRvbkwEqFAqFQqFoUKKDTw7Oxh/96EdtiLkkf4LUXH/99fY38fGSXKmZceqpm82RRz5vvvSlzeaLX1T/HIWi3qhDyjCFQpGD5zRV0xX+N0RXkWmRJQ7IFCuTjI9SGwSH5TR8dMji+eqrr5pevXrZaC9Si+clbB1/nC9/+VFz7LF9zNZbd613dxSKloUkKWuF2noKRaNj05bnNM0kjqknDMT35tprry39JmshBdvQ9qDNgexQI+S0006r6jiEqBPB5aYnh+iQdttPsa1QKFoXZHHu2rWreeutt8z2FJpTKBS5xeuvv26f2TSzr2eSGXnEiBGdnI/TrMwq1W19FRekx62+q1AoFGiQt9tuO5vQlHQXkB6FQpE/8DJCWQcUImkWDM+E6GQNzGJBBd9kHfl88mLCUigU9ccuu+xiVq5caVatWmXJzrbbbpvqRJp2baCNGzfamj9agyk76DjnY5xRWGCuQpMDyeHZ3HnnnVPtQ+pE54EHHrAZkstFVTHJ3HPPPRUdA2fmsMq2MEGqxSrRUSgUgm222cbsscce5pVXXjEvvPCCyTOY+Hmzfc973pNbMtYM0HHO1zhjqkJ+Q3LS1rqmSnTwxRk2bFgsz+lqbixIFNFcQeBtDWdohUKhcIH5aq+99jLvvvuu/eS5Svydd95pPvWpTzVUlfhGg45zfsYZTQ//ZUU4UyU6RFJBcPCR4TsZkNMGUVtRkMiuMLz99tv2I0BVJheDT1qQttJsUxEMHevaoJnGOc9+Oqj6IWL0Mc/9bHToOOdrnCt5+Yg7F7UVUgxaR5tCqPeTTz5psgIkpkePHqVQdh84I7NNmPPz+eefb773ve91Wn/llVfaNz6FQqFQKBT5x5tvvmlOPPFEG2iw44471s5HJ8x3JssyE0k0PoS2n3HGGR00Onvuuac1uUUNVCVME18hQt5VLZotdKxrAx3n2kDHuTbQcW78cRaLTDlslXUJiFqDPDpRWZfx6ObjI+24/azbVXSGjnVtoONcG+g41wY6zo07znHbSzWmDlMSJqNzzjnHZK3VgdCEaXQOOeSQTI+vUCgUCoWiMbBV2mokyA5Zi8llQ+JAsheHodLsyKNHj46MrEJFplAoFAqFQrFV2v45Eh721FNP2UzFQeFi+D+zvlKiQzkJMiOjvXF9dsivA8JCzxUKhUKhULQWUiU606ZNq0niJYgMCQFJTOjWuuL7ggULyjosKxQKhUKhaA2kSnQmTpxoagUIDdXLydcj1csxmSXNiCzR9XG9t5N4mhP6Rrvq6JYtdKxrAx3n2kDHuTbQcW78cRa5XTZBcZp5dBoRzz33nA0vVygUCoVC0Xh49tlnbYmXTIjOmDFjrKlq8uTJ5qCDDrK/44L95s2bZ/KQtXH16tVmhx12SNXsJvl5uABp5udRdIaOdW2g41wb6DjXBjrOjT/O0BeKgfbu3TuyMGtVRIeGIQeYkYYPH56oAiz7UbG0mS/uTjvtVDZjo6J66FjXBjrOtYGOc22g49w641yVj87SpUvtUhL0yW+FQqFQKBSKPKAqonPwwQdH/lYoFAqFQqGoJ6rKjEzdqOuuu67D7yVLlqTRr4YHZSa++93vBpabUKQLHevaQMe5NtBxrg10nFtnnKv20aEY5i233FL6jWPyhRdemGYfFQqFQqFQKOpjuqIq6THHHGOdjQCOyeS0aZSoK4VCoVAoFM2LqjQ6lFygHAPe1LaxtrayiXtaJepKoVAoFApF/ZFKwsCnn37aEpwBAwbY7MRxMyT37du32kMrFAqFQqFQZFsCQggLNagGDRqkBEahUCgUCkUu0PIlILIANbheffXVUg2uoUOHJq7B1WqgEj1FWlmuWLHCrFmzxkbxhY1bkjHW61EevKCE5cHSsa4ec+bM6eC72L9/fzNu3LhO2+lYVw4ZD8A8wj0dNMbutjrO4WAMx44dayseRJ1vVmOZ6rhDdBTpYdy4cYXp06d3WDdkyJDC7Nmz69anvGPt2rV23FgKli5dCgEvjBw5sqox1utRHoxR2FSgY10duKf9MeDe7tevn1260LGuHIzH8uXLO6xjLFgftK2OcziYczlvmRcWLFgQum1WY5n2uCvRSREinOOuVxQxceLEDiRHwI3OuC1atKiiMdbrUR6MxcCBAxONk451cqHhgvu5e/fuHQSzjnXlYDyZQ4LAvR30AuVDx7kzuD+jiE5WY5nFuFeVMFDREbNnzzYDBw7stF7WXXPNNXXoVf7BuKBm9oHPl6QsqGSM9XqUx9VXXx1ajFfHujosW7bMnvekSZM63ddr164tlc4BOtbVjTPm7iAwxu5/Os7pIauxzGLcleikCMLt3cnLRffu3W3OIUVnMGb45ASNGXD/SzLGej2igQ0cP6gw6FhXB3zOOPewcXGhY105GAuEH35QQSTIFZo6zukhq7HMYtyV6KQI3hx69uwZ+B/r77vvvpr3qRHAjcsbbtAkBQ499NCKxlivRzgYWyYTIZNB0LGuDowJY4xTJ6SSD9qdIIGsY105cFBlnEltgsMq482HHG+uNhjoOKeHrMYyi3FPJbxcUfRQjwICpdw2io5Ahcm4SeREkjHW61HeZDV9+vTQ/3Ws0yGTmKkgNm5uMQQwEW7c30DHunownowr2oAePXpYLc5tt93WgcjrOKeHrMYyq3FXjY4il2DC4jN37txIrYMifZOVonrIZMw97IfEQjAhP/ynSAfMERAdGWtIJqHRCgVQopMSygnjVmb/lYBJizdeV0gkGWO9HpWbrICOdXWQMWGsfX8D+S0aHR3r6oHJCrOG1FpEk4bfDvmKZEx0nNNDVmOZ1bgr0akRcKhVzUR8koPGISzZVxpj3KrXA5NVGsnOdKzjIey8WR8WKeRDxzoa+Oa42hyIJH5/EEnG2I96C4OOc3rIaiwrHXf10UkRXICg6CFhooccckjN+9RoYFLC+TisXlqSMdbr0RG84aLRQTC4EOc+WY9phbHTsa4O4ogcBH+9jnXlwAwYlOCfFyXGA3Iv0HFOD1mNZRbjrhqdFDF69OjItzTUq4roCYt03z7JcaNUkoyxXo+O4I1X3nTdj0wc8lvemHSsqwPmk7AJG7gTto51NvC1lzrO6SGrscxk3CtKM6gIzdDJkPpZfsPWKzqOkZ/yW+CuTzLGej2qKwGhY51OZlm/NIFkeHVLQOhYVw6yH7vZ011QMkDnj2wyI2c1llmMuxKdDFK+++nIqdERVS+k1cEDRe0fBC5jx0dqrQSNXZIx1utRHoxR2DuPjnV1YDwYA18wB5Us0LGubv4IIpRBtfJ0nONBCHlUfamsxjLtcdfq5RmgVavdVgoiI6JUleTI8FOCa/Xh6oFJEFOWpFRnjDGnSDSQQMc6nXEmKghTVlQ1aB3rysD84eeFYl4J8/XTcY72k2Q8pbQGpmzMsNy//tzQKNXLlegoFAqFQqFoWqgzskKhUCgUiqaFEh2FQqFQKBRNCyU6CoVCoVAomhZKdBQKhUKhUDQtlOgoFAqFQqFoWijRUSgUCoVC0bRQoqNQKBQKhaJpoURHoVAoFApF00KJjkKhUCgUiqaFEh2FosFAWvZ169ZlmgK+ra3NLF68uK5tNBLydr49evSwH4VCoURHoWgoQHCo4TNq1Kh6d0WhUCgaAlvVuwMKhSJfGD9+vDn00ENtgc96ttFIaLXzVSgaCUp0FApFB/Tr189+6t1GI6HVzlehaCSo6UqhaBAMHTq05HeBLwg+IWgSwIwZM+zvZcuW2c+gQYPsb9eXZ86cOaU2+A8TGL4lvr8PbdMevkACt33WSzt8OJbvm5JGG+5+cj4s+Q04d/qfBBwbsx/n7rfngnZlbBk3d/ugYwadL+C3ezyWtOtvJ7jmmms6jAvfOX4Y6Is7NuXGI+75KxRNhYJCoWgILFiwoDBu3LgCj22/fv0KEydOtOvA9OnT7frZs2fbZffu3QtDhgwprF271v4/cOBAu54P393ftOWCdlm/aNGi0jq/ffYZOXKkXUo7S5cuTbUNwP9uvzkvvrOe76yLCzmuHNsfExdyLDkPOZa7v4xt2PlyLu72XA/pP0t3fyDXVrZ3x4XzdcG+fn+kbTkOn0rPX6FoJijRUSgaCAg4EWYuhESIcHYBGQoTZrTjC+goksLHb18EtCuM02hDBDP9dkmBnE8SAb18+fLS+LhkinZlDOiDwCUB9CNo+3LnK20IGfXJG+MhYD/pH311+y2Ex21HjuePjbQjbVV6/gpFM0GJjkLRRETH184ABCTC1RXCPplwhXkUSQlqX4SoSzrSaEM0FK7g94lRXKIj5CJoDBhTOZZPUnxNSljfgs7Xb9M9V8YiiBQF9U80QzJucg+EjY1Leis9f4WimaA+OgpFE2HkyJGB6xYsWGCGDBnSYT2+ObNnz666/aROuHHakFxBAwcODGw/aXi9+P/4YwC6d+9eipbCh8WF+On4GD16dOD2LqTf+Nm427F+4sSJHfrC//QjqH8yBuLXI0u2DRqbcePGpXb+CkUzQKOuFIomAk6mQYA0zJ8/3yxatMgKykqTDoa1n3YbIszDwrWTkis5Vxxwo7BmzZoOv8OOL+cQ5lQMIJeQHEgGTr9CNFgHGYFguG1EnZMQHYjIfffdF7m9tJvG+SsUzQAlOgpFE6Fnz56d1iEcBw8ebIUdwhENwZgxY+yS/5JGLuX1PMsBAhCk7aiEQAmZePXVVyPbWr58uSU6kB6W8mHMWRek3cri3NM+f4WikaBER6FocmDmgeQECdYojUQ9IQI3rH9J+y3EZPr06Yn2Q3sSZO5ZunSpXZIksBzYX9rgOhAuDtHhuuAnWe5c3f9cIhK2fZCmrtLzVyiaAeqjo1A0ORCICLog7QEahzxCBDrajyDBndS3CBMU7YTl6sEUFWRSCzsOZkCAVixszINKdXAd8M8R4iHnxvmG9U/yDrEPHzkm2waRnaC8O5Wev0LRDFCio1A0IJL4UiAcEXK+UEQgSrK4LIuEVgrRPojZzU2qF5VEL6otiIfvcMs6xiaICAYdCx8b+sP2YaYe8alh/6BkiuwvxMXtn59MUBIOutsAyJL03R0bMYuldf4KRVOg3mFfCoUiPtzQYkKGJSxcQor9nC3ufxKW7ibpkzBtwoslr0u5ZH9BSBJeHrcNIDle5D/pt5tHJi5kn6AEfkEJA2W8whIGuqHd5fIGyfHcJIB+qLebMNBP6lguYaA7Nu65VXr+CkUzQTU6CkUDAQ0Ab+cs0RbEMT3x9o8JBi0Db/y80WP+YF/W8yaPVoCIrLyBPnG+4jgN8DWSsO8kjrm0Q3v4y6ARYywYE9aLz03Y8dmO47PEoZexK+e4y7hLWL8cDzDeHM/3/eFayPYSGcd3We+C608bHEPGRsxi9I3xmTJlStXnr1A0A9pgO/XuhEKhUPgQk0xQuDRCWsK0k/rrxAHh4JAHnR4VisaHanQUCkUuAdmgsGWQ/5BoOJImDlQoFK0HJToKhSKXEPMUzshitsKcg7MtDsKYXYJCvxUKhcKF5tFRKBS5BP4m9957r/VFkszCAvxSfL8VhUKhCIL66CgUilwDLQ4+OTjZkuulFpocyBXHlTBuhULRuFCio1AoFAqFommhPjoKhUKhUCiaFkp0FAqFQqFQNC2U6CgUCoVCoWhaKNFRKBQKhULRtFCio1AoFAqFommhREehUCgUCkXTQomOQqFQKBSKpoUSHYVCoVAoFKZZ8f8BQWKaaHsLfG4AAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# import plotting tool\n",
    "plt.rcParams.update({\n",
    "    \"text.usetex\": True, # enable latex font\n",
    "    \"font.family\": \"Helvetica\", # set font style\n",
    "    \"text.latex.preamble\": r'\\usepackage{amsmath}', # add latex packages\n",
    "    \"font.size\": \"16\", # set font size\n",
    "})\n",
    "\n",
    "# static plots\n",
    "%matplotlib inline \n",
    "\n",
    "### plot and examine learning curves\n",
    "\n",
    "episodes=list(range(N_episodes))\n",
    "\n",
    "plt.plot(episodes, mean_final_reward, '-k', label='batch average' )\n",
    "plt.fill_between(episodes, \n",
    "                 mean_final_reward-0.5*std_final_reward, \n",
    "                 mean_final_reward+0.5*std_final_reward, \n",
    "                 color='k', \n",
    "                 alpha=0.25)\n",
    "\n",
    "plt.plot(episodes, min_final_reward, '.b' , markersize=1, label='batch minimum' )\n",
    "plt.plot(episodes, max_final_reward, '.r' , markersize=1, label='batch maximum' )\n",
    "\n",
    "plt.xlabel('training episode')\n",
    "plt.ylabel('final reward $r_T{=}{-}\\\\log_{10}\\\\left(1{-}|\\\\langle\\\\psi_\\\\ast|\\\\psi(T)\\\\rangle|^2\\\\right) $')\n",
    "\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "# np.savez('PG-STA_training',\n",
    "#               episodes=episodes, \n",
    "#               mean_final_reward=mean_final_reward, \n",
    "#               std_final_reward=std_final_reward, \n",
    "#               min_final_reward=min_final_reward,\n",
    "#               max_final_reward=max_final_reward,\n",
    "#          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.reset()\n",
    "RL_field_t = np.zeros(env.n_time_steps)\n",
    "RL_actions_t = np.zeros(env.n_time_steps, dtype=int)\n",
    "fidelity_t = np.zeros(env.n_time_steps)\n",
    "fidelity_inst_t = np.zeros(env.n_time_steps)\n",
    "\n",
    "for time_step in range(env.n_time_steps):\n",
    "    #print('time step {0:d}'.format(time_step) )\n",
    "    # select state\n",
    "    state[:] = env.state[:]\n",
    "    CD_drive=env.CD_drive\n",
    "    \n",
    "    # select an action according to current policy\n",
    "    pi_s = np.exp( predict(current_params, state) )\n",
    "    action = np.argmax(pi_s)\n",
    "    #action = np.random.choice(env.actions, p = pi_s)\n",
    "    #print('policy:', pi_s, np.argmax(pi_s))\n",
    "\n",
    "    #action = RL_best_seen_actions[time_step]\n",
    "    \n",
    "    # record field value\n",
    "    RL_field_t[time_step] = CD_drive + env.delta_h*env.action_space[action]\n",
    "    RL_actions_t[time_step] = env.action_space[action]\n",
    "\n",
    "    #print(CD_drive, env.delta_h*env.action_space[action])\n",
    "    \n",
    "    # take an environment step\n",
    "    state[:], reward, _ = env.step(action)\n",
    "\n",
    "    # measure target fidelity\n",
    "    fidelity_t[time_step] = np.abs( env.psi_target.conj().dot(env.psi)  )**2 #reward\n",
    "\n",
    "    # measure instantaneous fidelity\n",
    "    drive = env.h_t(env.dt*env.ep_step)\n",
    "    H = env.Delta*env.sigma_z + drive*env.sigma_x\n",
    "    E_inst,V_inst = np.linalg.eigh(H)\n",
    "    psi_inst=V_inst[:,0]\n",
    "\n",
    "    fidelity_inst_t[time_step] = np.abs( psi_inst.conj().dot(env.psi)  )**2 #reward\n",
    "\n",
    "reward_RL = reward\n",
    "\n",
    "print('RL fidelity:', fidelity_t[-1])\n",
    "\n",
    "plt.step(times, fidelity_t, '.-k', where='pre')\n",
    "plt.step(times, fidelity_inst_t, '.-', color='brown', where='pre')\n",
    "\n",
    "plt.step(times, CD_protocol_t, '.-b', where='pre', label='discretized CD, $r_T={0:0.3f}$'.format(reward_CD_approx) )\n",
    "plt.step(times, RL_field_t, '.-g', where='pre', label='RL agent, $r_T={0:0.3f}$'.format(reward_RL) )\n",
    "plt.plot(times, exact_CD_protocol(times),'--r', label='exact CD, $r_T=\\\\infty$' )\n",
    "\n",
    "plt.legend(fontsize=14)\n",
    "plt.xlabel('time $t$')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# np.savez('PG-STA_protocol',\n",
    "#               times=times, \n",
    "#               fidelity_t=fidelity_t, \n",
    "#               fidelity_inst_t=fidelity_inst_t, \n",
    "#               RL_field_t=RL_field_t, \n",
    "#               CD_protocol_t=CD_protocol_t,\n",
    "#               exact_CD_protocol=exact_CD_protocol(times),\n",
    "#               reward_RL=reward_RL,\n",
    "#               reward_CD_approx=reward_CD_approx,\n",
    "#          )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dx0eLXIk2tlW"
   },
   "source": [
    "## Questions\n",
    "\n",
    "**Q0.** Try out different batch sizes and hyperparameters (including different network architectures). Can you improve the performance?\n",
    "\n",
    "**Q1.** Reducing the time step size while keeping the protocol duration fixed will increase the total number of steps in an episode. Does the RL agent find the exact CD protocol in this case?\n",
    "\n",
    "**Q2.** The current problem limits the RL agent to control the $\\sigma^y$ term only; add a second set of actions to also optimize the control field of the $\\sigma^x$ term simultaneously. You may need to run a new hyperparameter search. "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".quctrl (3.11.8)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "latex_metadata": {
   "affiliation": "Faculty of Physics, Sofia University, 5 James Bourchier Blvd., 1164 Sofia, Bulgaria",
   "author": "Marin Bukov",
   "title": "Reinforcement Learning Course: WiSe 2020/21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
